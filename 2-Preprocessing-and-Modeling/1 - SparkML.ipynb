{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36cf256-7d1c-41b6-9e53-c936bbd887eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am using the following SPARK_HOME: C:\\Users\\arthu\\Desktop\\spark\\spark-3.5.5-bin-hadoop3\n",
      "Windows detected: set HADOOP_HOME to: C:\\Users\\arthu\\Desktop\\spark\\winutils\n",
      "  Also added Hadoop bin directory to PATH: C:\\Users\\arthu\\Desktop\\spark\\winutils\\bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "spark_home = os.path.abspath(os.getcwd() + \"/../spark-3.5.5-bin-hadoop3\")\n",
    "hadoop_home = os.path.abspath(os.getcwd() + \"/../winutils\")\n",
    "print(f\"I am using the following SPARK_HOME: {spark_home}\")\n",
    "if os.name == 'nt':\n",
    "    os.environ[\"HADOOP_HOME\"] = f\"{hadoop_home}\"\n",
    "    print(f\"Windows detected: set HADOOP_HOME to: {os.environ['HADOOP_HOME']}\")\n",
    "    hadoop_bin = os.path.join(hadoop_home, \"bin\")\n",
    "    os.environ[\"PATH\"] = f\"{hadoop_bin};{os.environ['PATH']}\"\n",
    "    print(f\"  Also added Hadoop bin directory to PATH: {hadoop_bin}\")\n",
    "\n",
    "import findspark\n",
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "findspark.init(spark_home)\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8911ee64-b3cf-48b6-90b0-ea74aa142384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- published: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- updated: string (nullable = true)\n",
      "\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |main_category  |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|tensor-network toolbox for probing dynamics of non-abelian gauge\\n  theories tensor-network methods enable probing dynamics of strongly interacting\\nquantum many-body systems, including gauge theories, via hamiltonian\\nsimulation, hence bypassing sign problems. they also have the potential to\\ninform efficient quantum-simulation algorithms of the same theories. we develop\\nand benchmark a matrix-product-state ansatz for the su(2) lattice gauge theory\\nusing the loop-string-hadron formulation. this formulation has been\\ndemonstrated to be advantageous in hamiltonian simulation of non-abelian gauge\\ntheories. it is applicable to both su(2) and su(3) gauge groups, to periodic\\nand open boundary conditions, and to 1+1 and higher dimensions. in this work,\\nwe report on progress in computing static and dynamical observables in a su(2)\\ngauge theory in (1+1)d, pushing the boundary of existing studies.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |hep-lat        |\n",
      "|unveiling the complexity of arnold's tongues in a breathing-soliton\\n  laser synchronization occurs ubiquitously in nature and science. the\\nsynchronization regions generally broaden monotonically with the strength of\\nthe forcing, thereby featuring a tongue-like shape in parameter space, known as\\narnold's tongue. such a shape is universal, prevailing in many diverse\\nsynchronized systems. interestingly, theoretical studies suggest that under\\nstrong external forcing, the shape of the synchronization regions can change\\nsubstantially and even holes can appear in the solid patterns. however,\\nexperimentally accessing these abnormal regimes is quite challenging, mainly\\nbecause many real-world systems displaying synchronization become fragile under\\nstrong forcing. here, we are able to observe these intriguing regimes in a\\nbreathing-soliton laser. two types of abnormal synchronization regions are\\nunveiled, namely, a leaf- and a ray-like shape. high-resolution control of the\\nloss allows holes to be revealed in the synchronization regions. our work opens\\nthe possibility to study intriguing synchronization dynamics using a simple\\nbreathing-soliton laser as a testbed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |physics.optics |\n",
      "|planetesimal formation via the streaming instability in simulations of\\n  infall dominated young disks protoplanetary disks naturally emerge during protostellar core-collapse. in\\ntheir early evolutionary stages, infalling material dominates their dynamical\\nevolution. in the context of planet formation, this means that the conditions\\nin young disks are different from the typically considered disks where infall\\nhas subsided. high inward velocities are caused by the advection of accreted\\nmaterial which is deficient in angular momentum, rather than being set by\\nviscous spreading, and accretion gives rise to strong velocity fluctuations.\\ntherefore, we aim to investigate when it is possible for the first\\nplanetesimals to form and subsequent planet formation to commence. we analyze\\nthe disks obtained in numerical 3d nonideal magnetohydrodynamical simulations,\\nwhich serve as a basis for 1d models representing the conditions during the\\nclass 0/i evolutionary stages. we integrate the 1d models with an adapted\\nversion of the twopoppy code to investigate the formation of the first\\nplanetesimals via the streaming instability. in disks with temperatures such\\nthat the snow line is located at ~10 au and where it is assumed that velocity\\nfluctuations felt by the dust are reduced by a factor of 10 compared to the\\ngas, ${\\sim}10^{-3}m_\\odot$ of planetesimals may be formed already during the\\nfirst 100 kyr after disk formation, implying the possible early formation of\\ngiant planet cores. the cold-finger effect at the snow line is the dominant\\ndriver of planetesimal formation, which occurs in episodes and utilizes solids\\nsupplied directly from the envelope, leaving the disk solid reservoir intact.\\nhowever, if the cold-finger effect is suppressed, early planetesimal formation\\nis limited to cold disks with efficient dust settling whose dust-to-gas ratio\\nis initially enriched to $\\epsilon_0\\geq 0.03$.                                                                                                              |astro-ph.EP    |\n",
      "|carbon capture capacity estimation of taiga reforestation and\\n  afforestation at the western boreal edge using spatially explicit carbon\\n  budget modeling canada's northern boreal has considerable potential for tree planting related\\nclimate change mitigation solutions, considering the sparsity of trees and\\nlarge portions of non-forested land at the northern forest edge. moreover,\\nafforestation at the northern boreal edge would enable further the observed\\ngradual tree-line advancement of the taiga into the southern arctic, assisting\\nforests in their migration northward while capitalizing on their carbon capture\\ncapacity. however, significant uncertainties remain about the carbon capture\\ncapacity of large-scale tree planting in the northern boreal ecozones under\\nchanging climatic conditions due to lack of spatially explicit ecozone specific\\nmodeling. in this paper, we provide monte carlo estimates of carbon capture\\ncapacity of taiga reforestation and afforestation at the north-western boreal\\nedge using spatially explicit carbon budget modeling. we combine\\nsatellite-based forest inventory data and probabilistic fire regime\\nrepresentations to simulate how total ecosystem carbon (tec) might evolve from\\n2025 until 2100 under different scenarios composed of fire return intervals\\n(fri), historical land classes, planting mortality, and climatic variables. our\\nfindings suggest that afforestation at the north-western boreal edge could\\nprovide meaningful carbon sequestration toward canada's climate targets,\\npotentially storing approximately 3.88g tonnes of $co_{2}$e over the next 75\\nyears in the average case resulting from afforestation on approximately 6.4m\\nhectares, with the northwest territories (nt)-taiga shield west (tsw) zone\\nshowing the most potential. further research is needed to refine these\\nestimates using improved modeling, study economic viability of such a project,\\nand investigate the impact on other regional processes such as permafrost thaw,\\nenergy fluxes, and albedo feedbacks.|physics.comp-ph|\n",
      "|theoretical determination of the ionization potentials of scf, yf, laf\\n  and acf we present a comprehensive theoretical study of the ionization potentials of\\nthe mf (m = sc, y, la, ac) molecules using the state-of-the-art relativistic\\ncoupled cluster approach with single, double, and perturbative triple\\nexcitations (ccsd(t)). we have further corrected our results for higherorder\\nexcitations (up to full triples), the qed self-energy and vacuum-polarization\\ncontributions. we have extensively investigated the effect of the various\\ncomputational parameters on the calculated ionization potentials, allowing us\\nto assign realistic uncertainties to our predictions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |physics.atom-ph|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat_ws\n",
    "\n",
    "# Load your JSON file\n",
    "df = spark.read.option(\"multiLine\", True).json(\"C:/Users/arthu/Desktop/spark/Data JSON/data_ass3.json\")\n",
    "\n",
    "# Show original schema to verify structure\n",
    "df.printSchema()\n",
    "\n",
    "# Use the first category as the label (fine-grained)\n",
    "df = df.withColumn(\"main_category\", col(\"categories\")[0])\n",
    "\n",
    "# Join title and summary into one feature column\n",
    "df = df.withColumn(\"text\", concat_ws(\" \", col(\"title\"), col(\"summary\")))\n",
    "\n",
    "# Trimming leading and trailing white spaces \n",
    "from pyspark.sql.functions import trim\n",
    "df = df.withColumn(\"text\", trim(col(\"text\")))\n",
    "\n",
    "#Lowercase text \n",
    "from pyspark.sql.functions import lower\n",
    "df = df.withColumn(\"text\", lower(col(\"text\")))\n",
    "\n",
    "# Preview result\n",
    "df.select(\"text\", \"main_category\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16c75c",
   "metadata": {},
   "source": [
    "## 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537afcdd-6382-41f4-9b39-c2d7506f4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d9b6f4",
   "metadata": {},
   "source": [
    "## 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc35723-2ef5-4d54-971f-e17809e3628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text into words\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "\n",
    "# Remove stop words\n",
    "stopwords = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "\n",
    "# Convert words to term frequencies\n",
    "tf = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "\n",
    "# Compute IDF (inverse document frequency)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Index the label (main_category) as numerical class\n",
    "label_indexer = StringIndexer(inputCol=\"main_category\", outputCol=\"label\")\n",
    "\n",
    "# Classifier\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "\n",
    "# Assemble into pipeline\n",
    "pipeline_LR = Pipeline(stages=[tokenizer, stopwords, tf, idf, label_indexer, lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3916e743-bd79-49bc-994e-f5897d8fbe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9ee50d-bd11-4409-89b9-2f0d2d6e3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline_LR.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e336c9f",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d239ffd2-d6af-4da3-9826-e9aa964ad035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155b724b-37a4-44af-852e-6292ea968f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.5969\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test set accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b7db85-df54-456d-8d66-dfec16896966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|main_category|prediction|probability                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+-------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|nucl-ex      |97.0      |[3.395263818761074E-4,0.002810217203557092,1.5892907633857008E-4,0.0015168003948570095,0.0024382592323579436,0.0012231519737437692,1.420541627627325E-4,0.17517136827317162,0.0012027212891046063,0.0031415926308735777,0.0033614803509195985,8.492309408926863E-5,4.3138836742136243E-4,1.849585451471538E-4,5.643408396174271E-4,1.1136077054837739E-4,2.2450981954557587E-4,4.808292855627593E-4,0.002567078901712362,6.414447224933613E-4,2.498102648960191E-4,0.0014718013063113997,4.155583391973147E-4,1.1805774775925997E-4,8.711027144278449E-4,5.939482802906768E-4,0.0059126307329233265,0.0010437727885910756,2.889634313243771E-4,0.002299255158521643,9.927748789010508E-4,5.527357286989495E-4,5.979237970792474E-4,0.00323636855688038,0.0012285880760479317,0.0011292104537569474,0.0031405211486944516,0.0017428915372766519,4.74789903583313E-4,1.3910328369361205E-4,1.8589230929743258E-4,2.3690891860491908E-4,7.757135191124268E-4,5.863277217315133E-4,0.0017419838119363212,0.001625165374926326,5.380627714883713E-4,2.3912566558816967E-4,0.008148833053448795,9.27829889681226E-4,0.08414734035255111,1.1530102382999799E-4,2.0301159270801934E-4,0.17132268170090187,6.095232406748009E-4,3.1394111755896054E-4,0.0022344225353362703,7.013043017438247E-4,8.480801058485269E-4,9.548663226105151E-5,1.8265529575187543E-4,0.0010891757048106761,6.599567420948839E-4,5.077022982847E-4,3.7933694952806655E-4,1.4253071974063098E-4,1.994059149820258E-4,9.675246407241491E-5,2.288562950602385E-4,2.5799139816716206E-4,1.3266522458592144E-4,8.941852147555042E-5,3.585183098914236E-4,1.0255531358060516E-4,1.1491187499173233E-4,8.259118554781929E-4,9.944368873005427E-5,2.6475797759786807E-4,2.6864658207812343E-4,4.5770939131935083E-4,1.7038070223396876E-4,2.0113600655656083E-4,4.703220869482329E-5,2.271092825628657E-4,1.3792976582353953E-4,1.432651077911787E-4,1.4698907399761748E-4,1.7603117515605169E-4,2.577088086131044E-4,8.053298674697636E-5,9.338415174443383E-5,2.3574032043741701E-4,2.309635298858176E-4,2.1352109219349732E-4,2.0061370996198843E-4,7.329378048093489E-5,1.943891330486833E-4,0.4877576702105969,8.101199205902374E-5,3.5901812181157023E-4,1.609761327725093E-4,1.5859400845012663E-4,3.2453001600457035E-4,1.4271469833029493E-4,1.2352259235946672E-4,4.233595570964371E-5,2.021176789791706E-4,1.0586107920898744E-4,5.443116851279862E-5,1.6953433280244553E-4,7.495933777448479E-5,7.548602146392602E-5,1.5161268842205173E-4,8.088186472221433E-5,4.547154094963722E-5,3.131062502107585E-4,4.680453811271052E-5,7.573993782845593E-5,4.591155550395712E-5,4.9553392787436844E-5,3.717347310094634E-5,7.268208298627968E-5,7.983747327937323E-5,1.6430371637475558E-4,4.395838361552752E-5,5.9228213575013255E-5,5.312880933826185E-5,9.667392390914143E-5,5.22390167712271E-5,4.670903093269837E-5,3.3109949418349505E-5,3.7326511901764556E-5,4.774698927092008E-5,2.3103318124509688E-5,3.8983351530772776E-5,3.717596932790152E-5,2.4410278615544446E-5,5.781164842561616E-5,2.319495389928775E-5,2.7268879337476488E-5,2.1040513695929105E-5,1.5797713050363917E-5,1.895591926267444E-5,1.627901726922535E-5,1.1703010708736926E-5,9.05030716023629E-6,8.74984537272683E-6,6.774834559869117E-6,5.628460584582409E-6,5.5068472899857865E-6]     |charged-particle multiplicity distributions over a wide pseudorapidity\\n  range in p-pb collisions at $\\mathbf{\\sqrt{s}_{\\rm nn} = 5.02}$ tev this paper presents the primary charged-particle multiplicity distributions\\nin proton-lead collisions at a centre-of-mass energy per nucleon-nucleon\\ncollision of $\\sqrt{s_{\\rm nn}} = 5.02$ tev. the distributions are reported for\\nnon-single diffractive collisions in different pseudorapidity ranges. the\\nmeasurements are performed using the combined information from the silicon\\npixel detector and the forward multiplicity detector of alice. the multiplicity\\ndistributions are parametrised with a double negative binomial distribution\\nfunction which provides satisfactory descriptions of the distributions for all\\nthe studied pseudorapidity intervals. the data are compared to models and\\nanalysed quantitatively, evaluating the first four moments (mean, standard\\ndeviation, skewness, and kurtosis). the shape evolution of the measured\\nmultiplicity distributions is studied in terms of kno variables and it is found\\nthat none of the considered models reproduces the measurements. this paper also\\nreports on the average charged-particle multiplicity, normalised by the average\\nnumber of participating nucleon pairs, as a function of the collision energy.\\nthe multiplicity results are then compared to measurements made in\\nproton-proton and nucleus-nucleus collisions across a wide range of collision\\nenergies.                  |\n",
      "|nucl-ex      |7.0       |[9.664699688769892E-5,7.814287518927054E-4,5.183915412272251E-4,5.352241853494628E-4,1.1437370403190357E-4,0.005491879674337921,9.444386009616073E-5,0.742313369242681,4.5137798394534744E-4,0.0015628705383819413,8.397901111312473E-5,0.0010720240057354963,2.1064558877264587E-4,3.597439914680985E-5,0.005985305317441021,1.183584697713923E-4,3.429969341881999E-4,3.6955036892995935E-4,0.0019969025726930766,8.524475117963802E-5,0.002990069378328206,2.1482566823798158E-4,3.2432760964142324E-4,3.4235770587757704E-4,6.600463126729657E-4,4.2894009965300964E-4,1.9774593564537388E-4,3.6580290582833246E-4,0.0023516555040228077,0.004773828663221232,5.73186280055753E-4,2.484214513468597E-4,0.0014262290480794968,1.6341692575177886E-4,0.0010810082979764435,7.708190896399132E-4,6.9088648328371E-5,5.468584079611923E-4,3.102809719212562E-4,3.2705444500155743E-4,1.0237802441345859E-4,1.2083424984855791E-4,5.614431163561105E-4,7.821071639887816E-4,5.658899813863557E-4,4.5308089723715856E-4,2.3004463513336498E-4,2.449230132176897E-4,0.0013295146944298623,6.551806525980295E-4,0.10633219942022548,1.6058767291687162E-4,8.695404032309124E-5,0.02782388278958853,1.0125117717558547E-4,4.890618381641997E-4,1.5217223203221964E-4,0.009999600410383823,2.044080197153198E-4,2.178354432699956E-4,2.729728544296819E-4,6.093146233995378E-4,5.105840475513819E-4,2.3223805773813663E-4,3.136109414691611E-4,5.842079376046768E-4,1.7891767983908925E-4,6.291985782354324E-5,7.854368138951657E-4,0.002201138437490107,1.9725259057572198E-4,2.2874107237400403E-4,3.480203771677884E-4,1.124013759883542E-4,9.119646055980679E-5,0.0014800615892976519,2.9555831522455472E-5,1.1589015973095362E-4,8.630590093566098E-4,2.5912730829067446E-4,1.9231589001351103E-4,2.1780768285791644E-4,1.310611364312112E-4,1.5945864702797866E-4,9.244501121529388E-5,7.445179478854585E-5,1.1345701795044766E-4,1.1543102083279739E-4,1.1578254521943031E-4,2.6980104742757355E-4,1.7032129888495723E-4,1.149763007052863E-4,9.73680783938523E-5,1.1919448370927504E-4,4.924446834104079E-4,4.499451692277676E-5,2.362021724773011E-4,0.05349685571021416,2.4475301465353615E-4,9.790236212741692E-5,2.6426128614658085E-5,1.123570300970354E-4,2.2003992539345593E-4,6.508496000429194E-5,1.2269894808253587E-4,1.1178360264415143E-4,1.2985941648055284E-4,1.0835256054794332E-4,3.0624020607813497E-4,4.205363413975117E-5,6.904460595046316E-5,5.769439663120876E-5,1.6417218433869933E-4,1.012326782681855E-4,2.9289310527613894E-5,1.3746727068320323E-4,6.401504575813769E-5,6.602056661636011E-5,3.68791686987992E-5,2.9202908822229156E-5,2.5527780742948812E-5,4.40330195122741E-5,6.998038123632876E-5,1.1610277757538552E-4,4.5110083933441794E-5,2.7786148400811345E-5,4.027329825441045E-5,2.5551422403892757E-5,2.8154267439066845E-5,4.818683732772995E-5,5.570955280399328E-5,3.342926088744817E-5,1.7614252813581052E-5,3.6789652619492284E-5,2.5065199959813804E-5,2.5688380995743955E-5,2.1506164905260447E-5,4.904736257957104E-5,2.148410812049376E-5,2.6836000546589214E-5,1.7453394243305713E-5,1.2132750573066937E-5,1.577017497797237E-5,1.3757278724994144E-5,1.285243876420301E-5,8.975685698539737E-6,6.725373953619403E-6,5.454014225559004E-6,4.151389804027592E-6,4.964836831150533E-6]|measurement of correlations among net-charge, net-proton, and net-kaon\\n  multiplicity distributions in pb-pb collisions at $\\sqrt{s_\\text{nn}}=5.02$\\n  tev correlations among conserved quantum numbers, such as the net-electric\\ncharge, the net-baryon, and the net-strangeness in heavy-ion collisions, are\\ncrucial for exploring the qcd phase diagram. in this letter, these correlations\\nare investigated using net-proton number (as a proxy for the net-baryon),\\nnet-kaon number (for the net-strangeness), and net-charged particle number in\\npb-pb collisions at $\\sqrt{s_\\text{nn}}=5.02$ tev with the alice detector. the\\nobserved correlations deviate from the poissonian baseline, with a more\\npronounced deviation at lhc energies than at rhic. theoretical calculations of\\nthe thermal-fist hadron resonance gas model, hijing, and epos lhc event\\ngenerators are compared with experimental results, where a significant impact\\nof resonance decays is observed. thermal-fist calculations under the grand\\ncanonical and canonical ensembles highlight significant differences,\\nunderscoring the role of local charge conservation in explaining the data.\\nrecent lattice qcd studies have demonstrated that the magnetic field generated\\nby spectator protons in heavy-ion collisions affects susceptibility ratios, in\\nparticular those related to the net-electric charge and the net-baryon numbers.\\nthe experimental findings are in qualitative agreement with the expectations of\\nlattice qcd.|\n",
      "|hep-ex       |7.0       |[2.972433611984822E-4,0.003265414941694318,2.4765235524301237E-4,0.02387162130088591,0.001285090460333372,0.0027608262194712147,5.623849014475859E-4,0.5221519961301935,0.0016931720089451694,0.0017252343316110394,0.0010910876980347042,2.9065856395294094E-4,0.002812954387866067,9.003320514377546E-4,9.281724203290007E-4,7.358909781789972E-4,4.7740497292525215E-4,0.004564902650278061,0.004315615226558738,0.001202918841747933,0.0016505265492883297,0.004772819310633685,7.145254277959765E-4,3.4629590020390197E-4,7.800357432508252E-4,9.220509365549797E-4,0.0013768642347965748,7.88085413952293E-4,0.0013661825929313848,0.0012689022609417525,9.745950242188491E-4,0.0016276930280692261,6.494899094719966E-4,3.4904474736797286E-4,6.855538050490699E-4,7.194911559011018E-4,6.446357804782485E-4,0.0011590970230733412,4.290976243480056E-4,5.975294111154086E-4,6.697252128939919E-4,3.6675853211727354E-4,0.0014244175238072793,0.0011133141565342491,5.837386533264793E-4,0.001109300701538055,9.697211458659972E-4,5.127576024983563E-4,0.010182021527080067,0.0018477271439357036,0.021604761085445092,4.169484510498282E-4,4.5156114092808827E-4,0.3050605540282378,2.94717335658125E-4,2.630014022985767E-4,5.192346984789248E-4,0.012696152013772371,4.051054328829737E-4,2.5428388742249086E-4,2.0862706065147133E-4,3.7779808351824743E-4,7.368920722338897E-4,4.2641923265841183E-4,3.1186797297506777E-4,1.5253667193054746E-4,2.356866103932331E-4,3.0877912197354115E-4,3.062996192149567E-4,5.780323288569896E-4,4.6448416399445504E-4,3.2487700825788336E-4,1.5718000911327788E-4,1.4845012012834754E-4,1.840069113298263E-4,0.0041680485851958455,9.551081964205248E-5,4.448152562582457E-4,0.0020696172722188613,3.31194176356497E-4,1.765427751306343E-4,2.966756863020288E-4,1.6735852105988019E-4,5.179602163131872E-4,5.897069589204908E-4,1.6671311683014595E-4,1.7226283507784112E-4,2.0752870764307032E-4,1.9272967651389467E-4,1.6052104891390773E-4,2.740505304444697E-4,2.2741576718880567E-4,2.185903883397003E-4,1.6645075170148457E-4,2.7149746647746933E-4,8.332819092381437E-5,2.3719239909607685E-4,0.021398121553001807,1.1381370821963333E-4,2.451289315707769E-4,1.8429321721025437E-4,1.7970175307854507E-4,3.048810458925837E-4,1.0257901901765627E-4,1.9188431099317703E-4,1.1763290318115868E-4,1.4352579065089621E-4,2.9853166625006547E-4,9.586676797679607E-5,1.7146686287833004E-4,1.379262368261908E-4,1.1024722069105646E-4,1.2281350671845698E-4,1.2129615394233482E-4,5.988573777482674E-5,1.833182453438194E-4,1.225372902960264E-4,6.914285239107409E-5,9.708583587242096E-5,5.892179334287845E-5,1.0889902331474128E-4,7.039897040367418E-5,9.010569124953516E-5,9.220909708101496E-5,4.947385724637226E-5,5.350196377608687E-5,6.732035219075032E-5,6.399104542555885E-5,7.019160392902131E-5,7.659966162199884E-5,1.1727249573472603E-4,8.13593754740725E-5,4.9857622998497965E-5,3.8228552525757976E-5,4.139900401338601E-5,5.044627477688681E-5,4.008575956206056E-5,6.32746219568108E-5,3.2694998508386165E-5,2.9698078771331034E-5,2.8416790036571174E-5,2.7422113569725272E-5,2.265455317972279E-5,2.9391704966609143E-5,1.61795844255429E-5,1.52738060166328E-5,1.1718417520663051E-5,9.571675356742308E-6,7.5847017577814556E-6,7.636708162095361E-6]    |measurement of jet track functions in $pp$ collisions at $\\sqrt{s}=13$\\n  tev with the atlas detector measurements of jet substructure are key to probing the energy frontier at\\ncolliders, and many of them use track-based observables which take advantage of\\nthe angular precision of tracking detectors. theoretical calculations of\\ntrack-based observables require `track functions', which characterize the\\ntransverse momentum fraction $r_q$ carried by charged hadrons from a\\nfragmenting quark or gluon. this letter presents a direct measurement of $r_q$\\ndistributions in dijet events from the 140 fb$^{-1}$ of proton-proton\\ncollisions at $\\sqrt{s}=13$ tev recorded with the atlas detector. the data are\\ncorrected for detector effects using machine-learning methods. the scale\\nevolution of the moments of the $r_q$ distribution is sensitive to non-linear\\nrenormalization group evolution equations of qcd, and is compared with analytic\\npredictions. when incorporated into future theoretical calculations, these\\nresults will enable a precision program of theory-data comparison for\\ntrack-based jet substructure observables.                                                                                                                                                                                                                                                                                                                                                                |\n",
      "|hep-ex       |53.0      |[1.1182928273152458E-4,1.1934580318702456E-4,1.166102755031954E-4,4.0437654323596177E-4,2.9093372138109408E-5,4.259909788132619E-5,3.2013646614486467E-6,0.2510878582460272,1.9483725205187622E-5,1.1288987410978706E-4,3.8574837201004044E-4,7.365780038823724E-5,4.900146403998212E-5,5.380961083719076E-5,9.45441568925694E-5,7.822746387101783E-5,1.0199944589666446E-5,7.224969275566949E-4,8.969151223721114E-4,1.987999428034265E-5,3.788381425643361E-5,2.3962512352137763E-4,4.343128066450344E-5,4.473868313326344E-5,2.1241711710984969E-4,3.327037679443617E-5,5.5274923804466E-4,6.0917588974507606E-5,3.683015693609073E-5,2.347662084769148E-5,6.9318117367834E-5,1.2484445791834356E-4,2.4008083801213918E-5,1.254339251914248E-5,3.842114245610973E-5,6.423472669138043E-5,1.3904109585275449E-5,7.48149097093233E-5,6.753922598437338E-5,1.6364081764881047E-5,1.3644511586937394E-5,8.721395810283045E-5,2.8791648559520636E-5,4.1207818980652244E-5,4.113153511934107E-5,2.3441480287979355E-5,1.7584640936696965E-5,2.290404335951111E-5,0.00110200649081485,3.356749807265722E-5,0.0014234849542050425,2.4972195253496433E-5,7.407555065949816E-6,0.7375362411417639,2.4227574587530618E-5,8.736959487143274E-6,2.647549306860867E-5,8.519282518675395E-4,4.422774500173132E-5,9.014853817973168E-6,6.560101123807306E-6,2.7070007603098855E-5,5.125354743702296E-5,3.228199712794735E-5,4.9457375939594455E-5,1.1826931767046432E-5,4.557996449607516E-5,5.084767071419159E-6,5.026506460060142E-5,3.0991483533145674E-5,1.2355346070579248E-5,3.0840302932832833E-5,1.3083555338648737E-5,6.907206624971597E-6,4.903944479613344E-6,1.0991053284351016E-4,3.4505157524297263E-6,4.030561907487061E-5,3.122599684617655E-5,3.8621684249597665E-5,1.139032589586449E-5,7.320547120816964E-5,8.345465101742783E-6,5.823844872889736E-5,9.06494864916147E-6,4.902685989162536E-6,9.916270100993998E-6,3.4510174886657646E-5,1.5334196926478324E-5,2.365164832213298E-5,4.984545783839741E-6,1.9834337721298667E-5,4.00544058067442E-5,1.2724069916494415E-5,3.1931375952325826E-5,3.912930863750431E-6,1.2938750999772075E-5,0.0011315837037504074,7.396400145671072E-6,1.3879625062437455E-5,3.4082303967123335E-6,1.4227693517440639E-5,1.470789544024075E-5,5.266454504687433E-6,1.659833919983337E-5,5.979485325324707E-6,9.232099627957457E-6,2.0423125713609764E-5,1.185915966494121E-5,1.1345243633676453E-5,1.0658419032617028E-5,8.014199420873068E-6,1.619241175364101E-5,8.659918754647222E-6,3.1105174330867435E-6,8.007075390509228E-6,4.636501550551639E-6,3.8363866015801085E-6,5.918491023263296E-6,2.8971618936108866E-6,3.3205674207800767E-6,4.829981386451172E-6,7.475037705117696E-6,9.720628585907997E-6,2.8424850015428524E-6,3.397882050203699E-6,4.862780974517637E-6,3.555488649513477E-6,3.831073448860283E-6,4.0201293764195385E-6,9.479580257395239E-6,3.503843065093894E-6,3.2878918652973364E-6,2.6982769106797985E-6,2.369200800445837E-6,2.4326639548550636E-6,2.3950611696625837E-6,2.5186242434447955E-6,3.1498218543935647E-6,2.050306667519053E-6,1.5965514201642037E-6,3.032782804674585E-6,1.2734193437278356E-6,1.6897231000798833E-6,1.077505567239539E-6,1.1492032544316756E-6,7.190176171136685E-7,7.349637858181801E-7,4.414071742260808E-7,4.785244016478375E-7]        |measurement of the top quark mass with the atlas detector using\\n  $t\\bar{t}$ events with a high transverse momentum top quark the mass of the top quark is measured using top-antitop-quark pair events\\nwith high transverse momentum top quarks. the dataset, collected with the atlas\\ndetector in proton--proton collisions at $\\sqrt{s}=13$ tev delivered by the\\nlarge hadron collider, corresponds to an integrated luminosity of 140\\nfb$^{-1}$. the analysis targets events in the lepton-plus-jets decay channel,\\nwith an electron or muon from a semi-leptonically decaying top quark and a\\nhadronically decaying top quark that is sufficiently energetic to be\\nreconstructed as a single large-radius jet. the mean of the invariant mass of\\nthe reconstructed large-radius jet provides the sensitivity to the top quark\\nmass and is simultaneously fitted with two additional observables to reduce the\\nimpact of the systematic uncertainties. the top quark mass is measured to be\\n$m_t = 172.95 \\pm 0.53$ gev, which is the most precise atlas measurement from a\\nsingle channel.                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "|hep-ex       |53.0      |[5.350124202454609E-6,2.2516103042002368E-6,2.550061705609411E-6,2.686471418898564E-4,1.2446273211541236E-4,9.15714985692369E-5,1.7958106632225482E-6,0.04760750930703463,4.393183519177959E-6,2.6275899623915606E-5,1.7363625259702398E-5,3.7546543414218322E-6,7.382364741022314E-6,3.0199597156504497E-6,2.1964641793964885E-5,1.7281262004451217E-6,5.136462442563712E-7,1.390067742500301E-5,1.559540319464967E-4,1.2064721095819793E-6,1.4411956155646122E-5,7.591652876577362E-6,4.139818535316688E-6,4.0597383790925876E-7,1.1240119299039364E-5,4.818574422573195E-6,1.8987315099410746E-5,1.6536551473120355E-6,4.714864343176634E-6,2.4795968344751747E-5,1.536305867881501E-5,7.77466863874748E-6,7.576994655295439E-6,2.3834575269314372E-6,7.793335427457016E-6,1.9749936695275067E-6,1.2172795361788257E-6,8.459694325108633E-6,4.746142409420885E-6,3.344530548830461E-6,5.507684400117634E-6,9.829365336082725E-6,2.089038029430176E-6,1.231656334889242E-5,4.798301317238935E-6,4.025635834946704E-6,2.520326821578996E-6,9.864152280309516E-7,3.278083271926016E-5,2.3999638214239652E-6,3.5297393070824456E-5,1.3127637734411175E-6,6.771838803617548E-7,0.9503518471938319,5.587475807076379E-6,2.921196880313338E-6,3.361946337802907E-6,8.624936606807389E-4,3.238255205829256E-6,1.2601421729026255E-6,1.9385901081704417E-6,1.6059417640782377E-6,6.507600706006258E-6,2.7717433739339556E-6,3.7941390902059984E-6,6.786836523389316E-7,4.173807777035419E-6,8.092816242544776E-7,1.5774644074987865E-6,1.8621328615304385E-6,3.726235839094755E-6,2.896399940313271E-6,1.4847225317385573E-6,4.3886510037321216E-7,1.7684393604912767E-6,8.666147602190439E-6,3.3831460927570335E-7,2.4303234066219795E-6,1.6996514905354189E-6,2.2614192269145213E-6,9.848054872844629E-7,6.239720818223471E-6,2.088088469775773E-6,1.9523538040264904E-6,1.3047611284388124E-6,1.9188593135089606E-6,4.893799871904854E-6,3.2049576891468712E-6,8.222308908332789E-7,1.1811280932499873E-6,1.1682027848928634E-6,1.7304341549322131E-6,1.4878608844046293E-6,8.719341672618089E-7,1.445679032549572E-6,3.952994759076127E-7,2.417755626091768E-6,2.6543624869513703E-5,8.443920426865652E-7,2.183329507931193E-6,4.637195283255163E-7,1.2811703294129361E-6,1.9203300327416986E-6,4.763768968164137E-7,1.0814314386926032E-6,3.687637360994643E-7,1.0647153219493098E-6,6.492432994376519E-7,3.6998647711975915E-7,6.257127198186967E-7,5.460311934223522E-7,4.7411350494927195E-7,8.877128461120829E-7,6.058577387328225E-7,3.421970965797175E-7,9.151483432687844E-7,8.151580388938995E-7,4.866461694347366E-7,1.2061869968248748E-6,3.007193720648453E-7,8.329388514352456E-7,5.475609977683384E-7,4.214275113211223E-7,5.555572216819796E-7,3.107396487418636E-7,3.3972257349252715E-7,4.7338385499177094E-7,3.584262935192909E-7,6.137857582594153E-7,5.306108531502727E-7,5.057388462654636E-7,3.37656782573835E-7,2.583375340012651E-7,4.244544115564456E-7,1.997585757493833E-7,2.620820394515975E-7,2.7820893578354185E-7,3.694350793764168E-7,2.949121892280421E-7,7.691543804063628E-7,1.9341428788454348E-7,1.3103970563764161E-7,1.2885335843419914E-7,1.945477915245155E-7,1.008842173120756E-7,9.093387547634242E-8,7.788660731582884E-8,7.272568282080868E-8,4.645509543310732E-8,4.806199234765912E-8]      |search for a new pseudoscalar decaying into a pair of bottom and\\n  antibottom quarks in top-associated production in $\\sqrt{s}$=13 tev\\n  proton-proton collisions with the atlas detector a search for a pseudoscalar $a$ produced in association with a top-quark\\npair, or in association with a single top quark plus a $w$ boson, with the\\npseudoscalar decaying into $b$-quarks ($a\\rightarrow b\\bar{b}$), is performed\\nusing the full run 2 data sample using a dileptonic decay mode signature. the\\nsearch covers pseudoscalar boson masses between 12-100 gev and involves both\\nthe kinematic regime where the decay products of the pseudoscalar are\\nreconstructed as two standard $b$-tagged small-radius jets, or merged into a\\nlarge-radius jet due to its lorentz boost. no significant excess relative to\\nexpectations is observed. assuming a branching ratio br($a\\rightarrow\\nb\\bar{b}$)=100%, the range of pseudoscalar masses between 50 and 80 gev is\\nexcluded at 95% confidence level for a coupling of the pseudoscalar to the top\\nquark of 0.5, while a coupling of 1.0 is excluded at 95% confidence level for\\nthe masses considered, with the coupling defined as the strength modifier of\\nthe standard model yukawa coupling.                                                                                                                                                                                                                                                                       |\n",
      "+-------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"main_category\", \"prediction\", \"probability\", \"text\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df4e5a5f-5eb5-4ebb-bff0-9dbcc9f1933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|main_category|predicted_category|probability                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "+-------------+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|nucl-ex      |nucl-ex           |[3.395263818761074E-4,0.002810217203557092,1.5892907633857008E-4,0.0015168003948570095,0.0024382592323579436,0.0012231519737437692,1.420541627627325E-4,0.17517136827317162,0.0012027212891046063,0.0031415926308735777,0.0033614803509195985,8.492309408926863E-5,4.3138836742136243E-4,1.849585451471538E-4,5.643408396174271E-4,1.1136077054837739E-4,2.2450981954557587E-4,4.808292855627593E-4,0.002567078901712362,6.414447224933613E-4,2.498102648960191E-4,0.0014718013063113997,4.155583391973147E-4,1.1805774775925997E-4,8.711027144278449E-4,5.939482802906768E-4,0.0059126307329233265,0.0010437727885910756,2.889634313243771E-4,0.002299255158521643,9.927748789010508E-4,5.527357286989495E-4,5.979237970792474E-4,0.00323636855688038,0.0012285880760479317,0.0011292104537569474,0.0031405211486944516,0.0017428915372766519,4.74789903583313E-4,1.3910328369361205E-4,1.8589230929743258E-4,2.3690891860491908E-4,7.757135191124268E-4,5.863277217315133E-4,0.0017419838119363212,0.001625165374926326,5.380627714883713E-4,2.3912566558816967E-4,0.008148833053448795,9.27829889681226E-4,0.08414734035255111,1.1530102382999799E-4,2.0301159270801934E-4,0.17132268170090187,6.095232406748009E-4,3.1394111755896054E-4,0.0022344225353362703,7.013043017438247E-4,8.480801058485269E-4,9.548663226105151E-5,1.8265529575187543E-4,0.0010891757048106761,6.599567420948839E-4,5.077022982847E-4,3.7933694952806655E-4,1.4253071974063098E-4,1.994059149820258E-4,9.675246407241491E-5,2.288562950602385E-4,2.5799139816716206E-4,1.3266522458592144E-4,8.941852147555042E-5,3.585183098914236E-4,1.0255531358060516E-4,1.1491187499173233E-4,8.259118554781929E-4,9.944368873005427E-5,2.6475797759786807E-4,2.6864658207812343E-4,4.5770939131935083E-4,1.7038070223396876E-4,2.0113600655656083E-4,4.703220869482329E-5,2.271092825628657E-4,1.3792976582353953E-4,1.432651077911787E-4,1.4698907399761748E-4,1.7603117515605169E-4,2.577088086131044E-4,8.053298674697636E-5,9.338415174443383E-5,2.3574032043741701E-4,2.309635298858176E-4,2.1352109219349732E-4,2.0061370996198843E-4,7.329378048093489E-5,1.943891330486833E-4,0.4877576702105969,8.101199205902374E-5,3.5901812181157023E-4,1.609761327725093E-4,1.5859400845012663E-4,3.2453001600457035E-4,1.4271469833029493E-4,1.2352259235946672E-4,4.233595570964371E-5,2.021176789791706E-4,1.0586107920898744E-4,5.443116851279862E-5,1.6953433280244553E-4,7.495933777448479E-5,7.548602146392602E-5,1.5161268842205173E-4,8.088186472221433E-5,4.547154094963722E-5,3.131062502107585E-4,4.680453811271052E-5,7.573993782845593E-5,4.591155550395712E-5,4.9553392787436844E-5,3.717347310094634E-5,7.268208298627968E-5,7.983747327937323E-5,1.6430371637475558E-4,4.395838361552752E-5,5.9228213575013255E-5,5.312880933826185E-5,9.667392390914143E-5,5.22390167712271E-5,4.670903093269837E-5,3.3109949418349505E-5,3.7326511901764556E-5,4.774698927092008E-5,2.3103318124509688E-5,3.8983351530772776E-5,3.717596932790152E-5,2.4410278615544446E-5,5.781164842561616E-5,2.319495389928775E-5,2.7268879337476488E-5,2.1040513695929105E-5,1.5797713050363917E-5,1.895591926267444E-5,1.627901726922535E-5,1.1703010708736926E-5,9.05030716023629E-6,8.74984537272683E-6,6.774834559869117E-6,5.628460584582409E-6,5.5068472899857865E-6]     |\n",
      "|nucl-ex      |hep-ph            |[9.664699688769892E-5,7.814287518927054E-4,5.183915412272251E-4,5.352241853494628E-4,1.1437370403190357E-4,0.005491879674337921,9.444386009616073E-5,0.742313369242681,4.5137798394534744E-4,0.0015628705383819413,8.397901111312473E-5,0.0010720240057354963,2.1064558877264587E-4,3.597439914680985E-5,0.005985305317441021,1.183584697713923E-4,3.429969341881999E-4,3.6955036892995935E-4,0.0019969025726930766,8.524475117963802E-5,0.002990069378328206,2.1482566823798158E-4,3.2432760964142324E-4,3.4235770587757704E-4,6.600463126729657E-4,4.2894009965300964E-4,1.9774593564537388E-4,3.6580290582833246E-4,0.0023516555040228077,0.004773828663221232,5.73186280055753E-4,2.484214513468597E-4,0.0014262290480794968,1.6341692575177886E-4,0.0010810082979764435,7.708190896399132E-4,6.9088648328371E-5,5.468584079611923E-4,3.102809719212562E-4,3.2705444500155743E-4,1.0237802441345859E-4,1.2083424984855791E-4,5.614431163561105E-4,7.821071639887816E-4,5.658899813863557E-4,4.5308089723715856E-4,2.3004463513336498E-4,2.449230132176897E-4,0.0013295146944298623,6.551806525980295E-4,0.10633219942022548,1.6058767291687162E-4,8.695404032309124E-5,0.02782388278958853,1.0125117717558547E-4,4.890618381641997E-4,1.5217223203221964E-4,0.009999600410383823,2.044080197153198E-4,2.178354432699956E-4,2.729728544296819E-4,6.093146233995378E-4,5.105840475513819E-4,2.3223805773813663E-4,3.136109414691611E-4,5.842079376046768E-4,1.7891767983908925E-4,6.291985782354324E-5,7.854368138951657E-4,0.002201138437490107,1.9725259057572198E-4,2.2874107237400403E-4,3.480203771677884E-4,1.124013759883542E-4,9.119646055980679E-5,0.0014800615892976519,2.9555831522455472E-5,1.1589015973095362E-4,8.630590093566098E-4,2.5912730829067446E-4,1.9231589001351103E-4,2.1780768285791644E-4,1.310611364312112E-4,1.5945864702797866E-4,9.244501121529388E-5,7.445179478854585E-5,1.1345701795044766E-4,1.1543102083279739E-4,1.1578254521943031E-4,2.6980104742757355E-4,1.7032129888495723E-4,1.149763007052863E-4,9.73680783938523E-5,1.1919448370927504E-4,4.924446834104079E-4,4.499451692277676E-5,2.362021724773011E-4,0.05349685571021416,2.4475301465353615E-4,9.790236212741692E-5,2.6426128614658085E-5,1.123570300970354E-4,2.2003992539345593E-4,6.508496000429194E-5,1.2269894808253587E-4,1.1178360264415143E-4,1.2985941648055284E-4,1.0835256054794332E-4,3.0624020607813497E-4,4.205363413975117E-5,6.904460595046316E-5,5.769439663120876E-5,1.6417218433869933E-4,1.012326782681855E-4,2.9289310527613894E-5,1.3746727068320323E-4,6.401504575813769E-5,6.602056661636011E-5,3.68791686987992E-5,2.9202908822229156E-5,2.5527780742948812E-5,4.40330195122741E-5,6.998038123632876E-5,1.1610277757538552E-4,4.5110083933441794E-5,2.7786148400811345E-5,4.027329825441045E-5,2.5551422403892757E-5,2.8154267439066845E-5,4.818683732772995E-5,5.570955280399328E-5,3.342926088744817E-5,1.7614252813581052E-5,3.6789652619492284E-5,2.5065199959813804E-5,2.5688380995743955E-5,2.1506164905260447E-5,4.904736257957104E-5,2.148410812049376E-5,2.6836000546589214E-5,1.7453394243305713E-5,1.2132750573066937E-5,1.577017497797237E-5,1.3757278724994144E-5,1.285243876420301E-5,8.975685698539737E-6,6.725373953619403E-6,5.454014225559004E-6,4.151389804027592E-6,4.964836831150533E-6]|\n",
      "|hep-ex       |hep-ph            |[2.972433611984822E-4,0.003265414941694318,2.4765235524301237E-4,0.02387162130088591,0.001285090460333372,0.0027608262194712147,5.623849014475859E-4,0.5221519961301935,0.0016931720089451694,0.0017252343316110394,0.0010910876980347042,2.9065856395294094E-4,0.002812954387866067,9.003320514377546E-4,9.281724203290007E-4,7.358909781789972E-4,4.7740497292525215E-4,0.004564902650278061,0.004315615226558738,0.001202918841747933,0.0016505265492883297,0.004772819310633685,7.145254277959765E-4,3.4629590020390197E-4,7.800357432508252E-4,9.220509365549797E-4,0.0013768642347965748,7.88085413952293E-4,0.0013661825929313848,0.0012689022609417525,9.745950242188491E-4,0.0016276930280692261,6.494899094719966E-4,3.4904474736797286E-4,6.855538050490699E-4,7.194911559011018E-4,6.446357804782485E-4,0.0011590970230733412,4.290976243480056E-4,5.975294111154086E-4,6.697252128939919E-4,3.6675853211727354E-4,0.0014244175238072793,0.0011133141565342491,5.837386533264793E-4,0.001109300701538055,9.697211458659972E-4,5.127576024983563E-4,0.010182021527080067,0.0018477271439357036,0.021604761085445092,4.169484510498282E-4,4.5156114092808827E-4,0.3050605540282378,2.94717335658125E-4,2.630014022985767E-4,5.192346984789248E-4,0.012696152013772371,4.051054328829737E-4,2.5428388742249086E-4,2.0862706065147133E-4,3.7779808351824743E-4,7.368920722338897E-4,4.2641923265841183E-4,3.1186797297506777E-4,1.5253667193054746E-4,2.356866103932331E-4,3.0877912197354115E-4,3.062996192149567E-4,5.780323288569896E-4,4.6448416399445504E-4,3.2487700825788336E-4,1.5718000911327788E-4,1.4845012012834754E-4,1.840069113298263E-4,0.0041680485851958455,9.551081964205248E-5,4.448152562582457E-4,0.0020696172722188613,3.31194176356497E-4,1.765427751306343E-4,2.966756863020288E-4,1.6735852105988019E-4,5.179602163131872E-4,5.897069589204908E-4,1.6671311683014595E-4,1.7226283507784112E-4,2.0752870764307032E-4,1.9272967651389467E-4,1.6052104891390773E-4,2.740505304444697E-4,2.2741576718880567E-4,2.185903883397003E-4,1.6645075170148457E-4,2.7149746647746933E-4,8.332819092381437E-5,2.3719239909607685E-4,0.021398121553001807,1.1381370821963333E-4,2.451289315707769E-4,1.8429321721025437E-4,1.7970175307854507E-4,3.048810458925837E-4,1.0257901901765627E-4,1.9188431099317703E-4,1.1763290318115868E-4,1.4352579065089621E-4,2.9853166625006547E-4,9.586676797679607E-5,1.7146686287833004E-4,1.379262368261908E-4,1.1024722069105646E-4,1.2281350671845698E-4,1.2129615394233482E-4,5.988573777482674E-5,1.833182453438194E-4,1.225372902960264E-4,6.914285239107409E-5,9.708583587242096E-5,5.892179334287845E-5,1.0889902331474128E-4,7.039897040367418E-5,9.010569124953516E-5,9.220909708101496E-5,4.947385724637226E-5,5.350196377608687E-5,6.732035219075032E-5,6.399104542555885E-5,7.019160392902131E-5,7.659966162199884E-5,1.1727249573472603E-4,8.13593754740725E-5,4.9857622998497965E-5,3.8228552525757976E-5,4.139900401338601E-5,5.044627477688681E-5,4.008575956206056E-5,6.32746219568108E-5,3.2694998508386165E-5,2.9698078771331034E-5,2.8416790036571174E-5,2.7422113569725272E-5,2.265455317972279E-5,2.9391704966609143E-5,1.61795844255429E-5,1.52738060166328E-5,1.1718417520663051E-5,9.571675356742308E-6,7.5847017577814556E-6,7.636708162095361E-6]    |\n",
      "|hep-ex       |hep-ex            |[1.1182928273152458E-4,1.1934580318702456E-4,1.166102755031954E-4,4.0437654323596177E-4,2.9093372138109408E-5,4.259909788132619E-5,3.2013646614486467E-6,0.2510878582460272,1.9483725205187622E-5,1.1288987410978706E-4,3.8574837201004044E-4,7.365780038823724E-5,4.900146403998212E-5,5.380961083719076E-5,9.45441568925694E-5,7.822746387101783E-5,1.0199944589666446E-5,7.224969275566949E-4,8.969151223721114E-4,1.987999428034265E-5,3.788381425643361E-5,2.3962512352137763E-4,4.343128066450344E-5,4.473868313326344E-5,2.1241711710984969E-4,3.327037679443617E-5,5.5274923804466E-4,6.0917588974507606E-5,3.683015693609073E-5,2.347662084769148E-5,6.9318117367834E-5,1.2484445791834356E-4,2.4008083801213918E-5,1.254339251914248E-5,3.842114245610973E-5,6.423472669138043E-5,1.3904109585275449E-5,7.48149097093233E-5,6.753922598437338E-5,1.6364081764881047E-5,1.3644511586937394E-5,8.721395810283045E-5,2.8791648559520636E-5,4.1207818980652244E-5,4.113153511934107E-5,2.3441480287979355E-5,1.7584640936696965E-5,2.290404335951111E-5,0.00110200649081485,3.356749807265722E-5,0.0014234849542050425,2.4972195253496433E-5,7.407555065949816E-6,0.7375362411417639,2.4227574587530618E-5,8.736959487143274E-6,2.647549306860867E-5,8.519282518675395E-4,4.422774500173132E-5,9.014853817973168E-6,6.560101123807306E-6,2.7070007603098855E-5,5.125354743702296E-5,3.228199712794735E-5,4.9457375939594455E-5,1.1826931767046432E-5,4.557996449607516E-5,5.084767071419159E-6,5.026506460060142E-5,3.0991483533145674E-5,1.2355346070579248E-5,3.0840302932832833E-5,1.3083555338648737E-5,6.907206624971597E-6,4.903944479613344E-6,1.0991053284351016E-4,3.4505157524297263E-6,4.030561907487061E-5,3.122599684617655E-5,3.8621684249597665E-5,1.139032589586449E-5,7.320547120816964E-5,8.345465101742783E-6,5.823844872889736E-5,9.06494864916147E-6,4.902685989162536E-6,9.916270100993998E-6,3.4510174886657646E-5,1.5334196926478324E-5,2.365164832213298E-5,4.984545783839741E-6,1.9834337721298667E-5,4.00544058067442E-5,1.2724069916494415E-5,3.1931375952325826E-5,3.912930863750431E-6,1.2938750999772075E-5,0.0011315837037504074,7.396400145671072E-6,1.3879625062437455E-5,3.4082303967123335E-6,1.4227693517440639E-5,1.470789544024075E-5,5.266454504687433E-6,1.659833919983337E-5,5.979485325324707E-6,9.232099627957457E-6,2.0423125713609764E-5,1.185915966494121E-5,1.1345243633676453E-5,1.0658419032617028E-5,8.014199420873068E-6,1.619241175364101E-5,8.659918754647222E-6,3.1105174330867435E-6,8.007075390509228E-6,4.636501550551639E-6,3.8363866015801085E-6,5.918491023263296E-6,2.8971618936108866E-6,3.3205674207800767E-6,4.829981386451172E-6,7.475037705117696E-6,9.720628585907997E-6,2.8424850015428524E-6,3.397882050203699E-6,4.862780974517637E-6,3.555488649513477E-6,3.831073448860283E-6,4.0201293764195385E-6,9.479580257395239E-6,3.503843065093894E-6,3.2878918652973364E-6,2.6982769106797985E-6,2.369200800445837E-6,2.4326639548550636E-6,2.3950611696625837E-6,2.5186242434447955E-6,3.1498218543935647E-6,2.050306667519053E-6,1.5965514201642037E-6,3.032782804674585E-6,1.2734193437278356E-6,1.6897231000798833E-6,1.077505567239539E-6,1.1492032544316756E-6,7.190176171136685E-7,7.349637858181801E-7,4.414071742260808E-7,4.785244016478375E-7]        |\n",
      "|hep-ex       |hep-ex            |[5.350124202454609E-6,2.2516103042002368E-6,2.550061705609411E-6,2.686471418898564E-4,1.2446273211541236E-4,9.15714985692369E-5,1.7958106632225482E-6,0.04760750930703463,4.393183519177959E-6,2.6275899623915606E-5,1.7363625259702398E-5,3.7546543414218322E-6,7.382364741022314E-6,3.0199597156504497E-6,2.1964641793964885E-5,1.7281262004451217E-6,5.136462442563712E-7,1.390067742500301E-5,1.559540319464967E-4,1.2064721095819793E-6,1.4411956155646122E-5,7.591652876577362E-6,4.139818535316688E-6,4.0597383790925876E-7,1.1240119299039364E-5,4.818574422573195E-6,1.8987315099410746E-5,1.6536551473120355E-6,4.714864343176634E-6,2.4795968344751747E-5,1.536305867881501E-5,7.77466863874748E-6,7.576994655295439E-6,2.3834575269314372E-6,7.793335427457016E-6,1.9749936695275067E-6,1.2172795361788257E-6,8.459694325108633E-6,4.746142409420885E-6,3.344530548830461E-6,5.507684400117634E-6,9.829365336082725E-6,2.089038029430176E-6,1.231656334889242E-5,4.798301317238935E-6,4.025635834946704E-6,2.520326821578996E-6,9.864152280309516E-7,3.278083271926016E-5,2.3999638214239652E-6,3.5297393070824456E-5,1.3127637734411175E-6,6.771838803617548E-7,0.9503518471938319,5.587475807076379E-6,2.921196880313338E-6,3.361946337802907E-6,8.624936606807389E-4,3.238255205829256E-6,1.2601421729026255E-6,1.9385901081704417E-6,1.6059417640782377E-6,6.507600706006258E-6,2.7717433739339556E-6,3.7941390902059984E-6,6.786836523389316E-7,4.173807777035419E-6,8.092816242544776E-7,1.5774644074987865E-6,1.8621328615304385E-6,3.726235839094755E-6,2.896399940313271E-6,1.4847225317385573E-6,4.3886510037321216E-7,1.7684393604912767E-6,8.666147602190439E-6,3.3831460927570335E-7,2.4303234066219795E-6,1.6996514905354189E-6,2.2614192269145213E-6,9.848054872844629E-7,6.239720818223471E-6,2.088088469775773E-6,1.9523538040264904E-6,1.3047611284388124E-6,1.9188593135089606E-6,4.893799871904854E-6,3.2049576891468712E-6,8.222308908332789E-7,1.1811280932499873E-6,1.1682027848928634E-6,1.7304341549322131E-6,1.4878608844046293E-6,8.719341672618089E-7,1.445679032549572E-6,3.952994759076127E-7,2.417755626091768E-6,2.6543624869513703E-5,8.443920426865652E-7,2.183329507931193E-6,4.637195283255163E-7,1.2811703294129361E-6,1.9203300327416986E-6,4.763768968164137E-7,1.0814314386926032E-6,3.687637360994643E-7,1.0647153219493098E-6,6.492432994376519E-7,3.6998647711975915E-7,6.257127198186967E-7,5.460311934223522E-7,4.7411350494927195E-7,8.877128461120829E-7,6.058577387328225E-7,3.421970965797175E-7,9.151483432687844E-7,8.151580388938995E-7,4.866461694347366E-7,1.2061869968248748E-6,3.007193720648453E-7,8.329388514352456E-7,5.475609977683384E-7,4.214275113211223E-7,5.555572216819796E-7,3.107396487418636E-7,3.3972257349252715E-7,4.7338385499177094E-7,3.584262935192909E-7,6.137857582594153E-7,5.306108531502727E-7,5.057388462654636E-7,3.37656782573835E-7,2.583375340012651E-7,4.244544115564456E-7,1.997585757493833E-7,2.620820394515975E-7,2.7820893578354185E-7,3.694350793764168E-7,2.949121892280421E-7,7.691543804063628E-7,1.9341428788454348E-7,1.3103970563764161E-7,1.2885335843419914E-7,1.945477915245155E-7,1.008842173120756E-7,9.093387547634242E-8,7.788660731582884E-8,7.272568282080868E-8,4.645509543310732E-8,4.806199234765912E-8]      |\n",
      "+-------------+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import IndexToString\n",
    "\n",
    "# Get the fitted StringIndexerModel from the pipeline\n",
    "label_index_model = model.stages[4]  # Assuming indexer was 5th in your pipeline\n",
    "\n",
    "# Reverse the numeric prediction back to original label string\n",
    "label_reverse = IndexToString(\n",
    "    inputCol=\"prediction\",\n",
    "    outputCol=\"predicted_category\",\n",
    "    labels=label_index_model.labels\n",
    ")\n",
    "\n",
    "# Apply it\n",
    "predictions_labeled = label_reverse.transform(predictions)\n",
    "\n",
    "# View with readable category\n",
    "predictions_labeled.select(\"main_category\", \"predicted_category\", \"probability\").show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949e74f6-bd2f-42b0-82ec-4d518c5e0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:/Users/arthu/Desktop/spark/winutils\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a56b96",
   "metadata": {},
   "source": [
    "## 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ae07399-4df9-4e71-9d3a-a712ce57b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying improvements with random forest (sparse, not dense, as this crashes my session)\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import DenseVector, VectorUDT\n",
    "\n",
    "# Build minimal pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "stopwords = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "tf = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "label_indexer = StringIndexer(\n",
    "    inputCol=\"main_category\",\n",
    "    outputCol=\"label\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10, maxDepth=5)\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[tokenizer, stopwords, tf, idf, label_indexer, rf])\n",
    "\n",
    "# Fit the model\n",
    "model = pipeline_rf.fit(train_data)\n",
    "\n",
    "# Predict\n",
    "predictions_rf = model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f486f7b5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d76cb4-e1fe-4b2e-9f4f-35ffa372cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f021836-b723-40d7-bcf6-9cea4fb416b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy: 0.5969\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "acc_lr = evaluator.evaluate(predictions)\n",
    "print(f\"LogisticRegression accuracy: {acc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9331f060-f4db-4f85-bc1c-456c73846d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest accuracy: 0.1784\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "acc_rf = evaluator.evaluate(predictions_rf)\n",
    "print(f\"RandomForest accuracy: {acc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e30ab-231d-4618-9bde-b6e0c57f6126",
   "metadata": {},
   "source": [
    "## Random forest tuning with Cross Validation\n",
    "The poor performance of the Random Forest model is expected. TF-IDF produces high-dimensional sparse vectors, which are not ideal for tree-based models. We also used basic hyperparameters (10 trees, max depth of 5), as larger settings caused runtime issues. Additionally, we avoided dense vectorization due to memory constraints, which may further reduce the model's ability to make effective splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66cb8b5f-66c2-435f-be25-d64365d2fde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Random Forest accuracy (lite): 0.2225\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Slim grid for quick testing (my laptop cannot handle bigger)\n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "cv_rf = CrossValidator(\n",
    "    estimator=pipeline_rf,\n",
    "    estimatorParamMaps=paramGrid_rf,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=2  # use 2 instead of 3 for speed\n",
    ")\n",
    "\n",
    "# Fit the lighter model\n",
    "cv_model_rf = cv_rf.fit(train_data)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions_rf_tuned = cv_model_rf.transform(test_data)\n",
    "acc_rf_tuned = evaluator.evaluate(predictions_rf_tuned)\n",
    "print(f\"Tuned Random Forest accuracy (lite): {acc_rf_tuned:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144e585-e94f-4d3a-9c96-bc33370ad8e3",
   "metadata": {},
   "source": [
    "## Alternative feature representations\n",
    "Word2vec: works better than TF_IDF for random forest, but we also keep the latter for comparison in early analysis with logistic regression, where TF-IDF is better (more interpretable than Word2vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2bf465-40a4-4e6e-8d51-bb5de13d942a",
   "metadata": {},
   "source": [
    "### Word2Vec for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238bcfc1-71ed-4475-9afe-81aef956bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Word2Vec accuracy: 0.2888\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Updated feature extraction: Word2Vec instead of TF-IDF (again smaller sizes due to runtime)\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "stopwords = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "word2vec = Word2Vec(inputCol=\"filtered\", outputCol=\"features\", vectorSize=10, minCount=5)\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=\"main_category\", outputCol=\"label\", handleInvalid=\"keep\")\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10, maxDepth=5)\n",
    "\n",
    "pipeline_w2v_rf = Pipeline(stages=[tokenizer, stopwords, word2vec, label_indexer, rf])\n",
    "\n",
    "# Train\n",
    "model_w2v_rf = pipeline_w2v_rf.fit(train_data)\n",
    "\n",
    "# Predict\n",
    "predictions_w2v_rf = model_w2v_rf.transform(test_data)\n",
    "\n",
    "# Evaluate\n",
    "acc_w2v_rf = evaluator.evaluate(predictions_w2v_rf)\n",
    "print(f\"Random Forest with Word2Vec accuracy: {acc_w2v_rf:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5ec50-658e-4a34-b820-61cb273a6636",
   "metadata": {},
   "source": [
    "### word2vec for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "041a9638-07ac-4569-a168-400c736d1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Word2Vec accuracy: 0.5788\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, Word2Vec, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# --- 4. Evaluator ---\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "# --- 5. Word2Vec + Logistic Regression Pipeline ---\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "stopwords = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "word2vec = Word2Vec(inputCol=\"filtered\", outputCol=\"features\", vectorSize=100, minCount=5)\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=\"main_category\", outputCol=\"label\", handleInvalid=\"keep\")\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline_w2v_lr = Pipeline(stages=[tokenizer, stopwords, word2vec, label_indexer, lr])\n",
    "\n",
    "model_w2v_lr = pipeline_w2v_lr.fit(train_data)\n",
    "predictions_w2v_lr = model_w2v_lr.transform(test_data)\n",
    "\n",
    "acc_w2v_lr = evaluator.evaluate(predictions_w2v_lr)\n",
    "print(f\"Logistic Regression with Word2Vec accuracy: {acc_w2v_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d4628-5791-4018-85eb-17c38c542a24",
   "metadata": {},
   "source": [
    "# Small LLM: Bart Facebook on small number of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b70b8-cb92-465a-b3a9-b2d8600666ee",
   "metadata": {},
   "source": [
    "install transformers torch\n",
    "with pixi in terminal folder where pixi.toml is\n",
    "\n",
    "pixi add conda-forge::transformers conda-forge::pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce607661-af10-4098-b6d3-05db209e5612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hep-lat</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.2549302279949188, 0.24137187004089355, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>physics.optics</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.23048396408557892, 0.17416708171367645, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astro-ph.EP</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.20622789859771729, 0.1806761622428894, 0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>physics.comp-ph</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.29370442032814026, 0.11989302933216095, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>physics.atom-ph</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.20944005250930786, 0.17453129589557648, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cs.AR</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.30197227001190186, 0.18922507762908936, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cond-mat.quant-gas</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.22216995060443878, 0.12882345914840698, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>physics.acc-ph</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.21788351237773895, 0.1835835725069046, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>math.CV</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.16354073584079742, 0.15602795779705048, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>quant-ph</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>[0.3553391695022583, 0.12906913459300995, 0.11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 true predicted  \\\n",
       "0             hep-lat  quant-ph   \n",
       "1      physics.optics  quant-ph   \n",
       "2         astro-ph.EP  quant-ph   \n",
       "3     physics.comp-ph  quant-ph   \n",
       "4     physics.atom-ph  quant-ph   \n",
       "5               cs.AR  quant-ph   \n",
       "6  cond-mat.quant-gas  quant-ph   \n",
       "7      physics.acc-ph  quant-ph   \n",
       "8             math.CV  quant-ph   \n",
       "9            quant-ph  quant-ph   \n",
       "\n",
       "                                              scores  \n",
       "0  [0.2549302279949188, 0.24137187004089355, 0.14...  \n",
       "1  [0.23048396408557892, 0.17416708171367645, 0.1...  \n",
       "2  [0.20622789859771729, 0.1806761622428894, 0.16...  \n",
       "3  [0.29370442032814026, 0.11989302933216095, 0.1...  \n",
       "4  [0.20944005250930786, 0.17453129589557648, 0.1...  \n",
       "5  [0.30197227001190186, 0.18922507762908936, 0.1...  \n",
       "6  [0.22216995060443878, 0.12882345914840698, 0.1...  \n",
       "7  [0.21788351237773895, 0.1835835725069046, 0.12...  \n",
       "8  [0.16354073584079742, 0.15602795779705048, 0.1...  \n",
       "9  [0.3553391695022583, 0.12906913459300995, 0.11...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load the BART model for zero-shot classification\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Use your existing df with 'text' and 'main_category'\n",
    "sample_df = df.select(\"text\", \"main_category\").limit(10).toPandas()\n",
    "\n",
    "# Get distinct labels from your own data\n",
    "candidate_labels = sample_df[\"main_category\"].unique().tolist()\n",
    "\n",
    "# Run zero-shot classification\n",
    "results = []\n",
    "for _, row in sample_df.iterrows():\n",
    "    text = row[\"text\"][:1000]  # truncate to stay within model limits\n",
    "    true_label = row[\"main_category\"]\n",
    "\n",
    "    prediction = classifier(text, candidate_labels)\n",
    "    predicted_label = prediction[\"labels\"][0]\n",
    "\n",
    "    results.append({\n",
    "        \"true\": true_label,\n",
    "        \"predicted\": predicted_label,\n",
    "        \"scores\": prediction[\"scores\"]\n",
    "    })\n",
    "\n",
    "# Display result comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a01c32-c264-4a9c-aa43-ca2feb66771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot accuracy: 0.10\n"
     ]
    }
   ],
   "source": [
    "correct = results_df[\"true\"] == results_df[\"predicted\"]\n",
    "accuracy = correct.sum() / len(correct)\n",
    "print(f\"Zero-shot accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432bcd0-039a-45ce-8779-674afd6ceff3",
   "metadata": {},
   "source": [
    "Add in terminal: pixi add conda-forge::tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24bb6e3-89f5-43b7-8e43-7429dafc9e01",
   "metadata": {},
   "source": [
    "# Trying new approach for LLM: Fine tuning the LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41a1fa-e22a-455e-88f8-807459d418ba",
   "metadata": {},
   "source": [
    "run in terminal: pixi add conda-forge::accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3f3396-6423-423d-b305-bdece344d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Start with your Spark or Pandas dataframe\n",
    "df_pd = df.toPandas() if not isinstance(df, pd.DataFrame) else df.copy()\n",
    "\n",
    "# Step 1: Create input text and numerical labels\n",
    "df_pd[\"text\"] = df_pd[\"title\"] + \". \" + df_pd[\"summary\"]\n",
    "label2id = {label: i for i, label in enumerate(df_pd[\"main_category\"].unique())}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "df_pd[\"label\"] = df_pd[\"main_category\"].map(label2id)\n",
    "\n",
    "# Step 2: Convert to HuggingFace dataset\n",
    "dataset = Dataset.from_pandas(df_pd[[\"text\", \"label\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c6859-1e1b-40e9-8be8-30c87d35a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e320d2d90a4c2f97517245360f4d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49912 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d196d1ba146a4df3844eb075a21ddf49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12478 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\arthu\\AppData\\Local\\Temp\\ipykernel_8496\\1226223379.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='18717' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    7/18717 13:06 < 817:47:07, 0.01 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model_name = \"facebook/bart-base\"  # You can also use \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label2id))\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=None  # Add accuracy/F1 if needed\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2b26a-7abc-416e-bf08-c3a9d8ae5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(tokenized[\"test\"])\n",
    "pred_labels = [id2label[i] for i in preds.predictions.argmax(axis=1)]\n",
    "\n",
    "# Compare with true labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "true_labels = [id2label[i] for i in tokenized[\"test\"][\"label\"]]\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28166f2c-a1d9-4fda-86ad-478868e82025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n",
      "Device name: CPU only\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98804c00-c18a-45c7-8570-e0ef93cd40e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
