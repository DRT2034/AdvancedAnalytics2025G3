{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27913027-05f6-4aef-9712-66d9f0e8a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f724da-0c9e-4adb-97df-d12afaf9f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load all saved prediction files\n",
    "# This assumes you've saved them like: predictions_batch_2025-05-29_21-11-10.json\n",
    "files = glob.glob(\"predictions_batch_*.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1416ee-bef2-407d-bec8-00607bf10f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification Report ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       astro-ph.EP       1.00      1.00      1.00         1\n",
      "       astro-ph.GA       1.00      1.00      1.00         3\n",
      "       astro-ph.HE       0.75      0.75      0.75         4\n",
      "       astro-ph.SR       1.00      0.50      0.67         2\n",
      " cond-mat.mes-hall       0.33      0.50      0.40         2\n",
      " cond-mat.mtrl-sci       1.00      0.80      0.89         5\n",
      "     cond-mat.soft       1.00      1.00      1.00         2\n",
      "cond-mat.stat-mech       0.50      0.50      0.50         2\n",
      "   cond-mat.str-el       0.00      0.00      0.00         2\n",
      " cond-mat.supr-con       1.00      1.00      1.00         1\n",
      "             cs.AI       0.58      0.25      0.35        28\n",
      "             cs.AR       1.00      1.00      1.00         1\n",
      "             cs.CE       0.00      0.00      0.00         2\n",
      "             cs.CL       0.69      0.83      0.75        58\n",
      "             cs.CR       0.40      0.80      0.53         5\n",
      "             cs.CV       0.76      0.89      0.82        56\n",
      "             cs.CY       0.00      0.00      0.00         1\n",
      "             cs.DB       0.00      0.00      0.00         0\n",
      "             cs.DC       1.00      1.00      1.00         2\n",
      "             cs.DM       0.00      0.00      0.00         1\n",
      "             cs.GR       0.00      0.00      0.00         2\n",
      "             cs.GT       0.50      0.67      0.57         3\n",
      "             cs.HC       0.00      0.00      0.00         3\n",
      "             cs.IR       1.00      0.62      0.77         8\n",
      "             cs.IT       0.00      0.00      0.00         1\n",
      "             cs.LG       0.68      0.70      0.69        64\n",
      "             cs.LO       1.00      0.67      0.80         3\n",
      "             cs.MA       0.00      0.00      0.00         2\n",
      "             cs.NI       0.50      1.00      0.67         1\n",
      "             cs.RO       0.87      0.81      0.84        16\n",
      "             cs.SD       0.50      0.40      0.44        10\n",
      "             cs.SE       0.78      0.88      0.82         8\n",
      "             cs.SI       1.00      1.00      1.00         1\n",
      "           econ.GN       0.00      0.00      0.00         1\n",
      "           econ.TH       1.00      0.50      0.67         2\n",
      "           eess.AS       0.58      0.64      0.61        11\n",
      "           eess.IV       0.00      0.00      0.00         2\n",
      "           eess.SP       0.67      0.80      0.73         5\n",
      "           eess.SY       0.60      0.50      0.55         6\n",
      "             gr-qc       0.86      0.86      0.86         7\n",
      "            hep-ex       0.00      0.00      0.00         1\n",
      "           hep-lat       0.50      1.00      0.67         1\n",
      "            hep-ph       0.20      0.25      0.22         4\n",
      "            hep-th       0.25      0.50      0.33         2\n",
      "           math-ph       0.00      0.00      0.00         4\n",
      "           math.AG       0.67      0.67      0.67         3\n",
      "           math.AP       0.64      0.78      0.70         9\n",
      "           math.CA       0.00      0.00      0.00         2\n",
      "           math.CO       0.60      1.00      0.75         3\n",
      "           math.CT       0.00      0.00      0.00         1\n",
      "           math.CV       1.00      1.00      1.00         1\n",
      "           math.DG       0.00      0.00      0.00         1\n",
      "           math.DS       0.50      0.50      0.50         2\n",
      "           math.FA       0.50      1.00      0.67         1\n",
      "           math.GM       0.00      0.00      0.00         1\n",
      "           math.GN       1.00      1.00      1.00         1\n",
      "           math.GR       1.00      1.00      1.00         1\n",
      "           math.GT       1.00      1.00      1.00         1\n",
      "           math.LO       0.00      0.00      0.00         1\n",
      "           math.NA       0.60      0.50      0.55         6\n",
      "           math.NT       0.60      1.00      0.75         3\n",
      "           math.OA       1.00      1.00      1.00         1\n",
      "           math.OC       0.62      0.62      0.62         8\n",
      "           math.PR       0.50      1.00      0.67         3\n",
      "           math.RA       1.00      1.00      1.00         1\n",
      "           math.RT       1.00      0.67      0.80         3\n",
      "           math.ST       0.00      0.00      0.00         4\n",
      "           nlin.SI       0.00      0.00      0.00         1\n",
      "           nucl-ex       0.00      0.00      0.00         1\n",
      "           nucl-th       0.50      1.00      0.67         1\n",
      "     physics.ao-ph       0.00      0.00      0.00         0\n",
      "   physics.atom-ph       1.00      1.00      1.00         1\n",
      "    physics.bio-ph       0.00      0.00      0.00         0\n",
      "   physics.hist-ph       1.00      1.00      1.00         1\n",
      "   physics.ins-det       1.00      1.00      1.00         1\n",
      "    physics.med-ph       0.00      0.00      0.00         1\n",
      "    physics.optics       0.67      0.80      0.73         5\n",
      "  physics.plasm-ph       1.00      1.00      1.00         2\n",
      "          q-bio.CB       0.00      0.00      0.00         1\n",
      "          q-bio.NC       0.00      0.00      0.00         0\n",
      "          q-fin.TR       0.00      0.00      0.00         1\n",
      "          quant-ph       0.88      0.78      0.82         9\n",
      "           stat.AP       0.00      0.00      0.00         2\n",
      "           stat.ME       0.00      0.00      0.00         0\n",
      "           stat.ML       0.00      0.00      0.00         4\n",
      "\n",
      "          accuracy                           0.66       434\n",
      "         macro avg       0.49      0.52      0.49       434\n",
      "      weighted avg       0.64      0.66      0.64       434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Step 1: Find all batch output folders\n",
    "folders = glob.glob(\"predictions_batch_2025-*\")\n",
    "\n",
    "dfs = []\n",
    "for folder in folders:\n",
    "    # Look inside the folder for part-*.json files\n",
    "    json_parts = glob.glob(os.path.join(folder, \"part-*.json\"))\n",
    "    for part_file in json_parts:\n",
    "        try:\n",
    "            df = pd.read_json(part_file, lines=True)  # no lines=True because it's standard JSON\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {part_file}: {e}\")\n",
    "\n",
    "# Step 2: Combine and clean\n",
    "if dfs:\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df[\"true_label\"] = df[\"true_label\"].str.split(\",\").str[0]\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(\"\\n=== Classification Report ===\")\n",
    "    print(classification_report(df[\"true_label\"], df[\"pred\"]))\n",
    "else:\n",
    "    print(\"No valid data loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95ab19d-92d1-416f-8694-2a610f1483ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(df[\"true_label\"], df[\"pred\"], output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(\"evaluation_report.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb0ab2-7b08-488b-b701-74a9453ca421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
