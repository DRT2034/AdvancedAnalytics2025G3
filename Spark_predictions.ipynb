{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa3fc61-088a-4603-83bf-3c6e4af5f362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am using the following SPARK_HOME: C:\\Users\\arthu\\Desktop\\spark\\spark-3.5.5-bin-hadoop3\n",
      "Windows detected: set HADOOP_HOME to: C:\\Users\\arthu\\Desktop\\spark\\winutils\n",
      "  Also added Hadoop bin directory to PATH: C:\\Users\\arthu\\Desktop\\spark\\winutils\\bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "spark_home = os.path.abspath(os.getcwd() + \"/../spark-3.5.5-bin-hadoop3\")\n",
    "hadoop_home = os.path.abspath(os.getcwd() + \"/../winutils\")\n",
    "print(f\"I am using the following SPARK_HOME: {spark_home}\")\n",
    "if os.name == 'nt':\n",
    "    os.environ[\"HADOOP_HOME\"] = f\"{hadoop_home}\"\n",
    "    print(f\"Windows detected: set HADOOP_HOME to: {os.environ['HADOOP_HOME']}\")\n",
    "    hadoop_bin = os.path.join(hadoop_home, \"bin\")\n",
    "    os.environ[\"PATH\"] = f\"{hadoop_bin};{os.environ['PATH']}\"\n",
    "    print(f\"  Also added Hadoop bin directory to PATH: {hadoop_bin}\")\n",
    "\n",
    "import findspark\n",
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "findspark.init(spark_home)\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6144c95a-7494-436b-bbaf-88d180dfa6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81eecd3-bae3-4a8e-b855-c5d803cb6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fda849-3e4f-4aa0-b385-bf102518ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, col\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load models once\n",
    "globals()['models_loaded'] = False\n",
    "globals()['embedder'] = None\n",
    "globals()['clf'] = None\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        print(f\"[{time}] ‚Äî Empty batch.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n========= {str(time)} =========\")\n",
    "    try:\n",
    "        # Step 1: Read JSON from RDD\n",
    "        df = spark.read.json(rdd)\n",
    "\n",
    "        # Step 2: Clean missing title/summary\n",
    "        df = df.fillna({'title': '', 'summary': ''})\n",
    "\n",
    "        # Step 3: Combine into a single text column\n",
    "        df = df.withColumn(\"text\", concat_ws(\" \", col(\"title\"), col(\"summary\")))\n",
    "\n",
    "        # Step 4: Get text to predict\n",
    "        texts = [row[\"text\"] for row in df.select(\"text\").collect()]\n",
    "\n",
    "        # Step 5: Load models on first run only\n",
    "        if not globals()['models_loaded']:\n",
    "            model_path = \"C:/Users/arthu/Desktop/spark/notebooks/minilm_model\"\n",
    "            clf_path = \"C:/Users/arthu/Desktop/spark/notebooks/logreg_model.pkl\"\n",
    "            globals()['embedder'] = SentenceTransformer(model_path)\n",
    "            globals()['clf'] = joblib.load(clf_path)\n",
    "            globals()['models_loaded'] = True\n",
    "            print(\"‚úÖ Model and embedder loaded.\")\n",
    "\n",
    "        # Step 6: Predict\n",
    "        embeddings = globals()['embedder'].encode(texts)\n",
    "        predictions = globals()['clf'].predict(embeddings)\n",
    "\n",
    "        # Step 7: Assemble prediction DataFrame\n",
    "        pred_df = spark.createDataFrame(zip(texts, [str(p) for p in predictions]), [\"text\", \"pred\"])\n",
    "\n",
    "        # Step 8: Include true label (first category)\n",
    "        df = df.withColumnRenamed(\"categories\", \"true_label\")\n",
    "\n",
    "        # Step 9: Merge and show\n",
    "        result_df = df.join(pred_df, on=\"text\", how=\"left\")\n",
    "        result_df.select(\"aid\", \"text\", \"true_label\", \"pred\").show(truncate=False)\n",
    "\n",
    "        # Step 10: Save results to disk\n",
    "        timestamp = str(time).replace(\" \", \"_\").replace(\":\", \"-\")\n",
    "        output_path = f\"./predictions_batch_{timestamp}.json\"\n",
    "        result_df.select(\"aid\", \"text\", \"true_label\", \"pred\").write.json(output_path)\n",
    "        print(f\"üìÅ Saved predictions to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing batch: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e594650b-a547-4ea6-936d-5695e6fe7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test_json = json.dumps({\n",
    "    \"aid\": \"test123\",\n",
    "    \"title\": \"Deep learning in medicine\",\n",
    "    \"summary\": \"AI is being used to improve diagnostics and treatment accuracy.\",\n",
    "    \"categories\": [\"cs.AI\", \"stat.ML\"]\n",
    "})\n",
    "\n",
    "test_rdd = sc.parallelize([test_json])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d91c0c4-f38c-4189-94bb-bb88edda282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= test_run =========\n",
      "‚úÖ Model and embedder loaded.\n",
      "+-------+-----------------------------------------------------------------------------------------+----------------+-------+\n",
      "|aid    |text                                                                                     |true_label      |pred   |\n",
      "+-------+-----------------------------------------------------------------------------------------+----------------+-------+\n",
      "|test123|Deep learning in medicine AI is being used to improve diagnostics and treatment accuracy.|[cs.AI, stat.ML]|eess.IV|\n",
      "+-------+-----------------------------------------------------------------------------------------+----------------+-------+\n",
      "\n",
      "‚ùå Error processing batch: [PATH_ALREADY_EXISTS] Path file:/C:/Users/arthu/Desktop/spark/notebooks/predictions_batch_test_run.json already exists. Set mode as \"overwrite\" to overwrite the existing path.\n"
     ]
    }
   ],
   "source": [
    "process(\"test_run\", test_rdd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "647829fe-26d3-4c51-9333-be458388feb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arthu\\Desktop\\spark\\.pixi\\envs\\default\\Lib\\site-packages\\pyspark\\streaming\\context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= 2025-05-29 21:32:40 =========\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------+--------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |true_label                 |pred          |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------+--------------+\n",
      "|http://arxiv.org/abs/2505.19411v1|Split-as-a-Pro: behavioral control via operator splitting and\\n  alternating projections The paper introduces Split-as-a-Pro, a control framework that integrates\\nbehavioral systems theory, operator splitting methods, and alternating\\nprojection algorithms. The framework reduces dynamic optimization problems -\\narising in both control and estimation - to efficient projection computations.\\nSplit-as-a-Pro builds on a non-parametric formulation that exploits system\\nstructure to separate dynamic constraints imposed by individual subsystems from\\nexternal ones, such as interconnection constraints and input/output\\nconstraints. This enables the use of arbitrary system representations, as long\\nas the associated projection is efficiently computable, thereby enhancing\\nscalability and compatibility with gray-box modeling. We demonstrate the\\neffectiveness of Split-as-a-Pro by developing a distributed algorithm for\\nsolving finite-horizon linear quadratic control problems and illustrate its use\\nin predictive control. Our numerical case studies show that algorithms obtained\\nusing Split-as-a-Pro significantly outperform their centralized counterparts in\\nruntime and scalability across various standard graph topologies, while\\nseamlessly leveraging both model-based and data-driven system representations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |math.OC,cs.SY,eess.SY      |eess.SY       |\n",
      "|http://arxiv.org/abs/2505.19412v1|2d Cardy-Rabinovici model with the modified Villain lattice: Exact\\n  dualities and symmetries The Cardy-Rabinovici model is a toy model of the lattice $U(1)$ gauge\\ntheories to study various oblique confinement states associated with the\\nnonzero $\\theta$ angles. We reformulate the $2$d version of this model using\\nthe modified Villain lattice formalism, and we establish the exact $\\theta$\\nperiodicity for the Witten effect and the strong-weak duality at the finite\\nlattice spacings. We then study the phase structure of this model based on the\\nduality, symmetry and anomaly, and the perturbative renormalization group.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |hep-th,hep-lat             |hep-lat       |\n",
      "|http://arxiv.org/abs/2505.19413v1|Limit distributions for $\\text{SO}(n,1)$ action on $k$-lattices in\\n  $\\mathbb{R}^{n+1}$ We study the asymptotic distribution of norm ball averages along orbits of a\\nlattice $\\Gamma \\subset \\text{SO}(n,1)$ acting on the moduli space of pairs of\\northogonal discrete subgroups of $\\mathbb{R}^{n+1}$ up to homothety. Our main\\nresult shows that, except for special $2$-lattices in $\\mathbb{R}^3$ lying in\\nhyperplanes tangent to the light cone, these measures converge to an explicit\\nsemi-invariant probability measure supported on the space of homothety classes\\nof pairs of orthogonal lattices tangent to the light cone.\\n  Our main motivation is a conjecture of Sargent and Shapira, which is resolved\\nas a special case of our general result.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |math.DS                    |math.PR       |\n",
      "|http://arxiv.org/abs/2505.19414v1|Toward Physics-Informed Machine Learning for Data Center Operations: A\\n  Tropical Case Study Data centers are the backbone of computing capacity. Operating data centers\\nin the tropical regions faces unique challenges due to consistently high\\nambient temperature and elevated relative humidity throughout the year. These\\nconditions result in increased cooling costs to maintain the reliability of the\\ncomputing systems. While existing machine learning-based approaches have\\ndemonstrated potential to elevate operations to a more proactive and\\nintelligent level, their deployment remains dubious due to concerns about model\\nextrapolation capabilities and associated system safety issues. To address\\nthese concerns, this article proposes incorporating the physical\\ncharacteristics of data centers into traditional data-driven machine learning\\nsolutions. We begin by introducing the data center system, including the\\nrelevant multiphysics processes and the data-physics availability. Next, we\\noutline the associated modeling and optimization problems and propose an\\nintegrated, physics-informed machine learning system to address them. Using the\\nproposed system, we present relevant applications across varying levels of\\noperational intelligence. A case study on an industry-grade tropical data\\ncenter is provided to demonstrate the effectiveness of our approach. Finally,\\nwe discuss key challenges and highlight potential future directions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cs.AI,cs.LG                |cs.LG         |\n",
      "|http://arxiv.org/abs/2505.19415v1|MMIG-Bench: Towards Comprehensive and Explainable Evaluation of\\n  Multi-Modal Image Generation Models Recent multimodal image generators such as GPT-4o, Gemini 2.0 Flash, and\\nGemini 2.5 Pro excel at following complex instructions, editing images and\\nmaintaining concept consistency. However, they are still evaluated by disjoint\\ntoolkits: text-to-image (T2I) benchmarks that lacks multi-modal conditioning,\\nand customized image generation benchmarks that overlook compositional\\nsemantics and common knowledge. We propose MMIG-Bench, a comprehensive\\nMulti-Modal Image Generation Benchmark that unifies these tasks by pairing\\n4,850 richly annotated text prompts with 1,750 multi-view reference images\\nacross 380 subjects, spanning humans, animals, objects, and artistic styles.\\nMMIG-Bench is equipped with a three-level evaluation framework: (1) low-level\\nmetrics for visual artifacts and identity preservation of objects; (2) novel\\nAspect Matching Score (AMS): a VQA-based mid-level metric that delivers\\nfine-grained prompt-image alignment and shows strong correlation with human\\njudgments; and (3) high-level metrics for aesthetics and human preference.\\nUsing MMIG-Bench, we benchmark 17 state-of-the-art models, including Gemini 2.5\\nPro, FLUX, DreamBooth, and IP-Adapter, and validate our metrics with 32k human\\nratings, yielding in-depth insights into architecture and data design. We will\\nrelease the dataset and evaluation code to foster rigorous, unified evaluation\\nand accelerate future innovations in multi-modal image generation.                                                                                                                                                                                                                                                                                                                                                                                        |cs.CV                      |cs.CV         |\n",
      "|http://arxiv.org/abs/2505.19416v1|Quantitative analysis of cell size control mechanisms Cell size control is crucial for maintaining cellular function and\\nhomeostasis. In this study, we develop a first-order partial differential\\nequation model to examine the effects of three key size control mechanisms: the\\nsizer, timer, and adder. Each mechanism is incorporated into the model through\\ndistinct boundary conditions. Exact solutions for these mechanisms are derived\\nusing the method of characteristics, allowing us to explore how the\\nsteady-state size distribution depends on control parameters. Additionally,\\nindividual-cell-based stochastic simulations are performed to validate our\\ntheoretical findings and investigate the size distribution under various\\nconditions. This study provides new insights into the quantitative dynamics of\\ncell size regulation, highlighting the underlying mechanisms and laying the\\ngroundwork for future theoretical and experimental work on size homeostasis in\\nbiological systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |q-bio.CB                   |physics.bio-ph|\n",
      "|http://arxiv.org/abs/2505.19417v1|Irreducible cuspidal $\\mathfrak{sl}_{n+1}$-modules from\\n  finite-dimensional modules over the minimal nilpotent finite $W$-algebra A weight $\\mathfrak{sl}_{n+1}$-module with finite-dimensional weight spaces\\nis called a cuspidal module, if every root vector of $\\mathfrak{sl}_{n+1}$ acts\\ninjectively on it. In \\cite{LL}, it has been shown that any block with a\\ngeneralized central character of the cuspidal $\\mathfrak{sl}_{n+1}$-module\\ncategory is equivalent to a block of the category of finite-dimensional modules\\nover the minimal nilpotent finite $W$-algebra $W(e)$ for $\\mathfrak{sl}_{n+1}$.\\nIn this paper, using a centralizer realization of $W(e)$ and an explicit\\nembedding $W(e)\\rightarrow U(\\mathfrak{gl}_n)$, we show that every\\nfinite-dimensional irreducible $W(e)$-module is isomorphic to an irreducible\\n$W(e)$-quotient module of some finite-dimensional irreducible\\n$\\mathfrak{gl}_n$-module. As an application, we can give very explicit\\nrealizations of all irreducible cuspidal $\\mathfrak{sl}_{n+1}$-modules using\\nfinite-dimensional irreducible $\\mathfrak{gl}_n$-modules, avoiding using the\\ntwisted localization method and the coherent family introduced in \\cite{M}.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |math.RT,math.RA            |math.RT       |\n",
      "|http://arxiv.org/abs/2505.19418v1|Enhancing Test Efficiency through Automated ATPG-Aware Lightweight Scan\\n  Instrumentation Scan-based Design-for-Testability (DFT) measures are prevalent in modern\\ndigital integrated circuits to achieve high test quality at low hardware cost.\\nWith the advent of 3D heterogeneous integration and chiplet-based systems, the\\nrole of scan is becoming ever more important due to its ability to make\\ninternal design nodes controllable and observable in a systematic and scalable\\nmanner. However, the effectiveness of scan-based DFT suffers from poor\\ntestability of internal nodes for complex circuits at deep logic levels.\\nExisting solutions to address this problem primarily rely on Test Point\\nInsertion (TPI) in the nodes with poor controllability or observability.\\nHowever, TPI-based solutions, while an integral part of commercial practice,\\ncome at a high design and hardware cost. To address this issue, in this paper,\\nwe present LITE, a novel ATPG-aware lightweight scan instrumentation approach\\nthat utilizes the functional flip-flops in a scan chain to make multiple\\ninternal nodes observable and controllable in a low-cost, scalable manner. We\\nprovide both circuit-level design as well as an algorithmic approach for\\nautomating the insertion of LITE for design modifications. We show that LITE\\nsignificantly improves the testability in terms of the number of patterns and\\ntest coverage for ATPG and random pattern testability, respectively, while\\nincurring considerably lower overhead than TPI-based solutions.                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.AR,cs.ET                |cs.AR         |\n",
      "|http://arxiv.org/abs/2505.19419v1|It's Not Just Labeling\" -- A Research on LLM Generated Feedback\\n  Interpretability and Image Labeling Sketch Features The quality of training data is critical to the performance of machine\\nlearning applications in domains like transportation, healthcare, and robotics.\\nAccurate image labeling, however, often relies on time-consuming, expert-driven\\nmethods with limited feedback. This research introduces a sketch-based\\nannotation approach supported by large language models (LLMs) to reduce\\ntechnical barriers and enhance accessibility. Using a synthetic dataset, we\\nexamine how sketch recognition features relate to LLM feedback metrics, aiming\\nto improve the reliability and interpretability of LLM-assisted labeling. We\\nalso explore how prompting strategies and sketch variations influence feedback\\nquality. Our main contribution is a sketch-based virtual assistant that\\nsimplifies annotation for non-experts and advances LLM-driven labeling tools in\\nterms of scalability, accessibility, and explainability.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cs.HC,cs.AI                |cs.CV         |\n",
      "|http://arxiv.org/abs/2505.19420v1|ADD-SLAM: Adaptive Dynamic Dense SLAM with Gaussian Splatting Recent advancements in Neural Radiance Fields (NeRF) and 3D Gaussian-based\\nSimultaneous Localization and Mapping (SLAM) methods have demonstrated\\nexceptional localization precision and remarkable dense mapping performance.\\nHowever, dynamic objects introduce critical challenges by disrupting scene\\nconsistency, leading to tracking drift and mapping artifacts. Existing methods\\nthat employ semantic segmentation or object detection for dynamic\\nidentification and filtering typically rely on predefined categorical priors,\\nwhile discarding dynamic scene information crucial for robotic applications\\nsuch as dynamic obstacle avoidance and environmental interaction. To overcome\\nthese challenges, we propose ADD-SLAM: an Adaptive Dynamic Dense SLAM framework\\nbased on Gaussian splitting. We design an adaptive dynamic identification\\nmechanism grounded in scene consistency analysis, comparing geometric and\\ntextural discrepancies between real-time observations and historical maps. Ours\\nrequires no predefined semantic category priors and adaptively discovers scene\\ndynamics. Precise dynamic object recognition effectively mitigates interference\\nfrom moving targets during localization. Furthermore, we propose a\\ndynamic-static separation mapping strategy that constructs a temporal Gaussian\\nmodel to achieve online incremental dynamic modeling. Experiments conducted on\\nmultiple dynamic datasets demonstrate our method's flexible and accurate\\ndynamic segmentation capabilities, along with state-of-the-art performance in\\nboth localization and mapping.                                                                                                                                                                                                                                                                                                              |cs.CV                      |cs.RO         |\n",
      "|http://arxiv.org/abs/2505.19421v1|Certainty and Uncertainty Guided Active Domain Adaptation Active Domain Adaptation (ADA) adapts models to target domains by selectively\\nlabeling a few target samples. Existing ADA methods prioritize uncertain\\nsamples but overlook confident ones, which often match ground-truth. We find\\nthat incorporating confident predictions into the labeled set before active\\nsampling reduces the search space and improves adaptation. To address this, we\\npropose a collaborative framework that labels uncertain samples while treating\\nhighly confident predictions as ground truth. Our method combines Gaussian\\nProcess-based Active Sampling (GPAS) for identifying uncertain samples and\\nPseudo-Label-based Certain Sampling (PLCS) for confident ones, progressively\\nenhancing adaptation. PLCS refines the search space, and GPAS reduces the\\ndomain gap, boosting the proportion of confident samples. Extensive experiments\\non Office-Home and DomainNet show that our approach outperforms\\nstate-of-the-art ADA methods.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.CV                      |cs.LG         |\n",
      "|http://arxiv.org/abs/2505.19422v1|LlamaSeg: Image Segmentation via Autoregressive Mask Generation We present LlamaSeg, a visual autoregressive framework that unifies multiple\\nimage segmentation tasks via natural language instructions. We reformulate\\nimage segmentation as a visual generation problem, representing masks as\\n\"visual\" tokens and employing a LLaMA-style Transformer to predict them\\ndirectly from image inputs. By adhering to the next-token prediction paradigm,\\nour approach naturally integrates segmentation tasks into autoregressive\\narchitectures. To support large-scale training, we introduce a data annotation\\npipeline and construct the SA-OVRS dataset, which contains 2M segmentation\\nmasks annotated with over 5,800 open-vocabulary labels or diverse textual\\ndescriptions, covering a wide spectrum of real-world scenarios. This enables\\nour model to localize objects in images based on text prompts and to generate\\nfine-grained masks. To more accurately evaluate the quality of masks produced\\nby visual generative models, we further propose a composite metric that\\ncombines Intersection over Union (IoU) with Average Hausdorff Distance (AHD),\\noffering a more precise assessment of contour fidelity. Experimental results\\ndemonstrate that our method surpasses existing generative models across\\nmultiple datasets and yields more detailed segmentation masks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |cs.CV                      |cs.CV         |\n",
      "|http://arxiv.org/abs/2505.19423v1|Surrogate-Assisted Evolutionary Reinforcement Learning Based on\\n  Autoencoder and Hyperbolic Neural Network Evolutionary Reinforcement Learning (ERL), training the Reinforcement\\nLearning (RL) policies with Evolutionary Algorithms (EAs), have demonstrated\\nenhanced exploration capabilities and greater robustness than using traditional\\npolicy gradient. However, ERL suffers from the high computational costs and low\\nsearch efficiency, as EAs require evaluating numerous candidate policies with\\nexpensive simulations, many of which are ineffective and do not contribute\\nmeaningfully to the training. One intuitive way to reduce the ineffective\\nevaluations is to adopt the surrogates. Unfortunately, existing ERL policies\\nare often modeled as deep neural networks (DNNs) and thus naturally represented\\nas high-dimensional vectors containing millions of weights, which makes the\\nbuilding of effective surrogates for ERL policies extremely challenging. This\\npaper proposes a novel surrogate-assisted ERL that integrates Autoencoders (AE)\\nand Hyperbolic Neural Networks (HNN). Specifically, AE compresses\\nhigh-dimensional policies into low-dimensional representations while extracting\\nkey features as the inputs for the surrogate. HNN, functioning as a\\nclassification-based surrogate model, can learn complex nonlinear relationships\\nfrom sampled data and enable more accurate pre-selection of the sampled\\npolicies without real evaluations. The experiments on 10 Atari and 4 Mujoco\\ngames have verified that the proposed method outperforms previous approaches\\nsignificantly. The search trajectories guided by AE and HNN are also visually\\ndemonstrated to be more effective, in terms of both exploration and\\nconvergence. This paper not only presents the first learnable policy embedding\\nand surrogate-modeling modules for high-dimensional ERL policies, but also\\nempirically reveals when and why they can be successful.|cs.LG,cs.AI                |cs.LG         |\n",
      "|http://arxiv.org/abs/2505.19424v1|Matrix-product-state approach for qubits-waveguide systems in real space We present a matrix-product-state-based numerical approach for simulating\\nsystems composed of several qubits and a common one-dimensional waveguide. In\\nthe presented approach, the one-dimensional waveguide is modeled in real space.\\nThus, one can use the advantage of matrix-product states that are suited for\\nsimulating low-entangled one-dimensional systems. The price to pay is that the\\nvacuum of the waveguide in this modeling becomes the Bogoliubov vacuum, and one\\nhas to consider a not-so-small local Hilbert space for bosonic degrees of\\nfreedom. To manage the large local Hilbert space, we adopt the recently\\nproposed single-site schemes. We demonstrate the potential of the presented\\napproach by simulating superradiant phenomena within the Hamiltonian dynamics.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |quant-ph,cond-mat.stat-mech|quant-ph      |\n",
      "|http://arxiv.org/abs/2505.19425v1|Structure Disruption: Subverting Malicious Diffusion-Based Inpainting\\n  via Self-Attention Query Perturbation The rapid advancement of diffusion models has enhanced their image inpainting\\nand editing capabilities but also introduced significant societal risks.\\nAdversaries can exploit user images from social media to generate misleading or\\nharmful content. While adversarial perturbations can disrupt inpainting, global\\nperturbation-based methods fail in mask-guided editing tasks due to spatial\\nconstraints. To address these challenges, we propose Structure Disruption\\nAttack (SDA), a powerful protection framework for safeguarding sensitive image\\nregions against inpainting-based editing. Building upon the contour-focused\\nnature of self-attention mechanisms of diffusion models, SDA optimizes\\nperturbations by disrupting queries in self-attention during the initial\\ndenoising step to destroy the contour generation process. This targeted\\ninterference directly disrupts the structural generation capability of\\ndiffusion models, effectively preventing them from producing coherent images.\\nWe validate our motivation through visualization techniques and extensive\\nexperiments on public datasets, demonstrating that SDA achieves\\nstate-of-the-art (SOTA) protection performance while maintaining strong\\nrobustness.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |cs.CV,cs.CR,cs.LG          |cs.CV         |\n",
      "|http://arxiv.org/abs/2505.19426v1|The Role of Diversity in In-Context Learning for Large Language Models In-context learning (ICL) is a crucial capability of current large language\\nmodels (LLMs), where the selection of examples plays a key role in performance.\\nWhile most existing approaches focus on selecting the most similar examples to\\nthe query, the impact of diversity in example selection remains underexplored.\\nWe systematically investigate the role of diversity in in-context example\\nselection through experiments across a range of tasks, from sentiment\\nclassification to more challenging math and code problems. Experiments on\\nLlama-3.1, Gemma-2, and Mistral-v0.3 families of models show that\\ndiversity-aware selection methods improve performance, particularly on complex\\ntasks like math and code, and enhance robustness to out-of-distribution\\nqueries. To support these findings, we introduce a theoretical framework that\\nexplains the benefits of incorporating diversity in in-context example\\nselection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cs.CL,cs.AI,cs.LG          |cs.CL         |\n",
      "|http://arxiv.org/abs/2505.19427v1|WINA: Weight Informed Neuron Activation for Accelerating Large Language\\n  Model Inference The growing computational demands of large language models (LLMs) make\\nefficient inference and activation strategies increasingly critical. While\\nrecent approaches, such as Mixture-of-Experts (MoE), leverage selective\\nactivation but require specialized training, training-free sparse activation\\nmethods offer broader applicability and superior resource efficiency through\\ntheir plug-and-play design. However, many existing methods rely solely on\\nhidden state magnitudes to determine activation, resulting in high\\napproximation errors and suboptimal inference accuracy. To address these\\nlimitations, we propose WINA (Weight Informed Neuron Activation), a novel,\\nsimple, and training-free sparse activation framework that jointly considers\\nhidden state magnitudes and the column-wise $\\ell_2$-norms of weight matrices.\\nWe show that this leads to a sparsification strategy that obtains optimal\\napproximation error bounds with theoretical guarantees tighter than existing\\ntechniques. Empirically, WINA also outperforms state-of-the-art methods (e.g.,\\nTEAL) by up to $2.94\\%$ in average performance at the same sparsity levels,\\nacross a diverse set of LLM architectures and datasets. These results position\\nWINA as a new performance frontier for training-free sparse activation in LLM\\ninference, advancing training-free sparse activation methods and setting a\\nrobust baseline for efficient inference. The source code is available at\\nhttps://github.com/microsoft/wina.                                                                                                                                                                                                                                                                                                                                                                        |cs.LG,cs.AI                |cs.LG         |\n",
      "|http://arxiv.org/abs/2505.19428v1|Frictional Agent Alignment Framework: Slow Down and Don't Break Things AI support of collaborative interactions entails mediating potential\\nmisalignment between interlocutor beliefs. Common preference alignment methods\\nlike DPO excel in static settings, but struggle in dynamic collaborative tasks\\nwhere the explicit signals of interlocutor beliefs are sparse and skewed. We\\npropose the Frictional Agent Alignment Framework (FAAF), to generate precise,\\ncontext-aware \"friction\" that prompts for deliberation and re-examination of\\nexisting evidence. FAAF's two-player objective decouples from data skew: a\\nfrictive-state policy identifies belief misalignments, while an intervention\\npolicy crafts collaborator-preferred responses. We derive an analytical\\nsolution to this objective, enabling training a single policy via a simple\\nsupervised loss. Experiments on three benchmarks show FAAF outperforms\\ncompetitors in producing concise, interpretable friction and in OOD\\ngeneralization. By aligning LLMs to act as adaptive \"thought partners\" -- not\\npassive responders -- FAAF advances scalable, dynamic human-AI collaboration.\\nOur code and data can be found at https://github.com/csu-signal/FAAF_ACL.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.CL                      |cs.AI         |\n",
      "|http://arxiv.org/abs/2505.19429v1|Rhapsody: A Dataset for Highlight Detection in Podcasts Podcasts have become daily companions for half a billion users. Given the\\nenormous amount of podcast content available, highlights provide a valuable\\nsignal that helps viewers get the gist of an episode and decide if they want to\\ninvest in listening to it in its entirety. However, identifying highlights\\nautomatically is challenging due to the unstructured and long-form nature of\\nthe content. We introduce Rhapsody, a dataset of 13K podcast episodes paired\\nwith segment-level highlight scores derived from YouTube's 'most replayed'\\nfeature. We frame the podcast highlight detection as a segment-level binary\\nclassification task. We explore various baseline approaches, including\\nzero-shot prompting of language models and lightweight finetuned language\\nmodels using segment-level classification heads. Our experimental results\\nindicate that even state-of-the-art language models like GPT-4o and Gemini\\nstruggle with this task, while models finetuned with in-domain data\\nsignificantly outperform their zero-shot performance. The finetuned model\\nbenefits from leveraging both speech signal features and transcripts. These\\nfindings highlight the challenges for fine-grained information access in\\nlong-form spoken media.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CL                      |cs.CL         |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------+--------------+\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-32-40.json\n",
      "\n",
      "========= 2025-05-29 21:32:50 =========\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |true_label             |pred             |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------+\n",
      "|http://arxiv.org/abs/2505.19430v1|Deriving Strategic Market Insights with Large Language Models: A\\n  Benchmark for Forward Counterfactual Generation Counterfactual reasoning typically involves considering alternatives to\\nactual events. While often applied to understand past events, a distinct\\nform-forward counterfactual reasoning-focuses on anticipating plausible future\\ndevelopments. This type of reasoning is invaluable in dynamic financial\\nmarkets, where anticipating market developments can powerfully unveil potential\\nrisks and opportunities for stakeholders, guiding their decision-making.\\nHowever, performing this at scale is challenging due to the cognitive demands\\ninvolved, underscoring the need for automated solutions. Large Language Models\\n(LLMs) offer promise, but remain unexplored for this application. To address\\nthis gap, we introduce a novel benchmark, Fin-Force-FINancial FORward\\nCounterfactual Evaluation. By curating financial news headlines and providing\\nstructured evaluation, Fin-Force supports LLM based forward counterfactual\\ngeneration. This paves the way for scalable and automated solutions for\\nexploring and anticipating future market developments, thereby providing\\nstructured insights for decision-making. Through experiments on Fin-Force, we\\nevaluate state-of-the-art LLMs and counterfactual generation methods, analyzing\\ntheir limitations and proposing insights for future research.                                                                                                                                                                                                                                                                                                                                                                                                                      |cs.CL,cs.AI            |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19431v1|Importance Weighted Score Matching for Diffusion Samplers with Enhanced\\n  Mode Coverage Training neural samplers directly from unnormalized densities without access\\nto target distribution samples presents a significant challenge. A critical\\ndesideratum in these settings is achieving comprehensive mode coverage,\\nensuring the sampler captures the full diversity of the target distribution.\\nHowever, prevailing methods often circumvent the lack of target data by\\noptimizing reverse KL-based objectives. Such objectives inherently exhibit\\nmode-seeking behavior, potentially leading to incomplete representation of the\\nunderlying distribution. While alternative approaches strive for better mode\\ncoverage, they typically rely on implicit mechanisms like heuristics or\\niterative refinement. In this work, we propose a principled approach for\\ntraining diffusion-based samplers by directly targeting an objective analogous\\nto the forward KL divergence, which is conceptually known to encourage mode\\ncoverage. We introduce \\textit{Importance Weighted Score Matching}, a method\\nthat optimizes this desired mode-covering objective by re-weighting the score\\nmatching loss using tractable importance sampling estimates, thereby overcoming\\nthe absence of target distribution data. We also provide theoretical analysis\\nof the bias and variance for our proposed Monte Carlo estimator and the\\npractical loss function used in our method. Experiments on increasingly complex\\nmulti-modal distributions, including 2D Gaussian Mixture Models with up to 120\\nmodes and challenging particle systems with inherent symmetries -- demonstrate\\nthat our approach consistently outperforms existing neural samplers across all\\ndistributional distance metrics, achieving state-of-the-art results on all\\nbenchmarks.    |cs.LG                  |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19432v1|Advanced long-term earth system forecasting by learning the small-scale\\n  nature Reliable long-term forecast of Earth system dynamics is heavily hampered by\\ninstabilities in current AI models during extended autoregressive simulations.\\nThese failures often originate from inherent spectral bias, leading to\\ninadequate representation of critical high-frequency, small-scale processes and\\nsubsequent uncontrolled error amplification. We present Triton, an AI framework\\ndesigned to address this fundamental challenge. Inspired by increasing grids to\\nexplicitly resolve small scales in numerical models, Triton employs a\\nhierarchical architecture processing information across multiple resolutions to\\nmitigate spectral bias and explicitly model cross-scale dynamics. We\\ndemonstrate Triton's superior performance on challenging forecast tasks,\\nachieving stable year-long global temperature forecasts, skillful Kuroshio eddy\\npredictions till 120 days, and high-fidelity turbulence simulations preserving\\nfine-scale structures all without external forcing, with significantly\\nsurpassing baseline AI models in long-term stability and accuracy. By\\neffectively suppressing high-frequency error accumulation, Triton offers a\\npromising pathway towards trustworthy AI-driven simulation for climate and\\nearth system science.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.LG                  |physics.ao-ph    |\n",
      "|http://arxiv.org/abs/2505.19433v1|Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic\\n  Capabilities in LLM Compression Post-training compression reduces the computational and memory costs of large\\nlanguage models (LLMs), enabling resource-efficient deployment. However,\\nexisting compression benchmarks only focus on language modeling (e.g.,\\nperplexity) and natural language understanding tasks (e.g., GLUE accuracy),\\nignoring the agentic capabilities - workflow, tool use/function call,\\nlong-context understanding and real-world application. We introduce the Agent\\nCompression Benchmark (ACBench), the first comprehensive benchmark for\\nevaluating how compression impacts LLMs' agentic abilities. ACBench spans (1)\\n12 tasks across 4 capabilities (e.g., WorfBench for workflow generation,\\nNeedle-in-Haystack for long-context retrieval), (2) quantization (GPTQ, AWQ)\\nand pruning (Wanda, SparseGPT), and (3) 15 models, including small (Gemma-2B),\\nstandard (Qwen2.5 7B-32B), and distilled reasoning LLMs (DeepSeek-R1-Distill).\\nOur experiments reveal compression tradeoffs: 4-bit quantization preserves\\nworkflow generation and tool use (1%-3% drop) but degrades real-world\\napplication accuracy by 10%-15%. We introduce ERank, Top-k Ranking Correlation\\nand Energy to systematize analysis. ACBench provides actionable insights for\\noptimizing LLM compression in agentic scenarios. The code can be found in\\nhttps://github.com/pprp/ACBench.                                                                                                                                                                                                                                                                                                                                                                                            |cs.LG                  |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19434v1|CSTrack: Enhancing RGB-X Tracking via Compact Spatiotemporal Features Effectively modeling and utilizing spatiotemporal features from RGB and other\\nmodalities (\\eg, depth, thermal, and event data, denoted as X) is the core of\\nRGB-X tracker design. Existing methods often employ two parallel branches to\\nseparately process the RGB and X input streams, requiring the model to\\nsimultaneously handle two dispersed feature spaces, which complicates both the\\nmodel structure and computation process. More critically, intra-modality\\nspatial modeling within each dispersed space incurs substantial computational\\noverhead, limiting resources for inter-modality spatial modeling and temporal\\nmodeling. To address this, we propose a novel tracker, CSTrack, which focuses\\non modeling Compact Spatiotemporal features to achieve simple yet effective\\ntracking. Specifically, we first introduce an innovative Spatial Compact Module\\nthat integrates the RGB-X dual input streams into a compact spatial feature,\\nenabling thorough intra- and inter-modality spatial modeling. Additionally, we\\ndesign an efficient Temporal Compact Module that compactly represents temporal\\nfeatures by constructing the refined target distribution heatmap. Extensive\\nexperiments validate the effectiveness of our compact spatiotemporal modeling\\nmethod, with CSTrack achieving new SOTA results on mainstream RGB-X benchmarks.\\nThe code and models will be released at:\\nhttps://github.com/XiaokunFeng/CSTrack.                                                                                                                                                                                                                                                                                                                                     |cs.CV,cs.AI            |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19435v1|Route to Reason: Adaptive Routing for LLM and Reasoning Strategy\\n  Selection The inherent capabilities of a language model (LM) and the reasoning\\nstrategies it employs jointly determine its performance in reasoning tasks.\\nWhile test-time scaling is regarded as an effective approach to tackling\\ncomplex reasoning tasks, it incurs substantial computational costs and often\\nleads to \"overthinking\", where models become trapped in \"thought pitfalls\". To\\naddress this challenge, we propose Route-To-Reason (RTR), a novel unified\\nrouting framework that dynamically allocates both LMs and reasoning strategies\\naccording to task difficulty under budget constraints. RTR learns compressed\\nrepresentations of both expert models and reasoning strategies, enabling their\\njoint and adaptive selection at inference time. This method is low-cost, highly\\nflexible, and can be seamlessly extended to arbitrary black-box or white-box\\nmodels and strategies, achieving true plug-and-play functionality. Extensive\\nexperiments across seven open source models and four reasoning strategies\\ndemonstrate that RTR achieves an optimal trade-off between accuracy and\\ncomputational efficiency among all baselines, achieving higher accuracy than\\nthe best single model while reducing token usage by over 60%.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CL                  |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19436v1|Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents Large Language Models (LLMs) falter in multi-step interactions -- often\\nhallucinating, repeating actions, or misinterpreting user corrections -- due to\\nreliance on linear, unstructured context. This fragility stems from the lack of\\npersistent memory to track evolving goals and task dependencies, undermining\\ntrust in autonomous agents. We introduce the Task Memory Engine (TME), a\\nmodular memory controller that transforms existing LLMs into robust,\\nrevision-aware agents without fine-tuning. TME implements a spatial memory\\nframework that replaces flat context with graph-based structures to support\\nconsistent, multi-turn reasoning. Departing from linear concatenation and\\nReAct-style prompting, TME builds a dynamic task graph -- either a tree or\\ndirected acyclic graph (DAG) -- to map user inputs to subtasks, align them with\\nprior context, and enable dependency-tracked revisions. Its Task Representation\\nand Intent Management (TRIM) component models task semantics and user intent to\\nensure accurate interpretation. Across four multi-turn scenarios-trip planning,\\ncooking, meeting scheduling, and shopping cart editing -- TME eliminates 100%\\nof hallucinations and misinterpretations in three tasks, and reduces\\nhallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns,\\noutperforming ReAct. TME's modular design supports plug-and-play deployment and\\ndomain-specific customization, adaptable to both personal assistants and\\nenterprise automation. We release TME's codebase, benchmarks, and components as\\nopen-source resources, enabling researchers to develop reliable LLM agents.\\nTME's scalable architecture addresses a critical gap in agent performance\\nacross complex, interactive settings.  |cs.AI,cs.CL            |cs.AI            |\n",
      "|http://arxiv.org/abs/2505.19437v1|RA-CLAP: Relation-Augmented Emotional Speaking Style Contrastive\\n  Language-Audio Pretraining For Speech Retrieval The Contrastive Language-Audio Pretraining (CLAP) model has demonstrated\\nexcellent performance in general audio description-related tasks, such as audio\\nretrieval. However, in the emerging field of emotional speaking style\\ndescription (ESSD), cross-modal contrastive pretraining remains largely\\nunexplored. In this paper, we propose a novel speech retrieval task called\\nemotional speaking style retrieval (ESSR), and ESS-CLAP, an emotional speaking\\nstyle CLAP model tailored for learning relationship between speech and natural\\nlanguage descriptions. In addition, we further propose relation-augmented CLAP\\n(RA-CLAP) to address the limitation of traditional methods that assume a strict\\nbinary relationship between caption and audio. The model leverages\\nself-distillation to learn the potential local matching relationships between\\nspeech and descriptions, thereby enhancing generalization ability. The\\nexperimental results validate the effectiveness of RA-CLAP, providing valuable\\nreference in ESSD.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.SD,eess.AS          |eess.AS          |\n",
      "|http://arxiv.org/abs/2505.19438v1|Sampling from Binary Quadratic Distributions via Stochastic Localization Sampling from binary quadratic distributions (BQDs) is a fundamental but\\nchallenging problem in discrete optimization and probabilistic inference.\\nPrevious work established theoretical guarantees for stochastic localization\\n(SL) in continuous domains, where MCMC methods efficiently estimate the\\nrequired posterior expectations during SL iterations. However, achieving\\nsimilar convergence guarantees for discrete MCMC samplers in posterior\\nestimation presents unique theoretical challenges. In this work, we present the\\nfirst application of SL to general BQDs, proving that after a certain number of\\niterations, the external field of posterior distributions constructed by SL\\ntends to infinity almost everywhere, hence satisfy Poincar\\'e inequalities with\\nprobability near to 1, leading to polynomial-time mixing. This theoretical\\nbreakthrough enables efficient sampling from general BQDs, even those that may\\nnot originally possess fast mixing properties. Furthermore, our analysis,\\ncovering enormous discrete MCMC samplers based on Glauber dynamics and\\nMetropolis-Hastings algorithms, demonstrates the broad applicability of our\\ntheoretical framework. Experiments on instances with quadratic unconstrained\\nbinary objectives, including maximum independent set, maximum cut, and maximum\\nclique problems, demonstrate consistent improvements in sampling efficiency\\nacross different discrete MCMC samplers.                                                                                                                                                                                                                                                                                                                          |math.ST,stat.TH        |math.OC          |\n",
      "|http://arxiv.org/abs/2505.19439v1|Surrogate Signals from Format and Length: Reinforcement Learning for\\n  Solving Mathematical Problems without Ground Truth Answers Large Language Models have achieved remarkable success in natural language\\nprocessing tasks, with Reinforcement Learning playing a key role in adapting\\nthem to specific applications. However, obtaining ground truth answers for\\ntraining LLMs in mathematical problem-solving is often challenging, costly, and\\nsometimes unfeasible. This research delves into the utilization of format and\\nlength as surrogate signals to train LLMs for mathematical problem-solving,\\nbypassing the need for traditional ground truth answers.Our study shows that a\\nreward function centered on format correctness alone can yield performance\\nimprovements comparable to the standard GRPO algorithm in early phases.\\nRecognizing the limitations of format-only rewards in the later phases, we\\nincorporate length-based rewards. The resulting GRPO approach, leveraging\\nformat-length surrogate signals, not only matches but surpasses the performance\\nof the standard GRPO algorithm relying on ground truth answers in certain\\nscenarios, achieving 40.0\\% accuracy on AIME2024 with a 7B base model. Through\\nsystematic exploration and experimentation, this research not only offers a\\npractical solution for training LLMs to solve mathematical problems and\\nreducing the dependence on extensive ground truth data collection, but also\\nreveals the essence of why our label-free approach succeeds: base model is like\\nan excellent student who has already mastered mathematical and logical\\nreasoning skills, but performs poorly on the test paper, it simply needs to\\ndevelop good answering habits to achieve outstanding results in exams , in\\nother words, to unlock the capabilities it already possesses.|cs.CL                  |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19440v1|The Birth of Knowledge: Emergent Features across Time, Space, and Scale\\n  in Large Language Models This paper studies the emergence of interpretable categorical features within\\nlarge language models (LLMs), analyzing their behavior across training\\ncheckpoints (time), transformer layers (space), and varying model sizes\\n(scale). Using sparse autoencoders for mechanistic interpretability, we\\nidentify when and where specific semantic concepts emerge within neural\\nactivations. Results indicate clear temporal and scale-specific thresholds for\\nfeature emergence across multiple domains. Notably, spatial analysis reveals\\nunexpected semantic reactivation, with early-layer features re-emerging at\\nlater layers, challenging standard assumptions about representational dynamics\\nin transformer models.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.CL,cs.LG            |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19441v1|Fairness Practices in Industry: A Case Study in Machine Learning Teams\\n  Building Recommender Systems The rapid proliferation of recommender systems necessitates robust fairness\\npractices to address inherent biases. Assessing fairness, though, is\\nchallenging due to constantly evolving metrics and best practices. This paper\\nanalyzes how industry practitioners perceive and incorporate these changing\\nfairness standards in their workflows. Through semi-structured interviews with\\n11 practitioners from technical teams across a range of large technology\\ncompanies, we investigate industry implementations of fairness in\\nrecommendation system products. We focus on current debiasing practices,\\napplied metrics, collaborative strategies, and integrating academic research\\ninto practice. Findings show a preference for multi-dimensional debiasing over\\ntraditional demographic methods, and a reliance on intuitive rather than\\nacademic metrics. This study also highlights the difficulties in balancing\\nfairness with both the practitioner's individual (bottom-up) roles and\\norganizational (top-down) workplace constraints, including the interplay with\\nlegal and compliance experts. Finally, we offer actionable recommendations for\\nthe recommender system community and algorithmic fairness practitioners,\\nunderlining the need to refine fairness practices continually.                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.HC,cs.AI,cs.CY,cs.LG|cs.CY            |\n",
      "|http://arxiv.org/abs/2505.19442v1|Style2Code: A Style-Controllable Code Generation Framework with\\n  Dual-Modal Contrastive Representation Learning Controllable code generation, the ability to synthesize code that follows a\\nspecified style while maintaining functionality, remains a challenging task. We\\npropose a two-stage training framework combining contrastive learning and\\nconditional decoding to enable flexible style control. The first stage aligns\\ncode style representations with semantic and structural features. In the second\\nstage, we fine-tune a language model (e.g., Flan-T5) conditioned on the learned\\nstyle vector to guide generation. Our method supports style interpolation and\\nuser personalization via lightweight mixing. Compared to prior work, our\\nunified framework offers improved stylistic control without sacrificing code\\ncorrectness. This is among the first approaches to combine contrastive\\nalignment with conditional decoding for style-guided code generation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.AI                  |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19443v1|Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications\\n  of Agentic AI This review presents a comprehensive analysis of two emerging paradigms in\\nAI-assisted software development: vibe coding and agentic coding. While both\\nleverage large language models (LLMs), they differ fundamentally in autonomy,\\narchitectural design, and the role of the developer. Vibe coding emphasizes\\nintuitive, human-in-the-loop interaction through prompt-based, conversational\\nworkflows that support ideation, experimentation, and creative exploration. In\\ncontrast, agentic coding enables autonomous software development through\\ngoal-driven agents capable of planning, executing, testing, and iterating tasks\\nwith minimal human intervention. We propose a detailed taxonomy spanning\\nconceptual foundations, execution models, feedback loops, safety mechanisms,\\ndebugging strategies, and real-world tool ecosystems. Through comparative\\nworkflow analysis and 20 detailed use cases, we illustrate how vibe systems\\nthrive in early-stage prototyping and education, while agentic systems excel in\\nenterprise-grade automation, codebase refactoring, and CI/CD integration. We\\nfurther examine emerging trends in hybrid architectures, where natural language\\ninterfaces are coupled with autonomous execution pipelines. Finally, we\\narticulate a future roadmap for agentic AI, outlining the infrastructure needed\\nfor trustworthy, explainable, and collaborative systems. Our findings suggest\\nthat successful AI software engineering will rely not on choosing one paradigm,\\nbut on harmonizing their strengths within a unified, human-centered development\\nlifecycle.                                                                                                                                                  |cs.SE,cs.AI,cs.CL      |cs.SE            |\n",
      "|http://arxiv.org/abs/2505.19444v1|Radiative coupling between plasmon and electron-hole pairs in a metallic\\n  film based on extended Bohm-Pines theory Hot carrier generation in metals, where high-energy electron-hole pairs are\\nproduced via plasmon excitation,\\n  has emerged as a promising mechanism for photoelectric conversion and\\nphotocatalysis. However, conventional\\n  theories often describe this process through phenomenological relaxation via\\nLandau damping, which fails to\\n  account for the microscopic origin of the frequency-dependent internal\\nquantum efficiency (IQE) observed in\\n  experiments. To address this gap, we develop an extended Bohm-Pines theory\\nfor a metallic thin film that\\n  explicitly incorporates light-matter interactions within a non-local response\\nframework. Our approach treats\\n  collective (plasmonic) and individual (electron-hole) excitations on equal\\nfooting and includes their coupling\\n  mediated by both longitudinal and transverse electromagnetic fields. This\\nresults in a self-consistent theory\\n  of the optical response of metallic films. The derived total Hamiltonian\\nincludes radiative corrections that\\n  recover the known dispersion of surface plasmon polaritons and, importantly,\\npredict a frequency-dependent\\n  radiative coupling between collective and individual modes. This previously\\nneglected transverse coupling\\n  naturally explains the IQE peak near the plasmon resonance and reveals a new\\nmechanism of hot carrier\\n  generation distinct from conventional Landau damping. Our results provide a\\nunified theoretical foundation for\\n  understanding plasmon-induced hot carrier dynamics and offer guidance for\\nresonance-based photonic design\\n  strategies to enhance energy conversion efficiency in metal nanostructures.                                                   |physics.optics         |cond-mat.mes-hall|\n",
      "|http://arxiv.org/abs/2505.19445v1|MetaGMT: Improving Actionable Interpretability of Graph Multilinear\\n  Networks via Meta-Learning Filtration The growing adoption of Graph Neural Networks (GNNs) in high-stakes domains\\nlike healthcare and finance demands reliable explanations of their\\ndecision-making processes. While inherently interpretable GNN architectures\\nlike Graph Multi-linear Networks (GMT) have emerged, they remain vulnerable to\\ngenerating explanations based on spurious correlations, potentially undermining\\ntrust in critical applications. We present MetaGMT, a meta-learning framework\\nthat enhances explanation fidelity through a novel bi-level optimization\\napproach. We demonstrate that MetaGMT significantly improves both explanation\\nquality (AUC-ROC, Precision@K) and robustness to spurious patterns, across\\nBA-2Motifs, MUTAG, and SP-Motif benchmarks. Our approach maintains competitive\\nclassification accuracy while producing more faithful explanations (with an\\nincrease up to 8% of Explanation ROC on SP-Motif 0.5) compared to baseline\\nmethods. These advancements in interpretability could enable safer deployment\\nof GNNs in sensitive domains by (1) facilitating model debugging through more\\nreliable explanations, (2) supporting targeted retraining when biases are\\nidentified, and (3) enabling meaningful human oversight. By addressing the\\ncritical challenge of explanation reliability, our work contributes to building\\nmore trustworthy and actionable GNN systems for real-world applications.                                                                                                                                                                                                                                                                                                                         |cs.LG                  |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19446v1|Leveraging Cascaded Binary Classification and Multimodal Fusion for\\n  Dementia Detection through Spontaneous Speech This paper presents our submission to the PROCESS Challenge 2025, focusing on\\nspontaneous speech analysis for early dementia detection. For the three-class\\nclassification task (Healthy Control, Mild Cognitive Impairment, and Dementia),\\nwe propose a cascaded binary classification framework that fine-tunes\\npre-trained language models and incorporates pause encoding to better capture\\ndisfluencies. This design streamlines multi-class classification and addresses\\nclass imbalance by restructuring the decision process. For the Mini-Mental\\nState Examination score regression task, we develop an enhanced multimodal\\nfusion system that combines diverse acoustic and linguistic features. Separate\\nregression models are trained on individual feature sets, with ensemble\\nlearning applied through score averaging. Experimental results on the test set\\noutperform the baselines provided by the organizers in both tasks,\\ndemonstrating the robustness and effectiveness of our approach.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |eess.AS                |eess.AS          |\n",
      "|http://arxiv.org/abs/2505.19447v1|A Contrastive Learning Foundation Model Based on Perfectly Aligned\\n  Sample Pairs for Remote Sensing Images Self-Supervised Learning (SSL) enables us to pre-train foundation models\\nwithout costly labeled data. Among SSL methods, Contrastive Learning (CL)\\nmethods are better at obtaining accurate semantic representations in noise\\ninterference. However, due to the significant domain gap, while CL methods have\\nachieved great success in many computer vision tasks, they still require\\nspecific adaptation for Remote Sensing (RS) images. To this end, we present a\\nnovel self-supervised method called PerA, which produces all-purpose RS\\nfeatures through semantically Perfectly Aligned sample pairs. Specifically,\\nPerA obtains features from sampled views by applying spatially disjoint masks\\nto augmented images rather than random cropping. With disjoint masks, we divide\\npatches from different views into different parts that are semantically aligned\\nbut inconsistent in appearance. Our framework provides high-quality features by\\nensuring consistency between teacher and student and predicting learnable mask\\ntokens. Compared to previous contrastive methods, our method demonstrates\\nhigher memory efficiency and can be trained with larger batches due to its\\nsparse inputs. We also collect an unlabeled pre-training dataset, which\\ncontains about 5 million RS images. We conducted experiments on multiple\\ndownstream task datasets and achieved performance comparable to previous\\nstate-of-the-art methods with a limited model scale, which verified the\\nsuperiority of our method. We hope this work will contribute to practical\\nremote sensing interpretation works.                                                                                                                                    |eess.IV,cs.CV          |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19448v1|Beyond Manual Transcripts: The Potential of Automated Speech Recognition\\n  Errors in Improving Alzheimer's Disease Detection Recent breakthroughs in Automatic Speech Recognition (ASR) have enabled fully\\nautomated Alzheimer's Disease (AD) detection using ASR transcripts.\\nNonetheless, the impact of ASR errors on AD detection remains poorly\\nunderstood. This paper fills the gap. We conduct a comprehensive study on AD\\ndetection using transcripts from various ASR models and their synthesized\\nspeech on the ADReSS dataset. Experimental results reveal that certain ASR\\ntranscripts (ASR-synthesized speech) outperform manual transcripts\\n(manual-synthesized speech) in detection accuracy, suggesting that ASR errors\\nmay provide valuable cues for improving AD detection. Additionally, we propose\\na cross-attention-based interpretability model that not only identifies these\\ncues but also achieves superior or comparable performance to the baseline.\\nFurthermore, we utilize this model to unveil AD-related patterns within\\npre-trained embeddings. Our study offers novel insights into the potential of\\nASR models for AD detection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |eess.AS                |eess.AS          |\n",
      "|http://arxiv.org/abs/2505.19449v1|Simple finite-dimensional model of the metastable state We have constructed an approximate analytical solution of the spectral\\nproblem for a finite-dimensional matrix of a special kind, which turns out to\\nbe a very simple and quite satisfactory model of the metastable state. Most of\\nthe characteristic properties of the metastable state are reproduced: line\\nshape, decay dynamics, and density of states. The correctness of the\\napproximate analytical solution was verified by direct numerical calculations.\\nThe proposed model is a finite-dimensional analog of the Fano formalism.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |quant-ph               |math.NA          |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-32-50.json\n",
      "\n",
      "========= 2025-05-29 21:33:00 =========\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------+-------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |true_label                         |pred         |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------+-------------+\n",
      "|http://arxiv.org/abs/2505.19453v1|Approximately Optimal Mechanism Design for Competing Sellers Two sellers compete to sell identical products to a single buyer. Each seller\\nchooses an arbitrary mechanism, possibly involving lotteries, to sell their\\nproduct. The utility-maximizing buyer can choose to participate in one or both\\nmechanisms, resolving them in either order. Given a common prior over buyer\\nvalues, how should the sellers design their mechanisms to maximize their\\nrespective revenues?\\n  We first consider a Stackelberg setting where one seller (Alice) commits to\\nher mechanism and the other seller (Bob) best-responds. We show how to\\nconstruct a simple and approximately-optimal single-lottery mechanism for Alice\\nthat guarantees her a quarter of the optimal monopolist's revenue, for any\\nregular distribution. Along the way we prove a structural result: for any\\nsingle-lottery mechanism of Alice, there will always be a best response\\nmechanism for Bob consisting of a single take-it-or-leave-it price. We also\\nshow that no mechanism (single-lottery or otherwise) can guarantee Alice more\\nthan a 1/e fraction of the monopolist revenue. Finally, we show that our\\napproximation result does not extend to Nash equilibrium: there exist instances\\nin which a monopolist could extract full surplus, but neither competing seller\\nobtains positive revenue at any equilibrium choice of mechanisms.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.GT                              |cs.GT        |\n",
      "|http://arxiv.org/abs/2505.19454v1|Direct Pseudospectral Optimal Control by Orthogonal Polynomial Integral\\n  Collocation This paper details a methodology to transcribe an optimal control problem\\ninto a nonlinear program for generation of the trajectories that optimize a\\ngiven functional by approximating only the highest order derivatives of a given\\nsystem's dynamics. The underlying method uses orthogonal polynomial integral\\ncollocation by which successive integrals are taken to approximate all lower\\norder states. Hence, one set of polynomial coefficients can represent an entire\\ncoordinate's degree of freedom. Specifically, Chebyshev polynomials of the\\nfirst and second kind and Legendre polynomials are used over their associated\\ncommon interpolating grids derived from the bases' roots and extrema. Simple\\nexample problems compare different polynomial bases' performance to analytical\\nsolutions. The planar circular orbit raising problem is used to verify the\\nmethod with solutions obtained by other pseudospectral methods in literature.\\nFinally, a rocket landing flip maneuver problem is solved to demonstrate the\\nability to solve complex problems with multiple states and control variables\\nwith constraints. Simulations establish this method's performance, and reveal\\nthat the polynomial/node choice for a given problem notably affects the\\nperformance.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |math.OC,cs.SY,eess.SY              |math.OC      |\n",
      "|http://arxiv.org/abs/2505.19455v1|MM-Prompt: Cross-Modal Prompt Tuning for Continual Visual Question\\n  Answering Continual Visual Question Answering (CVQA) based on pre-trained models(PTMs)\\nhas achieved promising progress by leveraging prompt tuning to enable continual\\nmulti-modal learning. However, most existing methods adopt cross-modal prompt\\nisolation, constructing visual and textual prompts separately, which\\nexacerbates modality imbalance and leads to degraded performance over time. To\\ntackle this issue, we propose MM-Prompt, a novel framework incorporating\\ncross-modal prompt query and cross-modal prompt recovery. The former enables\\nbalanced prompt selection by incorporating cross-modal signals during query\\nformation, while the latter promotes joint prompt reconstruction through\\niterative cross-modal interactions, guided by an alignment loss to prevent\\nrepresentational drift. Extensive experiments show that MM-Prompt surpasses\\nprior approaches in accuracy and knowledge retention, while maintaining\\nbalanced modality engagement throughout continual learning.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.CV,cs.AI,cs.LG                  |cs.CV        |\n",
      "|http://arxiv.org/abs/2505.19456v1|An Empirical Study of JavaScript Inclusion Security Issues in Chrome\\n  Extensions JavaScript, a scripting language employed to augment the capabilities of web\\nbrowsers within web pages or browser extensions, utilizes code segments termed\\nJavaScript inclusions. While the security aspects of JavaScript inclusions in\\nweb pages have undergone substantial scrutiny, a thorough investigation into\\nthe security of such inclusions within browser extensions remains absent,\\ndespite the divergent security paradigms governing these environments. This\\nstudy presents a systematic measurement of JavaScript inclusions in Chrome\\nextensions, employing a hybrid methodology encompassing static and dynamic\\nanalysis to identify these inclusions. The analysis of 36,324 extensions\\nrevealed 350,784 JavaScript inclusions. Subsequent security assessment\\nindicated that, although the majority of these inclusions originate from local\\nfiles within the extensions rather than external servers, 22 instances of\\nvulnerable remote JavaScript inclusions were identified. These remote\\ninclusions present potential avenues for malicious actors to execute arbitrary\\ncode within the extension's execution context. Furthermore, an analysis of\\nJavaScript library utilization within Chrome extensions disclosed the prevalent\\nuse of susceptible and outdated libraries, notably within numerous widely\\nadopted extensions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |cs.CR                              |cs.CR        |\n",
      "|http://arxiv.org/abs/2505.19457v1|BizFinBench: A Business-Driven Real-World Financial Benchmark for\\n  Evaluating LLMs Large language models excel in general tasks, yet assessing their reliability\\nin logic-heavy, precision-critical domains like finance, law, and healthcare\\nremains challenging. To address this, we introduce BizFinBench, the first\\nbenchmark specifically designed to evaluate LLMs in real-world financial\\napplications. BizFinBench consists of 6,781 well-annotated queries in Chinese,\\nspanning five dimensions: numerical calculation, reasoning, information\\nextraction, prediction recognition, and knowledge-based question answering,\\ngrouped into nine fine-grained categories. The benchmark includes both\\nobjective and subjective metrics. We also introduce IteraJudge, a novel LLM\\nevaluation method that reduces bias when LLMs serve as evaluators in objective\\nmetrics. We benchmark 25 models, including both proprietary and open-source\\nsystems. Extensive experiments show that no model dominates across all tasks.\\nOur evaluation reveals distinct capability patterns: (1) In Numerical\\nCalculation, Claude-3.5-Sonnet (63.18) and DeepSeek-R1 (64.04) lead, while\\nsmaller models like Qwen2.5-VL-3B (15.92) lag significantly; (2) In Reasoning,\\nproprietary models dominate (ChatGPT-o3: 83.58, Gemini-2.0-Flash: 81.15), with\\nopen-source models trailing by up to 19.49 points; (3) In Information\\nExtraction, the performance spread is the largest, with DeepSeek-R1 scoring\\n71.46, while Qwen3-1.7B scores 11.23; (4) In Prediction Recognition,\\nperformance variance is minimal, with top models scoring between 39.16 and\\n50.00. We find that while current LLMs handle routine finance queries\\ncompetently, they struggle with complex scenarios requiring cross-concept\\nreasoning. BizFinBench offers a rigorous, business-aligned benchmark for future\\nresearch. The code and dataset are available at\\nhttps://github.com/HiThink-Research/BizFinBench.                                                                                                                     |cs.AI,cs.CE,cs.CL                  |cs.CL        |\n",
      "|http://arxiv.org/abs/2505.19458v1|Recurrent Self-Attention Dynamics: An Energy-Agnostic Perspective from\\n  Jacobians The theoretical understanding of self-attention (SA) has been steadily\\nprogressing. A prominent line of work studies a class of SA layers that admit\\nan energy function decreased by state updates. While it provides valuable\\ninsights into inherent biases in signal propagation, it often relies on\\nidealized assumptions or additional constraints not necessarily present in\\nstandard SA. Thus, to broaden our understanding, this work aims to relax these\\nenergy constraints and provide an energy-agnostic characterization of inference\\ndynamics by dynamical systems analysis. In more detail, we first consider\\nrelaxing the symmetry and single-head constraints traditionally required in\\nenergy-based formulations. Next, to investigate more general SA architectures\\ncapable of oscillatory dynamics without necessarily admitting an energy\\nfunction, we analyze the Jacobian matrix of the state. We reveal that\\nnormalization layers effectively normalize the Jacobian's complex eigenvalues,\\nforcing the dynamics close to a critical state. This significantly enhances\\ninference performance. Furthermore, we utilize the Jacobian perspective to\\ndevelop regularization methods for training and a pseudo-energy for monitoring\\ninference dynamics.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.LG,cond-mat.dis-nn,cs.NE,stat.ML|cs.LG        |\n",
      "|http://arxiv.org/abs/2505.19459v1|Your Classifier Can Do More: Towards Bridging the Gaps in\\n  Classification, Robustness, and Generation Joint Energy-based Models (JEMs), a class of hybrid generative-discriminative\\nmodels, are well known for their ability to achieve both high classification\\naccuracy and generative capability within a single model. However, their\\nrobustness still lags significantly behind the classifiers based adversarial\\ntraining (AT). Conversely, while AT is currently the most effective approach to\\nimproving the classifier's robustness, it typically sacrifices accuracy on\\nclean data and lacks generative capability. The triple trade-off between\\nclassification accuracy, generative capability and robustness, raises a natural\\nquestion: Can a single model simultaneously achieve high classification\\naccuracy, adversarial robustness, and generative performance? -- a goal that\\nhas been rarely explored. To address this question, we systematically analyze\\nthe energy distribution differences of clean, adversarial, and generated\\nsamples across various JEM variants and adversarially trained models. We\\nobserve that AT tends to reduce the energy gap between clean and adversarial\\nsamples, while JEMs reduce the gap between clean and synthetic ones. This\\nobservation suggests a key insight: if the energy distributions of all three\\ndata types can be aligned, we might unify the strengths of AT and JEMs,\\nresolving their inherent trade-offs. Building on this idea, we propose\\nEnergy-based Joint Distribution Adversarial Training (EB-JDAT), to jointly\\nmodel the clean data distribution, the adversarial distribution, and the\\nclassifier by maximizing their joint probability. EB-JDAT is a general and\\nflexible optimization method, compatible with various JEM variants. Extensive\\nexperimental results demonstrate that EB-JDAT not only maintains near original\\naccuracy and generative capability of JEMs, but also significantly enhances\\nrobustness, even surpassing state-of-the-art ATs.                                                          |cs.LG,cs.AI                        |cs.LG        |\n",
      "|http://arxiv.org/abs/2505.19460v1|Iterated Lusztig-Vogan Bijection and Distinguished Weights The distinguished weights form a subset of the weight lattice and are closely\\ntied to the notion of $p$-cells. These weights are defined via iterations of\\nthe Lusztig-Vogan bijection. We prove that all distinguished weights exhibit an\\nanti-symmetry under the composition of reversal and negation. We show that the\\ndistribution of these weights follows a polynomial asymptotic, with a leading\\ncoefficient relating to the telephone numbers. As an explicit computation, we\\ndetermine all the distinguished weights for $n \\leq 4$.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |math.RT                            |math.CO      |\n",
      "|http://arxiv.org/abs/2505.19461v1|Fluctuations in DNA Packing Density Drive the Spatial Segregation\\n  between Euchromatin and Heterochromatin In the crowded eukaryotic nucleus, euchromatin and heterochromatin segregate\\ninto distinct compartments, a phenomenon often attributed to homotypic\\ninteractions mediated by liquid liquid phase separation of chromatin associated\\nproteins. Here, we revisit genome compartmentalization by examining the role of\\nin vivo DNA packing density fluctuations driven by ATP dependent chromatin\\nremodelers. Leveraging DNA accessibility data, we develop a polymer based model\\nthat captures these fluctuations and successfully reproduces genome wide\\ncompartment patterns observed in HiC data, without invoking homotypic\\ninteractions. Further analysis reveals that density fluctuations in a crowded\\nnuclear environment elevate the system energy, while euchromatin\\nheterochromatin segregation facilitates energy dissipation, offering a\\nthermodynamic advantage for spontaneous compartment formation. These findings\\nsuggest that euchromatin heterochromatin segregation may arise through a non\\nequilibrium, self organizing process, providing new insights into genome\\norganization.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cond-mat.soft,q-bio.GN             |cond-mat.soft|\n",
      "|http://arxiv.org/abs/2505.19462v1|VoiceStar: Robust Zero-Shot Autoregressive TTS with Duration Control and\\n  Extrapolation We present VoiceStar, the first zero-shot TTS model that achieves both output\\nduration control and extrapolation. VoiceStar is an autoregressive\\nencoder-decoder neural codec language model, that leverages a novel\\nProgress-Monitoring Rotary Position Embedding (PM-RoPE) and is trained with\\nContinuation-Prompt Mixed (CPM) training. PM-RoPE enables the model to better\\nalign text and speech tokens, indicates the target duration for the generated\\nspeech, and also allows the model to generate speech waveforms much longer in\\nduration than those seen during. CPM training also helps to mitigate the\\ntraining/inference mismatch, and significantly improves the quality of the\\ngenerated speech in terms of speaker similarity and intelligibility. VoiceStar\\noutperforms or is on par with current state-of-the-art models on short-form\\nbenchmarks such as Librispeech and Seed-TTS, and significantly outperforms\\nthese models on long-form/extrapolation benchmarks (20-50s) in terms of\\nintelligibility and naturalness. Code and model weights:\\nhttps://github.com/jasonppy/VoiceStar                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |eess.AS,cs.SD                      |cs.SD        |\n",
      "|http://arxiv.org/abs/2505.19463v1|SMAP: Self-supervised Motion Adaptation for Physically Plausible\\n  Humanoid Whole-body Control This paper presents a novel framework that enables real-world humanoid robots\\nto maintain stability while performing human-like motion. Current methods train\\na policy which allows humanoid robots to follow human body using the massive\\nretargeted human data via reinforcement learning. However, due to the\\nheterogeneity between human and humanoid robot motion, directly using\\nretargeted human motion reduces training efficiency and stability. To this end,\\nwe introduce SMAP, a novel whole-body tracking framework that bridges the gap\\nbetween human and humanoid action spaces, enabling accurate motion mimicry by\\nhumanoid robots. The core idea is to use a vector-quantized periodic\\nautoencoder to capture generic atomic behaviors and adapt human motion into\\nphysically plausible humanoid motion. This adaptation accelerates training\\nconvergence and improves stability when handling novel or challenging motions.\\nWe then employ a privileged teacher to distill precise mimicry skills into the\\nstudent policy with a proposed decoupled reward. We conduct experiments in\\nsimulation and real world to demonstrate the superiority stability and\\nperformance of SMAP over SOTA methods, offering practical guidelines for\\nadvancing whole-body control in humanoid robots.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |cs.RO                              |cs.RO        |\n",
      "|http://arxiv.org/abs/2505.19464v1|LLMs as Better Recommenders with Natural Language Collaborative Signals:\\n  A Self-Assessing Retrieval Approach Incorporating collaborative information (CI) effectively is crucial for\\nleveraging LLMs in recommendation tasks. Existing approaches often encode CI\\nusing soft tokens or abstract identifiers, which introduces a semantic\\nmisalignment with the LLM's natural language pretraining and hampers knowledge\\nintegration. To address this, we propose expressing CI directly in natural\\nlanguage to better align with LLMs' semantic space. We achieve this by\\nretrieving a curated set of the most relevant user behaviors in natural\\nlanguage form. However, identifying informative CI is challenging due to the\\ncomplexity of similarity and utility assessment. To tackle this, we introduce a\\nSelf-assessing COllaborative REtrieval framework (SCORE) following the\\nretrieve-rerank paradigm. First, a Collaborative Retriever (CAR) is developed\\nto consider both collaborative patterns and semantic similarity. Then, a\\nSelf-assessing Reranker (SARE) leverages LLMs' own reasoning to assess and\\nprioritize retrieved behaviors. Finally, the selected behaviors are prepended\\nto the LLM prompt as natural-language CI to guide recommendation. Extensive\\nexperiments on two public datasets validate the effectiveness of SCORE in\\nimproving LLM-based recommendation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.IR                              |cs.IR        |\n",
      "|http://arxiv.org/abs/2505.19465v1|Residual Cross-Attention Transformer-Based Multi-User CSI Feedback with\\n  Deep Joint Source-Channel Coding This letter proposes a deep-learning (DL)-based multi-user channel state\\ninformation (CSI) feedback framework for massive multiple-input multiple-output\\nsystems, where the deep joint source-channel coding (DJSCC) is utilized to\\nimprove the CSI reconstruction accuracy. Specifically, we design a multi-user\\njoint CSI feedback framework, whereby the CSI correlation of nearby users is\\nutilized to reduce the feedback overhead. Under the framework, we propose a new\\nresidual cross-attention transformer architecture, which is deployed at the\\nbase station to further improve the CSI feedback performance. Moreover, to\\ntackle the \"cliff-effect\" of conventional bit-level CSI feedback approaches, we\\nintegrated DJSCC into the multi-user CSI feedback, together with utilizing a\\ntwo-stage training scheme to adapt to varying uplink noise levels. Experimental\\nresults demonstrate the superiority of our methods in CSI feedback performance,\\nwith low network complexity and better scalability.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.LG,cs.AI                        |eess.SP      |\n",
      "|http://arxiv.org/abs/2505.19466v1|Origin Tracer: A Method for Detecting LoRA Fine-Tuning Origins in LLMs As large language models (LLMs) continue to advance, their deployment often\\ninvolves fine-tuning to enhance performance on specific downstream tasks.\\nHowever, this customization is sometimes accompanied by misleading claims about\\nthe origins, raising significant concerns about transparency and trust within\\nthe open-source community. Existing model verification techniques typically\\nassess functional, representational, and weight similarities. However, these\\napproaches often struggle against obfuscation techniques, such as permutations\\nand scaling transformations. To address this limitation, we propose a novel\\ndetection method Origin-Tracer that rigorously determines whether a model has\\nbeen fine-tuned from a specified base model. This method includes the ability\\nto extract the LoRA rank utilized during the fine-tuning process, providing a\\nmore robust verification framework. This framework is the first to provide a\\nformalized approach specifically aimed at pinpointing the sources of model\\nfine-tuning. We empirically validated our method on thirty-one diverse\\nopen-source models under conditions that simulate real-world obfuscation\\nscenarios. We empirically analyze the effectiveness of our framework and\\nfinally, discuss its limitations. The results demonstrate the effectiveness of\\nour approach and indicate its potential to establish new benchmarks for model\\nverification.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.AI,cs.LG                        |cs.CL        |\n",
      "|http://arxiv.org/abs/2505.19467v1|GPU acceleration of non-equilibrium Green's function calculation using\\n  OpenACC and CUDA FORTRAN The numerical solution of the Kadanoff-Baym nonlinear integro-differential\\nequations, which yields the non-equilibrium Green's functions (NEGFs) of\\nquantum many-body systems, poses significant computational challenges due to\\nits high computational complexity. In this work, we present efficient\\nimplementations of a numerical method for solving these equations on\\ndistributed-memory architectures, including many-core CPUs and multi-GPU\\nsystems. For CPU-based platforms, we adopt a hybrid MPI/OpenMP programming\\nmodel to exploit both inter-node and intra-node parallelism. On GPU-accelerated\\nsystems, we implement the method using two distinct approaches: MPI/OpenACC and\\nMPI/CUDA FORTRAN. Several optimization strategies are employed to enhance GPU\\nperformance, including techniques to maximize computational resource\\nutilization and minimize the overhead associated with kernel launches and\\nmemory management. Although OpenACC is easy to use, CUDA FORTRAN provides more\\nadvanced features for configuring and managing multiple levels of concurrency,\\nwhile also simplifying memory allocation and data movement between host and\\ndevice. This flexibility translates into significant performance improvements.\\nWe compare the performance of the three implementations and demonstrate that\\nthe GPU-based approaches achieve substantial speedups over CPU-based\\nimplementations. Furthermore, both CPU and GPU versions exhibit excellent\\nstrong and weak scaling, confirming the scalability and efficiency of our\\napproach for large-scale NEGF computations.                                                                                                                                                                                                                                                                                                                                                                                                  |cs.DC                              |cs.DC        |\n",
      "|http://arxiv.org/abs/2505.19468v1|Comparison of Polar Magnetic Fields Derived from MILOS and MERLIN\\n  Inversions with Hinode/SOT-SP Data The detailed investigation of the polar magnetic field and its time evolution\\nis one of the major achievements of Hinode. Precise measurements of the polar\\nmagnetic field are essential for understanding the solar cycle, as they provide\\nimportant constraints for identifying the source regions of the solar wind. The\\nSpectropolarimeter (SP) of the Solar Optical Telescope (SOT) on board Hinode\\nhas been the instrument best suited to make such measurements. In this study,\\nwe compare the SOT-SP data for the polar regions, processed using two\\nrepresentative Milne-Eddington inversion codes, MILOS and MERLIN. These codes\\nare applied to the same level-1 SOT-SP data, and the same disambiguation\\nalgorithm is used on the maps that go through the two inversions. We find that\\nthe radial magnetic-flux density (the magnetic-flux density with respect to the\\nlocal vertical) provided by the MERLIN inversion tends to be approximately\\n7%-10% larger than that obtained from the MILOS inversion. The slightly higher\\nradial magnetic-flux density from MERLIN appears to be common to the polar\\nmagnetic fields observed at different phases of the solar cycle. When MILOS is\\nrun with the same scattered-light profile and the same magnetic filling factor\\nthat are derived with the MERLIN inversion, the radial magnetic-flux density\\nderived from the two inversions is almost the same. We attribute the difference\\nin the radial magnetic-flux density to different filling factors adopted by the\\ntwo inversions, based on whether the scattered-light profiles are assumed to be\\nthe Stokes I profiles averaged over the neighboring pixels or over the entire\\nfield of view. The relationship between the radial magnetic-flux density and\\nmagnetic filling factor could be more complex in the polar (limb) observations\\ndue to the possible contributions of the transverse magnetic-field component to\\nthe estimation of the radial magnetic-flux density.|astro-ph.SR                        |astro-ph.SR  |\n",
      "|http://arxiv.org/abs/2505.19469v1|Diversity-Driven Generative Dataset Distillation Based on Diffusion\\n  Model with Self-Adaptive Memory Dataset distillation enables the training of deep neural networks with\\ncomparable performance in significantly reduced time by compressing large\\ndatasets into small and representative ones. Although the introduction of\\ngenerative models has made great achievements in this field, the distributions\\nof their distilled datasets are not diverse enough to represent the original\\nones, leading to a decrease in downstream validation accuracy. In this paper,\\nwe present a diversity-driven generative dataset distillation method based on a\\ndiffusion model to solve this problem. We introduce self-adaptive memory to\\nalign the distribution between distilled and real datasets, assessing the\\nrepresentativeness. The degree of alignment leads the diffusion model to\\ngenerate more diverse datasets during the distillation process. Extensive\\nexperiments show that our method outperforms existing state-of-the-art methods\\nin most situations, proving its ability to tackle dataset distillation tasks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |cs.LG,cs.AI,cs.CV                  |cs.LG        |\n",
      "|http://arxiv.org/abs/2505.19470v1|Information-theoretic Generalization Analysis for VQ-VAEs: A Role of\\n  Latent Variables Latent variables (LVs) play a crucial role in encoder-decoder models by\\nenabling effective data compression, prediction, and generation. Although their\\ntheoretical properties, such as generalization, have been extensively studied\\nin supervised learning, similar analyses for unsupervised models such as\\nvariational autoencoders (VAEs) remain insufficiently underexplored. In this\\nwork, we extend information-theoretic generalization analysis to\\nvector-quantized (VQ) VAEs with discrete latent spaces, introducing a novel\\ndata-dependent prior to rigorously analyze the relationship among LVs,\\ngeneralization, and data generation. We derive a novel generalization error\\nbound of the reconstruction loss of VQ-VAEs, which depends solely on the\\ncomplexity of LVs and the encoder, independent of the decoder. Additionally, we\\nprovide the upper bound of the 2-Wasserstein distance between the distributions\\nof the true data and the generated data, explaining how the regularization of\\nthe LVs contributes to the data generation performance.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |stat.ML,cs.LG                      |cs.LG        |\n",
      "|http://arxiv.org/abs/2505.19471v1|C*-like modules and matrix $p$-operator norms We present a generalization of H\\\"older duality to algebra-valued pairings\\nvia $L^p$-modules. H\\\"older duality states that if $p \\in (1, \\infty)$ and\\n$p^{\\prime}$ are conjugate exponents, then the dual space of $L^p(\\mu)$ is\\nisometrically isomorphic to $L^{p^{\\prime}}(\\mu)$. In this work we study\\ncertain pairs $(\\mathsf{Y},\\mathsf{X})$, as generalizations of the pair\\n$(L^{p^{\\prime}}(\\mu), L^p(\\mu))$, that have an $L^p$-operator algebra valued\\npairing $\\mathsf{Y} \\times \\mathsf{X} \\to A$. When the $A$-valued version of\\nH\\\"older duality still holds, we say that $(\\mathsf{Y},\\mathsf{X})$ is C*-like.\\nWe show that finite and countable direct sums of the C*-like module $(A,A)$ are\\nstill C*-like when $A$ is any block diagonal subalgebra of $d \\times d$\\nmatrices. We provide counterexamples when $A \\subset M_d^p(\\mathbb{C})$ is not\\nblock diagonal.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |math.FA,math.OA                    |math.FA      |\n",
      "|http://arxiv.org/abs/2505.19472v1|Balancing Computation Load and Representation Expressivity in Parallel\\n  Hybrid Neural Networks Attention and State-Space Models (SSMs) when combined in a hybrid network in\\nsequence or in parallel provide complementary strengths. In a hybrid sequential\\npipeline they alternate between applying a transformer to the input and then\\nfeeding its output into a SSM. This results in idle periods in the individual\\ncomponents increasing end-to-end latency and lowering throughput caps. In the\\nparallel hybrid architecture, the transformer operates independently in\\nparallel with the SSM, and these pairs are cascaded, with output from one pair\\nforming the input to the next. Two issues are (i) creating an expressive\\nknowledge representation with the inherently divergent outputs from these\\nseparate branches, and (ii) load balancing the computation between these\\nparallel branches, while maintaining representation fidelity. In this work we\\npresent FlowHN, a novel parallel hybrid network architecture that accommodates\\nvarious strategies for load balancing, achieved through appropriate\\ndistribution of input tokens between the two branches. Two innovative\\ndifferentiating factors in FlowHN include a FLOP aware dynamic token split\\nbetween the attention and SSM branches yielding efficient balance in compute\\nload, and secondly, a method to fuse the highly divergent outputs from\\nindividual branches for enhancing representation expressivity. Together they\\nenable much better token processing speeds, avoid bottlenecks, and at the same\\ntime yield significantly improved accuracy as compared to other competing\\nworks. We conduct comprehensive experiments on autoregressive language modeling\\nfor models with 135M, 350M, and 1B parameters. FlowHN outperforms sequential\\nhybrid models and its parallel counterpart, achieving up to 4* higher Tokens\\nper Second (TPS) and 2* better Model FLOPs Utilization (MFU).                                                                                                                            |cs.CL                              |cs.LG        |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-33-00.json\n",
      "\n",
      "========= 2025-05-29 21:33:10 =========\n",
      "+---------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-----------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |true_label                       |pred             |\n",
      "+---------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-----------------+\n",
      "|http://arxiv.org/abs/2505.19477v1|Judging with Many Minds: Do More Perspectives Mean Less Prejudice? LLM-as-Judge has emerged as a scalable alternative to human evaluation,\\nenabling large language models (LLMs) to provide reward signals in trainings.\\nWhile recent work has explored multi-agent extensions such as multi-agent\\ndebate and meta-judging to enhance evaluation quality, the question of how\\nintrinsic biases manifest in these settings remains underexplored. In this\\nstudy, we conduct a systematic analysis of four diverse bias types: position\\nbias, verbosity bias, chain-of-thought bias, and bandwagon bias. We evaluate\\nthese biases across two widely adopted multi-agent LLM-as-Judge frameworks:\\nMulti-Agent-Debate and LLM-as-Meta-Judge. Our results show that debate\\nframework amplifies biases sharply after the initial debate, and this increased\\nbias is sustained in subsequent rounds, while meta-judge approaches exhibit\\ngreater resistance. We further investigate the incorporation of PINE, a leading\\nsingle-agent debiasing method, as a bias-free agent within these systems. The\\nresults reveal that this bias-free agent effectively reduces biases in debate\\nsettings but provides less benefit in meta-judge scenarios. Our work provides a\\ncomprehensive study of bias behavior in multi-agent LLM-as-Judge systems and\\nhighlights the need for targeted bias mitigation strategies in collaborative\\nevaluation settings.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.AI                            |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19478v1|Empirical 3D Channel Modeling for Cellular-Connected UAVs: A\\n  Triple-Layer Machine Learning Approach This work proposes an empirical air to ground (A2G) propagation model\\nspecifically designed for cellular connected unmanned aerial vehicles (UAVs).\\nAn in depth aerial drive test was carried out within an operating Long Term\\nEvolution (LTE) network, gathering thorough measurements of key network\\nparameters. Rigid preprocessing and statistical analysis of these data produced\\na strong foundation for training a new triple layer machine learning (ML)\\nmodel. The proposed ML framework employs a systematic hierarchical approach.\\nAccordingly, the first two layers, Stepwise Linear Regression (STW) and\\nEnsemble of Bagged Trees (EBT) generate predictions independently, meanwhile,\\nthe third layer, Gaussian Process Regression (GPR), explicitly acts as an\\naggregation layer, refining these predictions to accurately estimate Key\\nPerformance Indicators (KPIs) such as Reference Signal Received Power (RSRP),\\nReference Signal Received Quality (RSRQ), Received Signal Strength (RSSI), and\\nPath Loss (PL). Compared to traditional single layer ML or computationally\\nintensive ray tracing approaches, the proposed triple layer ML framework\\nsignificantly improves predictive accuracy and robustness, achieving around 99\\npercent accuracy in training and above 90 percent in testing while utilizing a\\nminimal but effective feature set log transformed 3D and 2D propagation\\ndistances, azimuth, and elevation angles. This streamlined feature selection\\nsubstantially reduces computing complexity, thus enhancing scalability across\\nvarious operating environments. The proposed frameworks practicality and\\nefficacy for real world deployment in UAV integrated cellular networks are\\nfurther demonstrated by comparative analyses, which underscore its substantial\\nimprovement.                                                                                                                                                                                                                    |eess.SP                          |eess.SP          |\n",
      "|http://arxiv.org/abs/2505.19479v1|Revolutionizing Wildfire Detection with Convolutional Neural Networks: A\\n  VGG16 Model Approach Over 8,024 wildfire incidents have been documented in 2024 alone, affecting\\nthousands of fatalities and significant damage to infrastructure and\\necosystems. Wildfires in the United States have inflicted devastating losses.\\nWildfires are becoming more frequent and intense, which highlights how urgently\\nefficient warning systems are needed to avoid disastrous outcomes. The goal of\\nthis study is to enhance the accuracy of wildfire detection by using\\nConvolutional Neural Network (CNN) built on the VGG16 architecture. The D-FIRE\\ndataset, which includes several kinds of wildfire and non-wildfire images, was\\nemployed in the study. Low-resolution images, dataset imbalance, and the\\nnecessity for real-time applicability are some of the main challenges. These\\nproblems were resolved by enriching the dataset using data augmentation\\ntechniques and optimizing the VGG16 model for binary classification. The model\\nproduced a low false negative rate, which is essential for reducing unexplored\\nfires, despite dataset boundaries. In order to help authorities execute fast\\nresponses, this work shows that deep learning models such as VGG16 can offer a\\nreliable, automated approach for early wildfire recognition. For the purpose of\\nreducing the impact of wildfires, our future work will concentrate on\\nconnecting to systems with real-time surveillance networks and enlarging the\\ndataset to cover more varied fire situations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.CV,cs.LG                      |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19480v1|Room Impulse Response as a Prompt for Acoustic Echo Cancellation Data-driven acoustic echo cancellation (AEC) methods, predominantly trained\\non synthetic or constrained real-world datasets, encounter performance declines\\nin unseen echo scenarios, especially in real environments where echo paths are\\nnot directly observable. Our proposed method counters this limitation by\\nintegrating room impulse response (RIR) as a pivotal training prompt, aiming to\\nimprove the generalization of AEC models in such unforeseen conditions. We also\\nexplore four RIR prompt fusion methods. Comprehensive evaluations, including\\nboth simulated RIR under unknown conditions and recorded RIR in real,\\ndemonstrate that the proposed approach significantly improves performance\\ncompared to baseline models. These results substantiate the effectiveness of\\nour RIR-guided approach in strengthening the model's generalization\\ncapabilities.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.SD,eess.AS                    |eess.AS          |\n",
      "|http://arxiv.org/abs/2505.19481v1|Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive\\n  Decisions of LLMs Large language models (LLMs) have shown remarkable performance across diverse\\nreasoning and generation tasks, and are increasingly deployed as agents in\\ndynamic environments such as code generation and recommendation systems.\\nHowever, many real-world applications, such as high-frequency trading and\\nreal-time competitive gaming, require decisions under strict latency\\nconstraints, where faster responses directly translate into higher rewards.\\nDespite the importance of this latency quality trade off, it remains\\nunderexplored in the context of LLM based agents. In this work, we present the\\nfirst systematic study of this trade off in real time decision making tasks. To\\nsupport our investigation, we introduce two new benchmarks: HFTBench, a high\\nfrequency trading simulation, and StreetFighter, a competitive gaming platform.\\nOur analysis reveals that optimal latency quality balance varies by task, and\\nthat sacrificing quality for lower latency can significantly enhance downstream\\nperformance. To address this, we propose FPX, an adaptive framework that\\ndynamically selects model size and quantization level based on real time\\ndemands. Our method achieves the best performance on both benchmarks, improving\\nwin rate by up to 80% in Street Fighter and boosting daily yield by up to\\n26.52% in trading, underscoring the need for latency aware evaluation and\\ndeployment strategies for LLM based agents. These results demonstrate the\\ncritical importance of latency aware evaluation and deployment strategies for\\nreal world LLM based agents. Our benchmarks are available at Latency Sensitive\\nBenchmarks.                                                                                                                                                                                                                                                                                                                                                                                    |cs.LG,cs.AI,cs.DC,cs.MA          |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19482v1|Language of Network: A Generative Pre-trained Model for Encrypted\\n  Traffic Comprehension The increasing demand for privacy protection and security considerations\\nleads to a significant rise in the proportion of encrypted network traffic.\\nSince traffic content becomes unrecognizable after encryption, accurate\\nanalysis is challenging, making it difficult to classify applications and\\ndetect attacks. Deep learning is currently the predominant approach for\\nencrypted traffic classification through feature analysis. However, these\\nmethods face limitations due to their high dependence on labeled data and\\ndifficulties in detecting attack variants. First, their performance is highly\\nsensitive to data quality, where the highcost manual labeling process and\\ndataset imbalance significantly degrade results. Second, the rapid evolution of\\nattack patterns makes it challenging for models to identify new types of\\nattacks. To tackle these challenges, we present GBC, a generative model based\\non pre-training for encrypted traffic comprehension. Since traditional\\ntokenization methods are primarily designed for natural language, we propose a\\nprotocol-aware tokenization approach for encrypted traffic that improves model\\ncomprehension of fields specific to network traffic. In addition, GBC employs\\npretraining to learn general representations from extensive unlabeled traffic\\ndata. Through prompt learning, it effectively adapts to various downstream\\ntasks, enabling both high-quality traffic generation and effective detection.\\nEvaluations across multiple datasets demonstrate that GBC achieves superior\\nresults in both traffic classification and generation tasks, resulting in a 5%\\nimprovement in F1 score compared to state-of-the-art methods for classification\\ntasks.                                                                                                                                                                                                                                                                                                             |cs.CR                            |cs.CR            |\n",
      "|http://arxiv.org/abs/2505.19483v1|Approximating the Particle Distribution in Rotating and Tandem Mirror\\n  Traps Steady state distribution functions can be used to calculate stability\\nconditions for modes, radiation energy losses, and particle loss rates.\\nHeuristic analytic approximations to these distributions can capture key\\nbehaviors of the true distributions while possessing computational advantages\\nover their numerical counterparts. In this paper, we motivate and present a\\nclosed-form analytic model for a distribution of particles in a centrifugal or\\ntandem mirror. We find that our model outperforms other known models in\\napproximating numerical steady-state simulations outside of a narrow range of\\nlow confining potentials. We demonstrate the model's suitability in the high\\nconfining potential regime for applications such as loss cone stability\\nthresholds, fusion yields, and available energy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |physics.plasm-ph                 |physics.plasm-ph |\n",
      "|http://arxiv.org/abs/2505.19484v1|CulFiT: A Fine-grained Cultural-aware LLM Training Paradigm via\\n  Multilingual Critique Data Synthesis Large Language Models (LLMs) have demonstrated remarkable capabilities across\\nvarious tasks, yet they often exhibit a specific cultural biases, neglecting\\nthe values and linguistic diversity of low-resource regions. This cultural bias\\nnot only undermines universal equality, but also risks reinforcing stereotypes\\nand perpetuating discrimination. To address this, we propose CulFiT, a novel\\nculturally-aware training paradigm that leverages multilingual data and\\nfine-grained reward modeling to enhance cultural sensitivity and inclusivity.\\nOur approach synthesizes diverse cultural-related questions, constructs\\ncritique data in culturally relevant languages, and employs fine-grained\\nrewards to decompose cultural texts into verifiable knowledge units for\\ninterpretable evaluation. We also introduce GlobalCultureQA, a multilingual\\nopen-ended question-answering dataset designed to evaluate culturally-aware\\nresponses in a global context. Extensive experiments on three existing\\nbenchmarks and our GlobalCultureQA demonstrate that CulFiT achieves\\nstate-of-the-art open-source model performance in cultural alignment and\\ngeneral reasoning.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.CL                            |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19485v1|Universal Symmetries in Twisted Moir√© Materials Two-dimensional multi-layer materials with an induced moir\\'e pattern, either\\ndue to strain or relative twist between layers, provide a versatile platform\\nfor exploring strongly correlated and topological electronic phenomena. While\\nthese systems offer unprecedented tunability, their theoretical description\\nremains challenging due to their complex atomic structures and large unit\\ncells. A notable example is twisted bilayer graphene, where even the relevant\\nsymmetry group remains unsettled despite its critical role in constructing\\neffective theories. Here, we focus on twisted bilayer graphene and use a\\ncombination of analytical methods, molecular dynamics simulations, and\\nfirst-principles calculations to show that twisted atomic configurations with\\ndistinct microscopic symmetries converge to a universal interlayer structure\\nthat governs the low-energy physics. This emergent universality provides a\\nrobust foundation for symmetry-respecting models and offers insight into the\\nrole of commensurability in real twisted moir\\'e systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cond-mat.str-el,cond-mat.mtrl-sci|cond-mat.mes-hall|\n",
      "|http://arxiv.org/abs/2505.19486v1|VLMLight: Traffic Signal Control via Vision-Language Meta-Control and\\n  Dual-Branch Reasoning Traffic signal control (TSC) is a core challenge in urban mobility, where\\nreal-time decisions must balance efficiency and safety. Existing methods -\\nranging from rule-based heuristics to reinforcement learning (RL) - often\\nstruggle to generalize to complex, dynamic, and safety-critical scenarios. We\\nintroduce VLMLight, a novel TSC framework that integrates vision-language\\nmeta-control with dual-branch reasoning. At the core of VLMLight is the first\\nimage-based traffic simulator that enables multi-view visual perception at\\nintersections, allowing policies to reason over rich cues such as vehicle type,\\nmotion, and spatial density. A large language model (LLM) serves as a\\nsafety-prioritized meta-controller, selecting between a fast RL policy for\\nroutine traffic and a structured reasoning branch for critical cases. In the\\nlatter, multiple LLM agents collaborate to assess traffic phases, prioritize\\nemergency vehicles, and verify rule compliance. Experiments show that VLMLight\\nreduces waiting times for emergency vehicles by up to 65% over RL-only systems,\\nwhile preserving real-time performance in standard conditions with less than 1%\\ndegradation. VLMLight offers a scalable, interpretable, and safety-aware\\nsolution for next-generation traffic signal control.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |eess.SY,cs.LG,cs.MA,cs.SY        |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19487v1|SpikeStereoNet: A Brain-Inspired Framework for Stereo Depth Estimation\\n  from Spike Streams Conventional frame-based cameras often struggle with stereo depth estimation\\nin rapidly changing scenes. In contrast, bio-inspired spike cameras emit\\nasynchronous events at microsecond-level resolution, providing an alternative\\nsensing modality. However, existing methods lack specialized stereo algorithms\\nand benchmarks tailored to the spike data. To address this gap, we propose\\nSpikeStereoNet, a brain-inspired framework and the first to estimate stereo\\ndepth directly from raw spike streams. The model fuses raw spike streams from\\ntwo viewpoints and iteratively refines depth estimation through a recurrent\\nspiking neural network (RSNN) update module. To benchmark our approach, we\\nintroduce a large-scale synthetic spike stream dataset and a real-world stereo\\nspike dataset with dense depth annotations. SpikeStereoNet outperforms existing\\nmethods on both datasets by leveraging spike streams' ability to capture subtle\\nedges and intensity shifts in challenging regions such as textureless surfaces\\nand extreme lighting conditions. Furthermore, our framework exhibits strong\\ndata efficiency, maintaining high accuracy even with substantially reduced\\ntraining data. The source code and datasets will be publicly available.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.CV                            |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19488v1|Understanding Transformer from the Perspective of Associative Memory In this paper, we share our reflections and insights on understanding\\nTransformer architectures through the lens of associative memory--a classic\\npsychological concept inspired by human cognition. We start with the basics of\\nassociative memory (think simple linear attention) and then dive into two\\ndimensions:\\n  Memory Capacity: How much can a Transformer really remember, and how well? We\\nintroduce retrieval SNR to measure this and use a kernel perspective to\\nmathematically reveal why Softmax Attention is so effective. We also show how\\nFFNs can be seen as a type of associative memory, leading to insights on their\\ndesign and potential improvements.\\n  Memory Update: How do these memories learn and evolve? We present a unified\\nframework for understanding how different Transformer variants (like DeltaNet\\nand Softmax Attention) update their \"knowledge base\". This leads us to tackle\\ntwo provocative questions: 1. Are Transformers fundamentally limited in what\\nthey can express, and can we break these barriers? 2. If a Transformer had\\ninfinite context, would it become infinitely intelligent?\\n  We want to demystify Transformer architecture, offering a clearer\\nunderstanding of existing designs. This exploration aims to provide fresh\\ninsights and spark new avenues for Transformer innovation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.LG,cs.AI                      |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19489v1|Benchmarking and Enhancing LLM Agents in Localizing Linux Kernel Bugs The Linux kernel is a critical system, serving as the foundation for numerous\\nsystems. Bugs in the Linux kernel can cause serious consequences, affecting\\nbillions of users. Fault localization (FL), which aims at identifying the buggy\\ncode elements in software, plays an essential role in software quality\\nassurance. While recent LLM agents have achieved promising accuracy in FL on\\nrecent benchmarks like SWE-bench, it remains unclear how well these methods\\nperform in the Linux kernel, where FL is much more challenging due to the\\nlarge-scale code base, limited observability, and diverse impact factors. In\\nthis paper, we introduce LinuxFLBench, a FL benchmark constructed from\\nreal-world Linux kernel bugs. We conduct an empirical study to assess the\\nperformance of state-of-the-art LLM agents on the Linux kernel. Our initial\\nresults reveal that existing agents struggle with this task, achieving a best\\ntop-1 accuracy of only 41.6% at file level. To address this challenge, we\\npropose LinuxFL$^+$, an enhancement framework designed to improve FL\\neffectiveness of LLM agents for the Linux kernel. LinuxFL$^+$ substantially\\nimproves the FL accuracy of all studied agents (e.g., 7.2% - 11.2% accuracy\\nincrease) with minimal costs. Data and code are available at\\nhttps://github.com/FudanSELab/LinuxFLBench.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |cs.AI,cs.SE                      |cs.SE            |\n",
      "|http://arxiv.org/abs/2505.19490v1|Automated CAD Modeling Sequence Generation from Text Descriptions via\\n  Transformer-Based Large Language Models Designing complex computer-aided design (CAD) models is often time-consuming\\ndue to challenges such as computational inefficiency and the difficulty of\\ngenerating precise models. We propose a novel language-guided framework for\\nindustrial design automation to address these issues, integrating large\\nlanguage models (LLMs) with computer-automated design (CAutoD).Through this\\nframework, CAD models are automatically generated from parameters and\\nappearance descriptions, supporting the automation of design tasks during the\\ndetailed CAD design phase. Our approach introduces three key innovations: (1) a\\nsemi-automated data annotation pipeline that leverages LLMs and vision-language\\nlarge models (VLLMs) to generate high-quality parameters and appearance\\ndescriptions; (2) a Transformer-based CAD generator (TCADGen) that predicts\\nmodeling sequences via dual-channel feature aggregation; (3) an enhanced CAD\\nmodeling generation model, called CADLLM, that is designed to refine the\\ngenerated sequences by incorporating the confidence scores from TCADGen.\\nExperimental results demonstrate that the proposed approach outperforms\\ntraditional methods in both accuracy and efficiency, providing a powerful tool\\nfor automating industrial workflows and generating complex CAD models from\\ntextual prompts. The code is available at\\nhttps://jianxliao.github.io/cadllm-page/                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |cs.AI                            |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19491v1|Discounted Online Convex Optimization: Uniform Regret Across a\\n  Continuous Interval Reflecting the greater significance of recent history over the distant past\\nin non-stationary environments, $\\lambda$-discounted regret has been introduced\\nin online convex optimization (OCO) to gracefully forget past data as new\\ninformation arrives. When the discount factor $\\lambda$ is given, online\\ngradient descent with an appropriate step size achieves an\\n$O(1/\\sqrt{1-\\lambda})$ discounted regret. However, the value of $\\lambda$ is\\noften not predetermined in real-world scenarios. This gives rise to a\\nsignificant open question: is it possible to develop a discounted algorithm\\nthat adapts to an unknown discount factor. In this paper, we affirmatively\\nanswer this question by providing a novel analysis to demonstrate that smoothed\\nOGD (SOGD) achieves a uniform $O(\\sqrt{\\log T/1-\\lambda})$ discounted regret,\\nholding for all values of $\\lambda$ across a continuous interval\\nsimultaneously. The basic idea is to maintain multiple OGD instances to handle\\ndifferent discount factors, and aggregate their outputs sequentially by an\\nonline prediction algorithm named as Discounted-Normal-Predictor (DNP)\\n(Kapralov and Panigrahy,2010). Our analysis reveals that DNP can combine the\\ndecisions of two experts, even when they operate on discounted regret with\\ndifferent discount factors.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |cs.LG,stat.ML                    |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19492v1|ViewCraft3D: High-Fidelity and View-Consistent 3D Vector Graphics\\n  Synthesis 3D vector graphics play a crucial role in various applications including 3D\\nshape retrieval, conceptual design, and virtual reality interactions due to\\ntheir ability to capture essential structural information with minimal\\nrepresentation. While recent approaches have shown promise in generating 3D\\nvector graphics, they often suffer from lengthy processing times and struggle\\nto maintain view consistency. To address these limitations, we propose\\nViewCraft3D (VC3D), an efficient method that leverages 3D priors to generate 3D\\nvector graphics. Specifically, our approach begins with 3D object analysis,\\nemploys a geometric extraction algorithm to fit 3D vector graphics to the\\nunderlying structure, and applies view-consistent refinement process to enhance\\nvisual quality. Our comprehensive experiments demonstrate that VC3D outperforms\\nprevious methods in both qualitative and quantitative evaluations, while\\nsignificantly reducing computational overhead. The resulting 3D sketches\\nmaintain view consistency and effectively capture the essential characteristics\\nof the original objects.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.CV                            |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19493v1|Multi-Channel Acoustic Echo Cancellation Based on Direction-of-Arrival\\n  Estimation Acoustic echo cancellation (AEC) is an important speech signal processing\\ntechnology that can remove echoes from microphone signals to enable\\nnatural-sounding full-duplex speech communication. While single-channel AEC is\\nwidely adopted, multi-channel AEC can leverage spatial cues afforded by\\nmultiple microphones to achieve better performance. Existing multi-channel AEC\\napproaches typically combine beamforming with deep neural networks (DNN). This\\nwork proposes a two-stage algorithm that enhances multi-channel AEC by\\nincorporating sound source directional cues. Specifically, a lightweight DNN is\\nfirst trained to predict the sound source directions, and then the predicted\\ndirectional information, multi-channel microphone signals, and single-channel\\nfar-end signal are jointly fed into an AEC network to estimate the near-end\\nsignal. Evaluation results show that the proposed algorithm outperforms\\nbaseline approaches and exhibits robust generalization across diverse acoustic\\nenvironments.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.SD,eess.AS                    |eess.AS          |\n",
      "|http://arxiv.org/abs/2505.19494v1|Anveshana: A New Benchmark Dataset for Cross-Lingual Information\\n  Retrieval On English Queries and Sanskrit Documents The study presents a comprehensive benchmark for retrieving Sanskrit\\ndocuments using English queries, focusing on the chapters of the\\nSrimadbhagavatam. It employs a tripartite approach: Direct Retrieval (DR),\\nTranslation-based Retrieval (DT), and Query Translation (QT), utilizing shared\\nembedding spaces and advanced translation methods to enhance retrieval systems\\nin a RAG framework. The study fine-tunes state-of-the-art models for Sanskrit's\\nlinguistic nuances, evaluating models such as BM25, REPLUG, mDPR, ColBERT,\\nContriever, and GPT-2. It adapts summarization techniques for Sanskrit\\ndocuments to improve QA processing. Evaluation shows DT methods outperform DR\\nand QT in handling the cross-lingual challenges of ancient texts, improving\\naccessibility and understanding. A dataset of 3,400 English-Sanskrit\\nquery-document pairs underpins the study, aiming to preserve Sanskrit\\nscriptures and share their philosophical importance widely. Our dataset is\\npublicly available at https://huggingface.co/datasets/manojbalaji1/anveshana                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |cs.CL,cs.IR                      |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19495v1|The Role of Video Generation in Enhancing Data-Limited Action\\n  Understanding Video action understanding tasks in real-world scenarios always suffer data\\nlimitations. In this paper, we address the data-limited action understanding\\nproblem by bridging data scarcity. We propose a novel method that employs a\\ntext-to-video diffusion transformer to generate annotated data for model\\ntraining. This paradigm enables the generation of realistic annotated data on\\nan infinite scale without human intervention. We proposed the information\\nenhancement strategy and the uncertainty-based label smoothing tailored to\\ngenerate sample training. Through quantitative and qualitative analysis, we\\nobserved that real samples generally contain a richer level of information than\\ngenerated samples. Based on this observation, the information enhancement\\nstrategy is proposed to enhance the informative content of the generated\\nsamples from two aspects: the environments and the characters. Furthermore, we\\nobserved that some low-quality generated samples might negatively affect model\\ntraining. To address this, we devised the uncertainty-based label smoothing\\nstrategy to increase the smoothing of these samples, thus reducing their\\nimpact. We demonstrate the effectiveness of the proposed method on four\\ndatasets across five tasks and achieve state-of-the-art performance for\\nzero-shot action recognition.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |cs.CV                            |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19496v1|A Characterization of Reny's Weakly Sequentially Rational Equilibrium\\n  through $\\varepsilon$-Perfect $Œ≥$-Weakly Sequentially Rational\\n  Equilibrium A weakening of sequential rationality of sequential equilibrium yields Reny's\\n(1992) weakly sequentially rational equilibrium (WSRE) in extensive-form games.\\nWSRE requires Kreps and Wilson's (1982) consistent assessment to satisfy global\\nrationality of nonconvex payoff functions at every information set reachable by\\na player's own strategy. The consistent assessment demands a convergent\\nsequence of totally mixed behavioral strategy profiles and associated Bayesian\\nbeliefs. Nonetheless, due to the nonconvexity, proving the existence of WSRE\\nrequired invoking the existence of a normal-form perfect equilibrium, which is\\nsufficient but not necessary. Furthermore, Reny's WSRE definition does not\\nfully specify how to construct the convergent sequence. To overcome these\\nchallenges, this paper develops a characterization of WSRE through\\n$\\varepsilon$-perfect $\\gamma$-WSRE with local sequential rationality, which is\\naccomplished by incorporating an extra behavioral strategy profile. For any\\ngiven $\\gamma>0$, we generate a perfect $\\gamma$-WSRE as a limit point of a\\nsequence of $\\varepsilon_k$-perfect $\\gamma$-WSRE with $\\varepsilon_k\\to 0$. A\\nWSRE is then acquired from a limit point of a sequence of perfect\\n$\\gamma_q$-WSRE with $\\gamma_q\\to 0$. This characterization enables analytical\\nidentification of all WSREs in small extensive-form games and a direct proof of\\nthe existence of WSRE. An application of the characterization yields a\\npolynomial system that serves as a necessary and sufficient condition for\\nverifying whether a totally mixed assessment is an $\\varepsilon$-perfect\\n$\\gamma$-WSRE. Exploiting the system, we devise differentiable path-following\\nmethods to compute WSREs by establishing the existence of smooth paths, which\\nare secured from the equilibrium systems of barrier and penalty extensive-form\\ngames. Comprehensive numerical results further confirm the efficiency of the\\nmethods.|econ.TH                          |cs.GT            |\n",
      "+---------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-33-10.json\n",
      "\n",
      "========= 2025-05-29 21:33:20 =========\n",
      "+---------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |true_label                   |pred   |\n",
      "+---------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-------+\n",
      "|http://arxiv.org/abs/2505.19501v1|Genome-Bench: A Scientific Reasoning Benchmark from Real-World Expert\\n  Discussions In this short report, we present an automated pipeline tailored for the\\ngenomics domain and introduce \\textit{Genome-Bench}, a new benchmark\\nconstructed from over a decade of scientific forum discussions on genome\\nengineering. Our pipeline transforms raw interactions into a reinforcement\\nlearning friendly multiple-choice questions format, supported by 3000+ high\\nquality question answer pairs spanning foundational biology, experimental\\ntroubleshooting, tool usage, and beyond. To our knowledge, this is the first\\nend-to-end pipeline for teaching LLMs to reason from scientific discussions,\\nwith promising potential for generalization across scientific domains beyond\\nbiology.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.AI                        |cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19502v1|CODE-DITING: A Reasoning-Based Metric for Functional Alignment in Code\\n  Evaluation Trustworthy evaluation methods for code snippets play a crucial role in\\nneural code generation. Traditional methods, which either rely on reference\\nsolutions or require executable test cases, have inherent limitation in\\nflexibility and scalability. The recent LLM-as-Judge methodology offers a\\npromising alternative by directly evaluating functional consistency between the\\nproblem description and the generated code. To systematically understand the\\nlandscape of these LLM-as-Judge methods, we conduct a comprehensive empirical\\nstudy across three diverse datasets. Our investigation reveals the pros and\\ncons of two categories of LLM-as-Judge methods: the methods based on general\\nfoundation models can achieve good performance but require complex prompts and\\nlack explainability, while the methods based on reasoning foundation models\\nprovide better explainability with simpler prompts but demand substantial\\ncomputational resources due to their large parameter sizes. To address these\\nlimitations, we propose CODE-DITING, a novel code evaluation method that\\nbalances accuracy, efficiency and explainability. We develop a data\\ndistillation framework that effectively transfers reasoning capabilities from\\nDeepSeek-R1671B to our CODE-DITING 1.5B and 7B models, significantly enhancing\\nevaluation explainability and reducing the computational cost. With the\\nmajority vote strategy in the inference process, CODE-DITING 1.5B outperforms\\nall models with the same magnitude of parameters and achieves performance which\\nwould normally exhibit in a model with 5 times of parameter scale. CODE-DITING\\n7B surpasses GPT-4o and DeepSeek-V3 671B, even though it only uses 1% of the\\nparameter volume of these large models. Further experiments show that\\nCODEDITING is robust to preference leakage and can serve as a promising\\nalternative for code evaluation.           |cs.SE,cs.AI                  |cs.SE  |\n",
      "|http://arxiv.org/abs/2505.19503v1|Locality-Aware Zero-Shot Human-Object Interaction Detection Recent methods for zero-shot Human-Object Interaction (HOI) detection\\ntypically leverage the generalization ability of large Vision-Language Model\\n(VLM), i.e., CLIP, on unseen categories, showing impressive results on various\\nzero-shot settings. However, existing methods struggle to adapt CLIP\\nrepresentations for human-object pairs, as CLIP tends to overlook fine-grained\\ninformation necessary for distinguishing interactions. To address this issue,\\nwe devise, LAIN, a novel zero-shot HOI detection framework enhancing the\\nlocality and interaction awareness of CLIP representations. The locality\\nawareness, which involves capturing fine-grained details and the spatial\\nstructure of individual objects, is achieved by aggregating the information and\\nspatial priors of adjacent neighborhood patches. The interaction awareness,\\nwhich involves identifying whether and how a human is interacting with an\\nobject, is achieved by capturing the interaction pattern between the human and\\nthe object. By infusing locality and interaction awareness into CLIP\\nrepresentation, LAIN captures detailed information about the human-object\\npairs. Our extensive experiments on existing benchmarks show that LAIN\\noutperforms previous methods on various zero-shot settings, demonstrating the\\nimportance of locality and interaction awareness for effective zero-shot HOI\\ndetection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.CV                        |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19504v1|DOGe: Defensive Output Generation for LLM Protection Against Knowledge\\n  Distillation Large Language Models (LLMs) represent substantial intellectual and economic\\ninvestments, yet their effectiveness can inadvertently facilitate model\\nimitation via knowledge distillation (KD).In practical scenarios, competitors\\ncan distill proprietary LLM capabilities by simply observing publicly\\naccessible outputs, akin to reverse-engineering a complex performance by\\nobservation alone. Existing protective methods like watermarking only identify\\nimitation post-hoc, while other defenses assume the student model mimics the\\nteacher's internal logits, rendering them ineffective against distillation\\npurely from observed output text. This paper confronts the challenge of\\nactively protecting LLMs within the realistic constraints of API-based access.\\nWe introduce an effective and efficient Defensive Output Generation (DOGe)\\nstrategy that subtly modifies the output behavior of an LLM. Its outputs remain\\naccurate and useful for legitimate users, yet are designed to be misleading for\\ndistillation, significantly undermining imitation attempts. We achieve this by\\nfine-tuning only the final linear layer of the teacher LLM with an adversarial\\nloss. This targeted training approach anticipates and disrupts distillation\\nattempts during inference time. Our experiments show that, while preserving or\\neven improving the original performance of the teacher model, student models\\ndistilled from the defensively generated teacher outputs demonstrate\\ncatastrophically reduced performance, demonstrating our method's effectiveness\\nas a practical safeguard against KD-based model imitation.                                                                                                                                                                                                                                                                                    |cs.LG,cs.AI,cs.CL            |cs.CR  |\n",
      "|http://arxiv.org/abs/2505.19505v1|Hierarchical Tree Search-based User Lifelong Behavior Modeling on Large\\n  Language Model Large Language Models (LLMs) have garnered significant attention in\\nRecommendation Systems (RS) due to their extensive world knowledge and robust\\nreasoning capabilities. However, a critical challenge lies in enabling LLMs to\\neffectively comprehend and extract insights from massive user behaviors.\\nCurrent approaches that directly leverage LLMs for user interest learning face\\nlimitations in handling long sequential behaviors, effectively extracting\\ninterest, and applying interest in practical scenarios. To address these\\nissues, we propose a Hierarchical Tree Search-based User Lifelong Behavior\\nModeling framework (HiT-LBM). HiT-LBM integrates Chunked User Behavior\\nExtraction (CUBE) and Hierarchical Tree Search for Interest (HTS) to capture\\ndiverse interests and interest evolution of user. CUBE divides user lifelong\\nbehaviors into multiple chunks and learns the interest and interest evolution\\nwithin each chunk in a cascading manner. HTS generates candidate interests\\nthrough hierarchical expansion and searches for the optimal interest with\\nprocess rating model to ensure information gain for each behavior chunk.\\nAdditionally, we design Temporal-Ware Interest Fusion (TIF) to integrate\\ninterests from multiple behavior chunks, constructing a comprehensive\\nrepresentation of user lifelong interests. The representation can be embedded\\ninto any recommendation model to enhance performance. Extensive experiments\\ndemonstrate the effectiveness of our approach, showing that it surpasses\\nstate-of-the-art methods.                                                                                                                                                                                                                                                                                                                                                 |cs.IR,cs.AI                  |cs.IR  |\n",
      "|http://arxiv.org/abs/2505.19506v1|A Path Planning Algorithm for a Hybrid UAV Traveling in Noise Restricted\\n  Zones This paper presents an integrated approach for efficient path planning and\\nenergy management in hybrid unmanned aerial vehicles (HUAVs) equipped with dual\\nfuel-electric propulsion systems. These HUAVs operate in environments that\\ninclude noise-restricted zones, referred to as quiet zones, where only electric\\nmode is permitted. We address the problem by parameterizing the position of a\\npoint along the side of the quiet zone using its endpoints and a scalar\\nparameter, transforming the problem into a variant of finding the shortest path\\nover a graph of convex sets. We formulate this problem as a mixed-integer\\nconvex program (MICP), which can be efficiently solved using commercial\\nsolvers. Additionally, a tight lower bound can be obtained by relaxing the\\npath-selection variable. Through extensive computations across 200 instances\\nover four maps, we show a substantial improvement in computational efficiency\\nover a state-of-the-art method, achieving up to a 100-fold and 10-fold decrease\\nin computation time for calculating the lower bound and the exact solution,\\nrespectively. Moreover, the average gap between the exact cost and the lower\\nbound was approximately 0.24%, and the exact cost was 1.05% lower than the\\nfeasible solution from the state-of-the-art approach on average, highlighting\\nthe effectiveness of our method. We also extend our approach to plan the HUAV\\nroute to visit a set of targets and return to its starting location in\\nenvironments with quiet zones, yielding a Traveling Salesman Problem (TSP). We\\nemploy two methodologies to solve the TSP: one where the SOC at each target is\\ndiscretized, and another where it is assumed to be the minimum allowable level\\nupon departure. A comparative analysis reveals the second method achieves a\\ncost within 1.02% of the first on average while requiring significantly less\\ncomputational time.|math.OC                      |math.OC|\n",
      "|http://arxiv.org/abs/2505.19507v1|Multimodal Machine Translation with Visual Scene Graph Pruning Multimodal machine translation (MMT) seeks to address the challenges posed by\\nlinguistic polysemy and ambiguity in translation tasks by incorporating visual\\ninformation. A key bottleneck in current MMT research is the effective\\nutilization of visual data. Previous approaches have focused on extracting\\nglobal or region-level image features and using attention or gating mechanisms\\nfor multimodal information fusion. However, these methods have not adequately\\ntackled the issue of visual information redundancy in MMT, nor have they\\nproposed effective solutions. In this paper, we introduce a novel\\napproach--multimodal machine translation with visual Scene Graph Pruning (PSG),\\nwhich leverages language scene graph information to guide the pruning of\\nredundant nodes in visual scene graphs, thereby reducing noise in downstream\\ntranslation tasks. Through extensive comparative experiments with\\nstate-of-the-art methods and ablation studies, we demonstrate the effectiveness\\nof the PSG model. Our results also highlight the promising potential of visual\\ninformation pruning in advancing the field of MMT.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.CV,cs.LG                  |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19508v1|On Relative Biexactness of Amalgamated Free Product von Neumann Algebras We show that if $M_{1}, M_{2}$ are weakly exact tracial von Neumann algebras\\nadmitting a common injective amalgam $B$, then the amalgamated free product\\n$M_{1}\\overline{*}_{B}M_{2}$ is biexact relative to $\\{M_{1},M_{2}\\}$. When\\neach $ M_i $ is injective, we also show that the amalgmated free product is\\nbiexact relative to the amalgam $B$.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |math.OA                      |math.OA|\n",
      "|http://arxiv.org/abs/2505.19509v1|Benchmarking Multimodal Knowledge Conflict for Large Multimodal Models Large Multimodal Models(LMMs) face notable challenges when encountering\\nmultimodal knowledge conflicts, particularly under retrieval-augmented\\ngeneration(RAG) frameworks where the contextual information from external\\nsources may contradict the model's internal parametric knowledge, leading to\\nunreliable outputs. However, existing benchmarks fail to reflect such realistic\\nconflict scenarios. Most focus solely on intra-memory conflicts, while\\ncontext-memory and inter-context conflicts remain largely investigated.\\nFurthermore, commonly used factual knowledge-based evaluations are often\\noverlooked, and existing datasets lack a thorough investigation into conflict\\ndetection capabilities. To bridge this gap, we propose MMKC-Bench, a benchmark\\ndesigned to evaluate factual knowledge conflicts in both context-memory and\\ninter-context scenarios. MMKC-Bench encompasses three types of multimodal\\nknowledge conflicts and includes 1,573 knowledge instances and 3,381 images\\nacross 23 broad types, collected through automated pipelines with human\\nverification. We evaluate three representative series of LMMs on both model\\nbehavior analysis and conflict detection tasks. Our findings show that while\\ncurrent LMMs are capable of recognizing knowledge conflicts, they tend to favor\\ninternal parametric knowledge over external evidence. We hope MMKC-Bench will\\nfoster further research in multimodal knowledge conflict and enhance the\\ndevelopment of multimodal RAG systems. The source code is available at\\nhttps://github.com/MLLMKCBENCH/MLLMKC.                                                                                                                                                                                                                                                                                                                                                 |cs.LG,cs.AI                  |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19510v1|LLM Meets Scene Graph: Can Large Language Models Understand and Generate\\n  Scene Graphs? A Benchmark and Empirical Study The remarkable reasoning and generalization capabilities of Large Language\\nModels (LLMs) have paved the way for their expanding applications in embodied\\nAI, robotics, and other real-world tasks. To effectively support these\\napplications, grounding in spatial and temporal understanding in multimodal\\nenvironments is essential. To this end, recent works have leveraged scene\\ngraphs, a structured representation that encodes entities, attributes, and\\ntheir relationships in a scene. However, a comprehensive evaluation of LLMs'\\nability to utilize scene graphs remains limited. In this work, we introduce\\nText-Scene Graph (TSG) Bench, a benchmark designed to systematically assess\\nLLMs' ability to (1) understand scene graphs and (2) generate them from textual\\nnarratives. With TSG Bench we evaluate 11 LLMs and reveal that, while models\\nperform well on scene graph understanding, they struggle with scene graph\\ngeneration, particularly for complex narratives. Our analysis indicates that\\nthese models fail to effectively decompose discrete scenes from a complex\\nnarrative, leading to a bottleneck when generating scene graphs. These findings\\nunderscore the need for improved methodologies in scene graph generation and\\nprovide valuable insights for future research. The demonstration of our\\nbenchmark is available at https://tsg-bench.netlify.app. Additionally, our code\\nand evaluation data are publicly available at\\nhttps://anonymous.4open.science/r/TSG-Bench.                                                                                                                                                                                                                                                                                                                                                                              |cs.CL                        |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19511v1|Causal Distillation: Transferring Structured Explanations from Large to\\n  Compact Language Models Large proprietary language models exhibit strong causal reasoning abilities\\nthat smaller open-source models struggle to replicate. We introduce a novel\\nframework for distilling causal explanations that transfers causal reasoning\\nskills from a powerful teacher model to a compact open-source model. The key\\nidea is to train the smaller model to develop causal reasoning abilities by\\ngenerating structured cause-and-effect explanations consistent with those of\\nthe teacher model. To evaluate the quality of the student-generated\\nexplanations, we introduce a new metric called Causal Explanation Coherence\\n(CEC) to assess the structural and logical consistency of causal reasoning.\\nThis metric uses sentence-level semantic alignment to measure how well each\\npart of the generated explanation corresponds to the teacher's reference,\\ncapturing both faithfulness and coverage of the underlying causal chain. Our\\nframework and the CEC metric provide a principled foundation for training\\nsmaller models to perform robust causal reasoning and for systematically\\nassessing the coherence of explanations in language model outputs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.CL                        |cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19512v1|LLA-MPC: Fast Adaptive Control for Autonomous Racing We present Look-Back and Look-Ahead Adaptive Model Predictive Control\\n(LLA-MPC), a real-time adaptive control framework for autonomous racing that\\naddresses the challenge of rapidly changing tire-surface interactions. Unlike\\nexisting approaches requiring substantial data collection or offline training,\\nLLA-MPC employs a model bank for immediate adaptation without a learning\\nperiod. It integrates two key mechanisms: a look-back window that evaluates\\nrecent vehicle behavior to select the most accurate model and a look-ahead\\nhorizon that optimizes trajectory planning based on the identified dynamics.\\nThe selected model and estimated friction coefficient are then incorporated\\ninto a trajectory planner to optimize reference paths in real-time. Experiments\\nacross diverse racing scenarios demonstrate that LLA-MPC outperforms\\nstate-of-the-art methods in adaptation speed and handling, even during sudden\\nfriction transitions. Its learning-free, computationally efficient design\\nenables rapid adaptation, making it ideal for high-speed autonomous racing in\\nmulti-surface environments.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |cs.RO,cs.SY,eess.SY          |cs.RO  |\n",
      "|http://arxiv.org/abs/2505.19513v1|Ring artifacts correction method in x-ray computed tomography based on\\n  stripe classification and removal in sinogram images X-ray computed tomography (CT) is widely utilized in the medical, industrial,\\nand other fields to nondestructively generate three-dimensional structural\\nimages of objects. However, CT images are often affected by various artifacts,\\nwith ring artifacts being a common occurrence that significantly compromises\\nimage quality and subsequent structural interpretation. In this study, a ring\\nartifact correction method based on stripe classification and removal in\\nsinogram images was proposed. The proposed method classifies ring artifacts\\ninto single stripes and multiple stripes, which were identified and eliminated\\nusing median filtering and multiphase decomposition, respectively. A novel\\nalgorithm combining median filtering, polyphase decomposition and median\\nfiltering was further developed to eliminate all forms of stripes\\nsimultaneously and effectively. The efficacy of the proposed method was\\nvalidated through both simulated and experimental CT data. The study provides a\\nnovel perspective and integrated approach to addressing ring artifacts in X-ray\\nCT. It will be of significant illuminating to a diverse readership, including\\nradiologists, clinical researchers, and industrial scientists.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |physics.med-ph,physics.optics|eess.IV|\n",
      "|http://arxiv.org/abs/2505.19514v1|SIPDO: Closed-Loop Prompt Optimization via Synthetic Data Feedback Prompt quality plays a critical role in the performance of large language\\nmodels (LLMs), motivating a growing body of work on prompt optimization. Most\\nexisting methods optimize prompts over a fixed dataset, assuming static input\\ndistributions and offering limited support for iterative improvement. We\\nintroduce SIPDO (Self-Improving Prompts through Data-Augmented Optimization), a\\nclosed-loop framework for prompt learning that integrates synthetic data\\ngeneration into the optimization process. SIPDO couples a synthetic data\\ngenerator with a prompt optimizer, where the generator produces new examples\\nthat reveal current prompt weaknesses and the optimizer incrementally refines\\nthe prompt in response. This feedback-driven loop enables systematic\\nimprovement of prompt performance without assuming access to external\\nsupervision or new tasks. Experiments across question answering and reasoning\\nbenchmarks show that SIPDO outperforms standard prompt tuning methods,\\nhighlighting the value of integrating data synthesis into prompt learning\\nworkflows.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cs.CL,cs.AI,cs.LG            |cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19515v1|Bias in Political Dialogue: Tagging U.S. Presidential Debates with an\\n  Extended DAMSL Framework We present a critical discourse analysis of the 2024 U.S. presidential\\ndebates, examining Donald Trump's rhetorical strategies in his interactions\\nwith Joe Biden and Kamala Harris. We introduce a novel annotation framework,\\nBEADS (Bias Enriched Annotation for Dialogue Structure), which systematically\\nextends the DAMSL framework to capture bias driven and adversarial discourse\\nfeatures in political communication. BEADS includes a domain and language\\nagnostic set of tags that model ideological framing, emotional appeals, and\\nconfrontational tactics. Our methodology compares detailed human annotation\\nwith zero shot ChatGPT assisted tagging on verified transcripts from the Trump\\nand Biden (19,219 words) and Trump and Harris (18,123 words) debates. Our\\nanalysis shows that Trump consistently dominated in key categories: Challenge\\nand Adversarial Exchanges, Selective Emphasis, Appeal to Fear, Political Bias,\\nand Perceived Dismissiveness. These findings underscore his use of emotionally\\ncharged and adversarial rhetoric to control the narrative and influence\\naudience perception. In this work, we establish BEADS as a scalable and\\nreproducible framework for critical discourse analysis across languages,\\ndomains, and political contexts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.CL                        |cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19516v1|DiffE2E: Rethinking End-to-End Driving with a Hybrid Action Diffusion\\n  and Supervised Policy End-to-end learning has emerged as a transformative paradigm in autonomous\\ndriving. However, the inherently multimodal nature of driving behaviors and the\\ngeneralization challenges in long-tail scenarios remain critical obstacles to\\nrobust deployment. We propose DiffE2E, a diffusion-based end-to-end autonomous\\ndriving framework. This framework first performs multi-scale alignment of\\nmulti-sensor perception features through a hierarchical bidirectional\\ncross-attention mechanism. It then introduces a novel class of hybrid\\ndiffusion-supervision decoders based on the Transformer architecture, and\\nadopts a collaborative training paradigm that seamlessly integrates the\\nstrengths of both diffusion and supervised policy. DiffE2E models structured\\nlatent spaces, where diffusion captures the distribution of future trajectories\\nand supervision enhances controllability and robustness. A global condition\\nintegration module enables deep fusion of perception features with high-level\\ntargets, significantly improving the quality of trajectory generation.\\nSubsequently, a cross-attention mechanism facilitates efficient interaction\\nbetween integrated features and hybrid latent variables, promoting the joint\\noptimization of diffusion and supervision objectives for structured output\\ngeneration, ultimately leading to more robust control. Experiments demonstrate\\nthat DiffE2E achieves state-of-the-art performance in both CARLA closed-loop\\nevaluations and NAVSIM benchmarks. The proposed integrated\\ndiffusion-supervision policy offers a generalizable paradigm for hybrid action\\nrepresentation, with strong potential for extension to broader domains\\nincluding embodied intelligence. More details and visualizations are available\\nat \\href{https://infinidrive.github.io/DiffE2E/}{project website}.                                                        |cs.RO                        |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19517v1|Synchronous Models and Fundamental Systems in Observer Design This paper introduces the concept of a synchronous model as an extension of\\nthe internal model concept used in observer design for dynamical systems. A\\nsystem is said to contain a synchronous model of another if there is a suitable\\nerror function between the two systems that remains stationary for all of the\\ntrajectories of the two systems. A system is said to admit a synchronous lift\\nif a second system containing a synchronous model exists. We provide necessary\\nand sufficient conditions that a system admits a synchronous lift and provide a\\nmethod to construct a (there may be many) lifted system should one exist. We\\ncharacterise the class of all systems that admit a synchronous lift by showing\\nthat they consist of fundamental vector fields induced by a Lie group action, a\\nclass of system we term fundamental systems. For fundamental systems we propose\\na simple synchronous observer design methodology, for which we show how\\ncorrection terms can be discretised and combined easily, facilitating global\\ncharacterisation of convergence and performance. Finally, we provide three\\nexamples to demonstrate the key concepts of synchrony, symmetry construction,\\nand observer design for a fundamental system.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |eess.SY,cs.SY                |eess.SY|\n",
      "|http://arxiv.org/abs/2505.19518v1|Toward Patient-specific Partial Point Cloud to Surface Completion for\\n  Pre- to Intra-operative Registration in Image-guided Liver Interventions Intra-operative data captured during image-guided surgery lacks sub-surface\\ninformation, where key regions of interest, such as vessels and tumors, reside.\\nImage-to-physical registration enables the fusion of pre-operative information\\nand intra-operative data, typically represented as a point cloud. However, this\\nregistration process struggles due to partial visibility of the intra-operative\\npoint cloud. In this research, we propose a patient-specific point cloud\\ncompletion approach to assist with the registration process. Specifically, we\\nleverage VN-OccNet to generate a complete liver surface from a partial\\nintra-operative point cloud. The network is trained in a patient-specific\\nmanner, where simulated deformations from the pre-operative model are used to\\ntrain the model. First, we conduct an in-depth analysis of VN-OccNet's\\nrotation-equivariant property and its effectiveness in recovering complete\\nsurfaces from partial intra-operative surfaces. Next, we integrate the\\ncompleted intra-operative surface into the Go-ICP registration algorithm to\\ndemonstrate its utility in improving initial rigid registration outcomes. Our\\nresults highlight the promise of this patient-specific completion approach in\\nmitigating the challenges posed by partial intra-operative visibility. The\\nrotation equivariant and surface generation capabilities of VN-OccNet hold\\nstrong promise for developing robust registration frameworks for variations of\\nthe intra-operative point cloud.                                                                                                                                                                                                                                                                                                                                  |cs.CV                        |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19519v1|Regularized Personalization of Text-to-Image Diffusion Models without\\n  Distributional Drift Personalization using text-to-image diffusion models involves adapting a\\npretrained model to novel subjects with only a few image examples. This task\\npresents a fundamental challenge, as the model must not only learn the new\\nsubject effectively but also preserve its ability to generate diverse and\\ncoherent outputs across a wide range of prompts. In other words, successful\\npersonalization requires integrating new concepts without forgetting previously\\nlearned generative capabilities. Forgetting denotes unintended distributional\\ndrift, where the model's output distribution deviates from that of the original\\npretrained model. In this paper, we provide an analysis of this issue and\\nidentify a mismatch between standard training objectives and the goals of\\npersonalization. To address this, we propose a new training objective based on\\na Lipschitz-bounded formulation that explicitly constrains deviation from the\\npretrained distribution. Our method provides improved control over\\ndistributional drift and performs well even in data-scarce scenarios.\\nExperimental results demonstrate that our approach consistently outperforms\\nexisting personalization methods, achieving higher CLIP-T, CLIP-I, and DINO\\nscores.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CV                        |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19520v1|Equivalence of Connected and Peak-Pit Maximal Condorcet Domains This paper provides a combinatorial proof to show that, in the study of\\nmaximal Condorcet domains, the class of peak-pit Condorcet domains, the class\\nof connected Condorcet domains, and the class of directly connected Condorcet\\ndomains are all equivalent.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |math.CO                      |math.CO|\n",
      "+---------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-33-20.json\n",
      "\n",
      "========= 2025-05-29 21:33:30 =========\n",
      "+---------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |true_label                   |pred   |\n",
      "+---------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-------+\n",
      "|http://arxiv.org/abs/2505.19526v1|Sharpness of the Mockenhaupt-Mitsis-Bak-Seeger Fourier restriction\\n  theorem in all dimensions We prove the optimality of the exponent in the Mockenhaupt-Mitsis-Bak-Seeger\\nFourier restriction theorem in all dimensions $d$ and the full parameter range\\n$0 < a,b < d$. Our construction is deterministic and also yields Salem sets.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |math.CA,math.NT              |math.FA|\n",
      "|http://arxiv.org/abs/2505.19527v1|Navigating loss manifolds via rigid body dynamics: A promising avenue\\n  for robustness and generalisation Training large neural networks through gradient-based optimization requires\\nnavigating high-dimensional loss landscapes, which often exhibit pathological\\ngeometry, leading to undesirable training dynamics. In particular, poor\\ngeneralization frequently results from convergence to sharp minima that are\\nhighly sensitive to input perturbations, causing the model to overfit the\\ntraining data while failing to generalize to unseen examples. Furthermore,\\nthese optimization procedures typically display strong dependence on the fine\\nstructure of the loss landscape, leading to unstable training dynamics, due to\\nthe fractal-like nature of the loss surface. In this work, we propose an\\nalternative optimizer that simultaneously reduces this dependence, and avoids\\nsharp minima, thereby improving generalization. This is achieved by simulating\\nthe motion of the center of a ball rolling on the loss landscape. The degree to\\nwhich our optimizer departs from the standard gradient descent is controlled by\\na hyperparameter, representing the radius of the ball. Changing this\\nhyperparameter allows for probing the loss landscape at different scales,\\nmaking it a valuable tool for understanding its geometry.                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.LG,cs.AI,math.OC          |cs.LG  |\n",
      "|http://arxiv.org/abs/2505.19528v1|AmpleHate: Amplifying the Attention for Versatile Implicit Hate\\n  Detection Implicit hate speech detection is challenging due to its subtlety and\\nreliance on contextual interpretation rather than explicit offensive words.\\nCurrent approaches rely on contrastive learning, which are shown to be\\neffective on distinguishing hate and non-hate sentences. Humans, however,\\ndetect implicit hate speech by first identifying specific targets within the\\ntext and subsequently interpreting how these target relate to their surrounding\\ncontext. Motivated by this reasoning process, we propose AmpleHate, a novel\\napproach designed to mirror human inference for implicit hate detection.\\nAmpleHate identifies explicit target using a pretrained Named Entity\\nRecognition model and capture implicit target information via [CLS] tokens. It\\ncomputes attention-based relationships between explicit, implicit targets and\\nsentence context and then, directly injects these relational vectors into the\\nfinal sentence representation. This amplifies the critical signals of\\ntarget-context relations for determining implicit hate. Experiments demonstrate\\nthat AmpleHate achieves state-of-the-art performance, outperforming contrastive\\nlearning baselines by an average of 82.14% and achieve faster convergence.\\nQualitative analyses further reveal that attention patterns produced by\\nAmpleHate closely align with human judgement, underscoring its interpretability\\nand robustness.                                                                                                                                                                                                                                                                   |cs.CL,cs.AI,cs.CY,I.2.7      |cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19529v1|Small Language Models: Architectures, Techniques, Evaluation, Problems\\n  and Future Adaptation Small Language Models (SLMs) have gained substantial attention due to their\\nability to execute diverse language tasks successfully while using fewer\\ncomputer resources. These models are particularly ideal for deployment in\\nlimited environments, such as mobile devices, on-device processing, and edge\\nsystems. In this study, we present a complete assessment of SLMs, focussing on\\ntheir design frameworks, training approaches, and techniques for lowering model\\nsize and complexity. We offer a novel classification system to organize the\\noptimization approaches applied for SLMs, encompassing strategies like pruning,\\nquantization, and model compression. Furthermore, we assemble SLM's studies of\\nevaluation suite with some existing datasets, establishing a rigorous platform\\nfor measuring SLM capabilities. Alongside this, we discuss the important\\ndifficulties that remain unresolved in this sector, including trade-offs\\nbetween efficiency and performance, and we suggest directions for future study.\\nWe anticipate this study to serve as a beneficial guide for researchers and\\npractitioners who aim to construct compact, efficient, and high-performing\\nlanguage models.                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CL                        |cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19530v1|Heavy lifting tasks via haptic teleoperation of a wheeled humanoid Humanoid robots can support human workers in physically demanding\\nenvironments by performing tasks that require whole-body coordination, such as\\nlifting and transporting heavy objects.These tasks, which we refer to as\\nDynamic Mobile Manipulation (DMM), require the simultaneous control of\\nlocomotion, manipulation, and posture under dynamic interaction forces. This\\npaper presents a teleoperation framework for DMM on a height-adjustable wheeled\\nhumanoid robot for carrying heavy payloads. A Human-Machine Interface (HMI)\\nenables whole-body motion retargeting from the human pilot to the robot by\\ncapturing the motion of the human and applying haptic feedback. The pilot uses\\nbody motion to regulate robot posture and locomotion, while arm movements guide\\nmanipulation.Real time haptic feedback delivers end effector wrenches and\\nbalance related cues, closing the loop between human perception and robot\\nenvironment interaction. We evaluate the different telelocomotion mappings that\\noffer varying levels of balance assistance, allowing the pilot to either\\nmanually or automatically regulate the robot's lean in response to\\npayload-induced disturbances. The system is validated in experiments involving\\ndynamic lifting of barbells and boxes up to 2.5 kg (21% of robot mass),\\ndemonstrating coordinated whole-body control, height variation, and disturbance\\nhandling under pilot guidance. Video demo can be found at:\\nhttps://youtu.be/jF270_bG1h8?feature=shared                                                                                                                                                                                        |cs.RO                        |cs.RO  |\n",
      "|http://arxiv.org/abs/2505.19531v1|Minimalist Softmax Attention Provably Learns Constrained Boolean\\n  Functions We study the computational limits of learning $k$-bit Boolean functions\\n(specifically, $\\mathrm{AND}$, $\\mathrm{OR}$, and their noisy variants), using\\na minimalist single-head softmax-attention mechanism, where $k=\\Theta(d)$\\nrelevant bits are selected from $d$ inputs. We show that these simple\\n$\\mathrm{AND}$ and $\\mathrm{OR}$ functions are unsolvable with a single-head\\nsoftmax-attention mechanism alone. However, with teacher forcing, the same\\nminimalist attention is capable of solving them. These findings offer two key\\ninsights: Architecturally, solving these Boolean tasks requires only minimalist\\nattention, without deep Transformer blocks or FFNs. Methodologically, one\\ngradient descent update with supervision suffices and replaces the multi-step\\nChain-of-Thought (CoT) reasoning scheme of [Kim and Suzuki, ICLR 2025] for\\nsolving Boolean problems. Together, the bounds expose a fundamental gap between\\nwhat this minimal architecture achieves under ideal supervision and what is\\nprovably impossible under standard training.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |cs.LG,cs.AI,stat.ML          |cs.LG  |\n",
      "|http://arxiv.org/abs/2505.19532v1|Fox in the Henhouse: Supply-Chain Backdoor Attacks Against Reinforcement\\n  Learning The current state-of-the-art backdoor attacks against Reinforcement Learning\\n(RL) rely upon unrealistically permissive access models, that assume the\\nattacker can read (or even write) the victim's policy parameters, observations,\\nor rewards. In this work, we question whether such a strong assumption is\\nrequired to launch backdoor attacks against RL. To answer this question, we\\npropose the \\underline{S}upply-\\underline{C}h\\underline{a}in\\n\\underline{B}ackdoor (SCAB) attack, which targets a common RL workflow:\\ntraining agents using external agents that are provided separately or embedded\\nwithin the environment. In contrast to prior works, our attack only relies on\\nlegitimate interactions of the RL agent with the supplied agents. Despite this\\nlimited access model, by poisoning a mere $3\\%$ of training experiences, our\\nattack can successfully activate over $90\\%$ of triggered actions, reducing the\\naverage episodic return by $80\\%$ for the victim. Our novel attack demonstrates\\nthat RL attacks are likely to become a reality under untrusted RL training\\nsupply-chains.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |cs.LG                        |cs.CR  |\n",
      "|http://arxiv.org/abs/2505.19533v1|ExAnte: A Benchmark for Ex-Ante Inference in Large Language Models Large language models (LLMs) face significant challenges in ex-ante\\nreasoning, where analysis, inference, or predictions must be made without\\naccess to information from future events. Even with explicit prompts enforcing\\ntemporal cutoffs, LLMs often generate outputs influenced by internalized\\nknowledge of events beyond the specified cutoff. This paper introduces a novel\\ntask and benchmark designed to evaluate the ability of LLMs to reason while\\nadhering to such temporal constraints. The benchmark includes a variety of\\ntasks: stock prediction, Wikipedia event prediction, scientific publication\\nprediction, and Question Answering (QA), designed to assess factual knowledge\\nunder temporal cutoff constraints. We use leakage rate to quantify models'\\nreliance on future information beyond cutoff timestamps. Experimental results\\nreveal that LLMs struggle to consistently adhere to temporal cutoffs across\\ncommon prompting strategies and tasks, demonstrating persistent challenges in\\nex-ante reasoning. This benchmark provides a potential evaluation framework to\\nadvance the development of LLMs' temporal reasoning ability for time-sensitive\\napplications.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |cs.LG                        |cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19534v1|Training-Free Multi-Step Audio Source Separation Audio source separation aims to separate a mixture into target sources.\\nPrevious audio source separation systems usually conduct one-step inference,\\nwhich does not fully explore the separation ability of models. In this work, we\\nreveal that pretrained one-step audio source separation models can be leveraged\\nfor multi-step separation without additional training. We propose a simple yet\\neffective inference method that iteratively applies separation by optimally\\nblending the input mixture with the previous step's separation result. At each\\nstep, we determine the optimal blending ratio by maximizing a metric. We prove\\nthat our method always yield improvement over one-step inference, provide error\\nbounds based on model smoothness and metric robustness, and provide theoretical\\nanalysis connecting our method to denoising along linear interpolation paths\\nbetween noise and clean distributions, a property we link to denoising\\ndiffusion bridge models. Our approach effectively delivers improved separation\\nperformance as a \"free lunch\" from existing models. Our empirical results\\ndemonstrate that our multi-step separation approach consistently outperforms\\none-step inference across both speech enhancement and music source separation\\ntasks, and can achieve scaling performance similar to training a larger model,\\nusing more data, or in some cases employing a multi-step training objective.\\nThese improvements appear not only on the optimization metric during multi-step\\ninference, but also extend to nearly all non-optimized metrics (with one\\nexception). We also discuss limitations of our approach and directions for\\nfuture research.                   |cs.SD,cs.AI,cs.LG,eess.AS    |cs.SD  |\n",
      "|http://arxiv.org/abs/2505.19535v1|TDVE-Assessor: Benchmarking and Evaluating the Quality of Text-Driven\\n  Video Editing with LMMs Text-driven video editing is rapidly advancing, yet its rigorous evaluation\\nremains challenging due to the absence of dedicated video quality assessment\\n(VQA) models capable of discerning the nuances of editing quality. To address\\nthis critical gap, we introduce TDVE-DB, a large-scale benchmark dataset for\\ntext-driven video editing. TDVE-DB consists of 3,857 edited videos generated\\nfrom 12 diverse models across 8 editing categories, and is annotated with\\n173,565 human subjective ratings along three crucial dimensions, i.e., edited\\nvideo quality, editing alignment, and structural consistency. Based on TDVE-DB,\\nwe first conduct a comprehensive evaluation for the 12 state-of-the-art editing\\nmodels revealing the strengths and weaknesses of current video techniques, and\\nthen benchmark existing VQA methods in the context of text-driven video editing\\nevaluation. Building on these insights, we propose TDVE-Assessor, a novel VQA\\nmodel specifically designed for text-driven video editing assessment.\\nTDVE-Assessor integrates both spatial and temporal video features into a large\\nlanguage model (LLM) for rich contextual understanding to provide comprehensive\\nquality assessment. Extensive experiments demonstrate that TDVE-Assessor\\nsubstantially outperforms existing VQA models on TDVE-DB across all three\\nevaluation dimensions, setting a new state-of-the-art. Both TDVE-DB and\\nTDVE-Assessor will be released upon the publication.                                                                                                                                                                                  |cs.CV                        |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19536v1|FlowCut: Rethinking Redundancy via Information Flow for Efficient\\n  Vision-Language Models Large vision-language models (LVLMs) excel at multimodal understanding but\\nsuffer from high computational costs due to redundant vision tokens. Existing\\npruning methods typically rely on single-layer attention scores to rank and\\nprune redundant visual tokens to solve this inefficiency. However, as the\\ninteraction between tokens and layers is complicated, this raises a basic\\nquestion: Is such a simple single-layer criterion sufficient to identify\\nredundancy? To answer this question, we rethink the emergence of redundant\\nvisual tokens from a fundamental perspective: information flow, which models\\nthe interaction between tokens and layers by capturing how information moves\\nbetween tokens across layers. We find (1) the CLS token acts as an information\\nrelay, which can simplify the complicated flow analysis; (2) the redundancy\\nemerges progressively and dynamically via layer-wise attention concentration;\\nand (3) relying solely on attention scores from single layers can lead to\\ncontradictory redundancy identification. Based on this, we propose FlowCut, an\\ninformation-flow-aware pruning framework, mitigating the insufficiency of the\\ncurrent criterion for identifying redundant tokens and better aligning with the\\nmodel's inherent behaviors. Extensive experiments show that FlowCut achieves\\nsuperior results, outperforming SoTA by 1.6% on LLaVA-1.5-7B with 88.9% token\\nreduction, and by 4.3% on LLaVA-NeXT-7B with 94.4% reduction, delivering 3.2x\\nspeed-up in the prefilling stage. Our code is available at\\nhttps://github.com/TungChintao/FlowCut                                                              |cs.CV,cs.AI,cs.CL            |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19537v1|Continuous-Time Analysis of Heavy Ball Momentum in Min-Max Games Since Polyak's pioneering work, heavy ball (HB) momentum has been widely\\nstudied in minimization. However, its role in min-max games remains largely\\nunexplored. As a key component of practical min-max algorithms like Adam, this\\ngap limits their effectiveness. In this paper, we present a continuous-time\\nanalysis for HB with simultaneous and alternating update schemes in min-max\\ngames. Locally, we prove smaller momentum enhances algorithmic stability by\\nenabling local convergence across a wider range of step sizes, with alternating\\nupdates generally converging faster. Globally, we study the implicit\\nregularization of HB, and find smaller momentum guides algorithms trajectories\\ntowards shallower slope regions of the loss landscapes, with alternating\\nupdates amplifying this effect. Surprisingly, all these phenomena differ from\\nthose observed in minimization, where larger momentum yields similar effects.\\nOur results reveal fundamental differences between HB in min-max games and\\nminimization, and numerical experiments further validate our theoretical\\nresults.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |cs.GT,cs.LG                  |math.OC|\n",
      "|http://arxiv.org/abs/2505.19538v1|DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through\\n  Textual Gradients Existing medical RAG systems mainly leverage knowledge from medical knowledge\\nbases, neglecting the crucial role of experiential knowledge derived from\\nsimilar patient cases -- a key component of human clinical reasoning. To bridge\\nthis gap, we propose DoctorRAG, a RAG framework that emulates doctor-like\\nreasoning by integrating both explicit clinical knowledge and implicit\\ncase-based experience. DoctorRAG enhances retrieval precision by first\\nallocating conceptual tags for queries and knowledge sources, together with a\\nhybrid retrieval mechanism from both relevant knowledge and patient. In\\naddition, a Med-TextGrad module using multi-agent textual gradients is\\nintegrated to ensure that the final output adheres to the retrieved knowledge\\nand patient query. Comprehensive experiments on multilingual, multitask\\ndatasets demonstrate that DoctorRAG significantly outperforms strong baseline\\nRAG models and gains improvements from iterative refinements. Our approach\\ngenerates more accurate, relevant, and comprehensive responses, taking a step\\ntowards more doctor-like medical reasoning systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.CL,cs.AI,cs.CE,cs.IR,cs.MA|cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19539v1|Water Level Sensing via Communication Signals in a Bi-Static System Accurate water level sensing is essential for flood monitoring, agricultural\\nirrigation, and water resource optimization. Traditional methods require\\ndedicated sensor deployments, leading to high installation costs, vulnerability\\nto interference, and limited resolution. This work proposes PMNs-WaterSense, a\\nnovel scheme leveraging Channel State Information (CSI) from existing mobile\\nnetworks for water level sensing. Our scheme begins with a CSI-power method to\\neliminate phase offsets caused by clock asynchrony in bi-static systems. We\\nthen apply multi-domain filtering across the time (Doppler), frequency (delay),\\nand spatial (Angle-of-Arrival, AoA) domains to extract phase features that\\nfinely capture variations in path length over water. To resolve the $2\\pi$\\nphase ambiguity, we introduce a Kalman filter-based unwrapping technique.\\nAdditionally, we exploit transceiver geometry to convert path length variations\\ninto water level height changes, even with limited antenna configurations. We\\nvalidate our framework through controlled experiments with 28 GHz mmWave and\\n3.1 GHz LTE signals in real time, achieving average height estimation errors of\\n0.025 cm and 0.198 cm, respectively. Moreover, real-world river monitoring with\\n2.6 GHz LTE signals achieves an average error of 4.8 cm for a 1-meter water\\nlevel change, demonstrating its effectiveness in practical deployments.                                                                                                                                                                                                                                                               |eess.SP                      |eess.SP|\n",
      "|http://arxiv.org/abs/2505.19540v1|Real-time Whole-body Model Predictive Control for Bipedal Locomotion\\n  with a Novel Kino-dynamic Model and Warm-start Method Advancements in optimization solvers and computing power have led to growing\\ninterest in applying whole-body model predictive control (WB-MPC) to bipedal\\nrobots. However, the high degrees of freedom and inherent model complexity of\\nbipedal robots pose significant challenges in achieving fast and stable control\\ncycles for real-time performance. This paper introduces a novel kino-dynamic\\nmodel and warm-start strategy for real-time WB-MPC in bipedal robots. Our\\nproposed kino-dynamic model combines the linear inverted pendulum plus flywheel\\nand full-body kinematics model. Unlike the conventional whole-body model that\\nrely on the concept of contact wrenches, our model utilizes the zero-moment\\npoint (ZMP), reducing baseline computational costs and ensuring consistently\\nlow latency during contact state transitions. Additionally, a modularized\\nmulti-layer perceptron (MLP) based warm-start strategy is proposed, leveraging\\na lightweight neural network to provide a good initial guess for each control\\ncycle. Furthermore, we present a ZMP-based whole-body controller (WBC) that\\nextends the existing WBC for explicitly controlling impulses and ZMP,\\nintegrating it into the real-time WB-MPC framework. Through various comparative\\nexperiments, the proposed kino-dynamic model and warm-start strategy have been\\nshown to outperform previous studies. Simulations and real robot experiments\\nfurther validate that the proposed framework demonstrates robustness to\\nperturbation and satisfies real-time control requirements during walking.                                                  |cs.RO                        |cs.RO  |\n",
      "|http://arxiv.org/abs/2505.19541v1|An effective upper bound for Fano indices of canonical Fano threefolds,\\n  I Let $X$ be a $\\mathbb Q$-factorial weak Fano $3$-fold with at worst isolated\\ncanonical singularities. We show that the $\\mathbb Q$-Fano index of $X$ is at\\nmost $61$.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |math.AG                      |math.AG|\n",
      "|http://arxiv.org/abs/2505.19542v1|Mazur's growth number conjecture and congruences Motivated by the work of Greenberg-Vatsal and Emerton-Pollack-Weston, I\\ninvestigate the extent to which Mazur's conjecture on the growth of Selmer\\nranks in $\\mathbb{Z}_p$-extensions of an imaginary quadratic field persists\\nunder $p$-congruences between Galois representations. As a first step, I\\nestablish Mazur's conjecture for certain triples $(E, K, p)$ under explicit\\nhypotheses. Building on this, I prove analogous results for Greenberg Selmer\\ngroups attached to modular forms that are congruent mod $p$ to $E$, including\\nall specializations arising from Hida families of fixed tame level. In\\nparticular, I show that the Mordell-Weil ranks in non-anticyclotomic\\n$\\mathbb{Z}_p$-extensions of $K$ remain bounded for elliptic curves $E'$ such\\nthat $E[p]$ and $E'[p]$ are isomorphic as Galois modules.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |math.NT                      |math.NT|\n",
      "|http://arxiv.org/abs/2505.19543v1|Cuff-KT: Tackling Learners' Real-time Learning Pattern Adjustment via\\n  Tuning-Free Knowledge State Guided Model Updating Knowledge Tracing (KT) is a core component of Intelligent Tutoring Systems,\\nmodeling learners' knowledge state to predict future performance and provide\\npersonalized learning support. Traditional KT models assume that learners'\\nlearning abilities remain relatively stable over short periods or change in\\npredictable ways based on prior performance. However, in reality, learners'\\nabilities change irregularly due to factors like cognitive fatigue, motivation,\\nand external stress -- a task introduced, which we refer to as Real-time\\nLearning Pattern Adjustment (RLPA). Existing KT models, when faced with RLPA,\\nlack sufficient adaptability, because they fail to timely account for the\\ndynamic nature of different learners' evolving learning patterns. Current\\nstrategies for enhancing adaptability rely on retraining, which leads to\\nsignificant overfitting and high time overhead issues. To address this, we\\npropose Cuff-KT, comprising a controller and a generator. The controller\\nassigns value scores to learners, while the generator generates personalized\\nparameters for selected learners. Cuff-KT controllably adapts to data changes\\nfast and flexibly without fine-tuning. Experiments on five datasets from\\ndifferent subjects demonstrate that Cuff-KT significantly improves the\\nperformance of five KT models with different structures under intra- and\\ninter-learner shifts, with an average relative increase in AUC of 10% and 4%,\\nrespectively, at a negligible time cost, effectively tackling RLPA task. Our\\ncode and datasets are fully available at https://github.com/zyy-2001/Cuff-KT.|cs.LG,cs.IR                  |cs.LG  |\n",
      "|http://arxiv.org/abs/2505.19544v1|Unlocking the Power of Diffusion Models in Sequential Recommendation: A\\n  Simple and Effective Approach In this paper, we focus on the often-overlooked issue of embedding collapse\\nin existing diffusion-based sequential recommendation models and propose ADRec,\\nan innovative framework designed to mitigate this problem. Diverging from\\nprevious diffusion-based methods, ADRec applies an independent noise process to\\neach token and performs diffusion across the entire target sequence during\\ntraining. ADRec captures token interdependency through auto-regression while\\nmodeling per-token distributions through token-level diffusion. This dual\\napproach enables the model to effectively capture both sequence dynamics and\\nitem representations, overcoming the limitations of existing methods. To\\nfurther mitigate embedding collapse, we propose a three-stage training\\nstrategy: (1) pre-training the embedding weights, (2) aligning these weights\\nwith the ADRec backbone, and (3) fine-tuning the model. During inference, ADRec\\napplies the denoising process only to the last token, ensuring that the\\nmeaningful patterns in historical interactions are preserved. Our comprehensive\\nempirical evaluation across six datasets underscores the effectiveness of ADRec\\nin enhancing both the accuracy and efficiency of diffusion-based sequential\\nrecommendation systems.                                                                                                                                                                                                                                                                                                                                                                         |cs.IR,cs.LG                  |cs.IR  |\n",
      "|http://arxiv.org/abs/2505.19545v1|Asymptotic gauge symmetry and UV extension of the nonperturbative\\n  coupling in holographic QCD We extend our recent analytic study of the strong coupling $\\alpha_{\\rm eff}$\\nin the nonperturbative and near-perturbative regimes~\\cite{deTeramond:2024ikl}\\nby imposing rigorous renormalization-group results from asymptotically free\\ngauge theories at $Q^2 \\to \\infty$. The asymptotic boundary conditions modify\\nthe scaling properties of $\\alpha_{\\rm eff}$ at large values of the momentum\\ntransfer $Q^2$, and lead to a scale-dependent confinement strength\\n$\\kappa(Q^2)$. This requires that both $\\kappa(Q^2)$ and $\\alpha_{\\rm\\neff}\\left(Q^2, \\kappa(Q^2)\\right)$ remain holomorphic in the complex $Q^2$\\nplane, except at the physical cuts associated with the heavy-quark thresholds\\nand the singularity flow trajectory studied in~\\cite{deTeramond:2024ikl}. For\\ncolor $SU(3)$, a precise connection is found between the scaling exponent of\\n$\\kappa(Q^2)$ in the ultraviolet, the value of the infrared fixed point of the\\nstrong coupling, and the number of flavors in agreement with observations. The\\nnonperturbative analytic model gives an accurate description of the strong\\ncoupling at all scales, up to the highest available data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |hep-ph,hep-ex,hep-th         |hep-th |\n",
      "+---------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-33-30.json\n",
      "\n",
      "========= 2025-05-29 21:33:40 =========\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+----------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |true_label           |pred            |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+----------------+\n",
      "|http://arxiv.org/abs/2505.19551v1|Customising Electricity Contracts at Scale with Large Language Models The electricity system becomes more complex, connecting massive numbers of\\nend-users and distributed generators. Adding or removing grid connections\\nrequires expert studies to align technical constraints with user requests. In\\ntimes of labour shortages, carrying out these studies represents a significant\\namount of time that engineers at system operators spend in planning\\ndepartments. As time is limited, only standard block connectivity contracts can\\nbe offered to end-users, or the requests pile up. Even if offers are made,\\nthese often do not perfectly match the user's requirements, leading to\\noverpaying or underusing the grid capacity. This paper investigates whether\\nend-users can negotiate individual, flexible time-of-use contracts directly\\nwith the grid using Large Language Models (LLM) in chats at scale. The\\nLLM-based chat has direct access to a model of the grid and studies the grid's\\ntechnical constraints just as an expert engineer. The advantage of this system\\nis that end-users can directly interact with grid models through natural\\nlanguage; no intermediate is needed to service, analyse, study, assess, advise,\\nconsult and engineer. This initial study paves the way toward developing this\\ntailored LLM system, resulting in possible high-efficiency gains for grid\\nplanning and customer management.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |eess.SY,cs.SY,eess.SP|cs.AI           |\n",
      "|http://arxiv.org/abs/2505.19552v1|On scalable and efficient training of diffusion samplers We address the challenge of training diffusion models to sample from\\nunnormalized energy distributions in the absence of data, the so-called\\ndiffusion samplers. Although these approaches have shown promise, they struggle\\nto scale in more demanding scenarios where energy evaluations are expensive and\\nthe sampling space is high-dimensional. To address this limitation, we propose\\na scalable and sample-efficient framework that properly harmonizes the powerful\\nclassical sampling method and the diffusion sampler. Specifically, we utilize\\nMonte Carlo Markov chain (MCMC) samplers with a novelty-based auxiliary energy\\nas a Searcher to collect off-policy samples, using an auxiliary energy function\\nto compensate for exploring modes the diffusion sampler rarely visits. These\\noff-policy samples are then combined with on-policy data to train the diffusion\\nsampler, thereby expanding its coverage of the energy landscape. Furthermore,\\nwe identify primacy bias, i.e., the preference of samplers for early experience\\nduring training, as the main cause of mode collapse during training, and\\nintroduce a periodic re-initialization trick to resolve this issue. Our method\\nsignificantly improves sample efficiency on standard benchmarks for diffusion\\nsamplers and also excels at higher-dimensional problems and real-world\\nmolecular conformer generation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.LG                |cs.LG           |\n",
      "|http://arxiv.org/abs/2505.19553v1|An electric circuital analysis of laboratory plasma sheath fluctuations\\n  and propagations The effective inductive (L), capacitive (C), and resistive (R) behavior of a\\nplasma sheath in a conjoint coupled form is well familiar among plasma physics\\ncommunities. A dynamic sheath instability in laboratory plasmas is\\nsystematically modelled herein as an electrical series-resonance LCR circuit of\\nthe above kind. It theoretically yields experimentally observed findings on\\ncoexistent plasma sheath oscillation, electric current perturbation, and\\nsubsequent plasma sheath waves (PSWs). The plasma current in the LCR circuit\\nformalism is allowed to undergo linear (small-scale) spatiotemporal\\nperturbations about its homogeneous equilibrium state. The oscillating sheath\\ntriggers ion-acoustic wave excitation in the bulk plasma through sheath-induced\\nenergy transfer processes. The obtained results could be applicable mainly in\\nunderstanding electromagnetic communication antennas, ion energy modulation\\nprocesses, diverse plasma probe diagnostics, etc.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |physics.plasm-ph     |physics.plasm-ph|\n",
      "|http://arxiv.org/abs/2505.19554v1|Aggregated Structural Representation with Large Language Models for\\n  Human-Centric Layout Generation Time consumption and the complexity of manual layout design make automated\\nlayout generation a critical task, especially for multiple applications across\\ndifferent mobile devices. Existing graph-based layout generation approaches\\nsuffer from limited generative capability, often resulting in unreasonable and\\nincompatible outputs. Meanwhile, vision based generative models tend to\\noverlook the original structural information, leading to component\\nintersections and overlaps. To address these challenges, we propose an\\nAggregation Structural Representation (ASR) module that integrates graph\\nnetworks with large language models (LLMs) to preserve structural information\\nwhile enhancing generative capability. This novel pipeline utilizes graph\\nfeatures as hierarchical prior knowledge, replacing the traditional Vision\\nTransformer (ViT) module in multimodal large language models (MLLM) to predict\\nfull layout information for the first time. Moreover, the intermediate graph\\nmatrix used as input for the LLM is human editable, enabling progressive, human\\ncentric design generation. A comprehensive evaluation on the RICO dataset\\ndemonstrates the strong performance of ASR, both quantitatively using mean\\nIntersection over Union (mIoU), and qualitatively through a crowdsourced user\\nstudy. Additionally, sampling on relational features ensures diverse layout\\ngeneration, further enhancing the adaptability and creativity of the proposed\\napproach.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |cs.CV                |cs.CV           |\n",
      "|http://arxiv.org/abs/2505.19555v1|Reduced-Order Solution for Rarefied Gas Flow by Proper Generalised\\n  Decomposition Modelling rarefied gas flow via the Boltzmann equation plays a vital role in\\nmany areas. Due to the high dimensionality of this kinetic equation and the\\ncoexistence of multiple characteristic scales in the transport processes,\\nconventional solution strategies incur prohibitively high computational costs\\nand are inadequate for rapid response for parametric analysis and optimisation\\nloops in engineering design simulations. This paper proposes an \\textit{a\\npriori} reduced-order method based on the proper generalised decomposition to\\nsolve the high-dimensional, parametrised Shakhov kinetic model equation. This\\nmethod reduces the original problem into a few low-dimensional problem by\\nformulating separated representations for the low-rank solution, as well as\\ndata and operators in the equation, thereby overcoming the curse of\\ndimensionality. Furthermore, a general solution can be calculated once and for\\nall in the whole range of the rarefaction parameter, enabling fast and multiple\\nqueries to a specific solution at any point in the parameter space. Numerical\\nexamples are presented to demonstrate the capability of the method to simulate\\nrarefied gas flow with high accuracy and significant reduction in CPU time and\\nmemory requirements.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |math.NA,cs.NA        |math.NA         |\n",
      "|http://arxiv.org/abs/2505.19556v1|A Framework for Combined Transaction Posting and Pricing for Layer 2\\n  Blockchains This paper presents a comprehensive framework for transaction posting and\\npricing in Layer 2 (L2) blockchain systems, focusing on challenges stemming\\nfrom fluctuating Layer 1 (L1) gas fees and the congestion issues within L2\\nnetworks. Existing methods have focused on the problem of optimal posting\\nstrategies to L1 in isolation, without simultaneously considering the L2 fee\\nmechanism. In contrast, our work offers a unified approach that addresses the\\ncomplex interplay between transaction queue dynamics, L1 cost variability, and\\nuser responses to L2 fees. We contribute by (1) formulating a dynamic model\\nthat integrates both posting and pricing strategies, capturing the interplay\\nbetween L1 gas price fluctuations and L2 queue management, (2) deriving an\\noptimal threshold-based posting policy that guides L2 sequencers in managing\\ntransactions based on queue length and current L1 conditions, and (3)\\nestablishing theoretical foundations for a dynamic L2 fee mechanism that\\nbalances cost recovery with congestion control. We validate our framework\\nthrough simulations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |cs.GT                |cs.GT           |\n",
      "|http://arxiv.org/abs/2505.19557v1|Formulas for Residues of Type Camacho-Sad and applications In this paper we give formulas for the sum of residues of type Camacho-Sad of\\na $p$-dimensional foliation ${\\mathcal{F}}$, relative to an invariant analytic\\nsubvariety $V$. As application, in context of projective foliations, we obtain\\na formula that relates the sum these residues with the degree and other\\ncharacteristics of the invariant subvariety.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |math.AG              |math.AG         |\n",
      "|http://arxiv.org/abs/2505.19558v1|EuroCon: Benchmarking Parliament Deliberation for Political Consensus\\n  Finding Achieving political consensus is crucial yet challenging for the effective\\nfunctioning of social governance. However, although frontier AI systems\\nrepresented by large language models (LLMs) have developed rapidly in recent\\nyears, their capabilities on this scope are still understudied. In this paper,\\nwe introduce EuroCon, a novel benchmark constructed from 2,225 high-quality\\ndeliberation records of the European Parliament over 13 years, ranging from\\n2009 to 2022, to evaluate the ability of LLMs to reach political consensus\\namong divergent party positions across diverse parliament settings.\\nSpecifically, EuroCon incorporates four factors to build each simulated\\nparliament setting: specific political issues, political goals, participating\\nparties, and power structures based on seat distribution. We also develop an\\nevaluation framework for EuroCon to simulate real voting outcomes in different\\nparliament settings, assessing whether LLM-generated resolutions meet\\npredefined political goals. Our experimental results demonstrate that even\\nstate-of-the-art models remain undersatisfied with complex tasks like passing\\nresolutions by a two-thirds majority and addressing security issues, while\\nrevealing some common strategies LLMs use to find consensus under different\\npower structures, such as prioritizing the stance of the dominant party,\\nhighlighting EuroCon's promise as an effective platform for studying LLMs'\\nability to find political consensus.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.CY,cs.LG          |cs.CL           |\n",
      "|http://arxiv.org/abs/2505.19559v1|Multipole Distributions and Hyper-Flux Fields We outline here a simple mathematical introduction to the notions of\\nmultipoles for a general extensive property $\\Pi$ from the point of view of\\ncontinuum mechanics. Classically, $\\Pi$ is the electric charge, but the theory\\nis not limited to electrostatics. The proposed framework allows a simple\\ncomputation of the bound \"charges\" and bound multipoles of lower orders. In\\naddition, if the property $\\Pi$ has a potential function in the sense described\\nbelow, a general expression for the mechanical force (power) functional acting\\non bodies containing the property is presented. Finally, using a similar\\nviewpoint, we consider hyper-fluxes -- flux fields of tensorial order greater\\nthan one -- and show that moving multipoles (in particular, a moving\\ndielectric) give rise to hyper-fluxes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |math-ph,math.MP      |hep-th          |\n",
      "|http://arxiv.org/abs/2505.19560v1|LF-GNSS: Towards More Robust Satellite Positioning with a Hard Example\\n  Mining Enhanced Learning-Filtering Deep Fusion Framework Global Navigation Satellite System (GNSS) is essential for autonomous driving\\nsystems, unmanned vehicles, and various location-based technologies, as it\\nprovides the precise geospatial information necessary for navigation and\\nsituational awareness. However, its performance is often degraded by\\nNon-Line-Of-Sight (NLOS) and multipath effects, especially in urban\\nenvironments. Recently, Artificial Intelligence (AI) has been driving\\ninnovation across numerous industries, introducing novel solutions to mitigate\\nthe challenges in satellite positioning. This paper presents a\\nlearning-filtering deep fusion framework for satellite positioning, termed\\nLF-GNSS. The framework utilizes deep learning networks to intelligently analyze\\nthe signal characteristics of satellite observations, enabling the adaptive\\nconstruction of observation noise covariance matrices and compensated\\ninnovation vectors for Kalman filter input. A dynamic hard example mining\\ntechnique is incorporated to enhance model robustness by prioritizing\\nchallenging satellite signals during training. Additionally, we introduce a\\nnovel feature representation based on Dilution of Precision (DOP)\\ncontributions, which helps to more effectively characterize the signal quality\\nof individual satellites and improve measurement weighting. LF-GNSS has been\\nvalidated on both public and private datasets, demonstrating superior\\npositioning accuracy compared to traditional methods and other learning-based\\nsolutions. To encourage further integration of AI and GNSS research, we will\\nopen-source the code at https://github.com/GarlanLou/LF-GNSS, and release a\\ncollection of satellite positioning datasets for urban scenarios at\\nhttps://github.com/GarlanLou/LF-GNSS-Dataset.                                                                                                                                                            |cs.RO                |cs.RO           |\n",
      "|http://arxiv.org/abs/2505.19561v1|Lego Sketch: A Scalable Memory-augmented Neural Network for Sketching\\n  Data Streams Sketches, probabilistic structures for estimating item frequencies in\\ninfinite data streams with limited space, are widely used across various\\ndomains. Recent studies have shifted the focus from handcrafted sketches to\\nneural sketches, leveraging memory-augmented neural networks (MANNs) to enhance\\nthe streaming compression capabilities and achieve better space-accuracy\\ntrade-offs.However, existing neural sketches struggle to scale across different\\ndata domains and space budgets due to inflexible MANN configurations. In this\\npaper, we introduce a scalable MANN architecture that brings to life the {\\it\\nLego sketch}, a novel sketch with superior scalability and accuracy. Much like\\nassembling creations with modular Lego bricks, the Lego sketch dynamically\\ncoordinates multiple memory bricks to adapt to various space budgets and\\ndiverse data domains. Our theoretical analysis guarantees its high scalability\\nand provides the first error bound for neural sketch. Furthermore, extensive\\nexperimental evaluations demonstrate that the Lego sketch exhibits superior\\nspace-accuracy trade-offs, outperforming existing handcrafted and neural\\nsketches. Our code is available at https://github.com/FFY0/LegoSketch_ICML.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |cs.LG                |cs.LG           |\n",
      "|http://arxiv.org/abs/2505.19562v1|AMQA: An Adversarial Dataset for Benchmarking Bias of LLMs in Medicine\\n  and Healthcare Large language models (LLMs) are reaching expert-level accuracy on medical\\ndiagnosis questions, yet their mistakes and the biases behind them pose\\nlife-critical risks. Bias linked to race, sex, and socioeconomic status is\\nalready well known, but a consistent and automatic testbed for measuring it is\\nmissing. To fill this gap, this paper presents AMQA -- an Adversarial Medical\\nQuestion-Answering dataset -- built for automated, large-scale bias evaluation\\nof LLMs in medical QA. AMQA includes 4,806 medical QA pairs sourced from the\\nUnited States Medical Licensing Examination (USMLE) dataset, generated using a\\nmulti-agent framework to create diverse adversarial descriptions and question\\npairs. Using AMQA, we benchmark five representative LLMs and find surprisingly\\nsubstantial disparities: even GPT-4.1, the least biased model tested, answers\\nprivileged-group questions over 10 percentage points more accurately than\\nunprivileged ones. Compared with the existing benchmark CPV, AMQA reveals 15%\\nlarger accuracy gaps on average between privileged and unprivileged groups. Our\\ndataset and code are publicly available at https://github.com/XY-Showing/AMQA\\nto support reproducible research and advance trustworthy, bias-aware medical\\nAI.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.AI                |cs.CL           |\n",
      "|http://arxiv.org/abs/2505.19563v1|Automated Text-to-Table for Reasoning-Intensive Table QA: Pipeline\\n  Design and Benchmarking Insights Reasoning with tabular data holds increasing importance in modern\\napplications, yet comprehensive evaluation methodologies for\\nreasoning-intensive Table Question Answering (QA) tasks remain nascent.\\nExisting research is constrained by two primary bottlenecks: 1) Reliance on\\ncostly manually annotated real-world data, which is difficult to cover complex\\nreasoning scenarios; 2) The heterogeneity of table structures hinders\\nsystematic analysis of the intrinsic mechanisms behind the underperformance of\\nLLMs, especially in reasoning-intensive tasks. To address these issues, we\\npropose an automated generation pipeline AutoT2T that transforms mathematical\\nword problems into table-based reasoning tasks, eliminating the need for manual\\nannotation. The pipeline can generate multiple variants of a table for the same\\nreasoning problem, including noisy versions to support robustness evaluation.\\nBased on this, we construct a new benchmark TabularGSM, which systematically\\nspans a range of table complexities and trap problems. Experimental analyses\\nthrough AutoT2T and TabularGSM reveal that the tight coupling between reasoning\\nand retrieval or identification processes is a key factor underlying the\\nfailure of LLMs in complex Table QA tasks. This highlights the necessity for\\nmodels to develop synergistic reasoning capabilities in order to perform\\neffectively in complex Table QA tasks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.AI,cs.CL          |cs.CL           |\n",
      "|http://arxiv.org/abs/2505.19564v1|K-Buffers: A Plug-in Method for Enhancing Neural Fields with Multiple\\n  Buffers Neural fields are now the central focus of research in 3D vision and computer\\ngraphics. Existing methods mainly focus on various scene representations, such\\nas neural points and 3D Gaussians. However, few works have studied the\\nrendering process to enhance the neural fields. In this work, we propose a\\nplug-in method named K-Buffers that leverages multiple buffers to improve the\\nrendering performance. Our method first renders K buffers from scene\\nrepresentations and constructs K pixel-wise feature maps. Then, We introduce a\\nK-Feature Fusion Network (KFN) to merge the K pixel-wise feature maps. Finally,\\nwe adopt a feature decoder to generate the rendering image. We also introduce\\nan acceleration strategy to improve rendering speed and quality. We apply our\\nmethod to well-known radiance field baselines, including neural point fields\\nand 3D Gaussian Splatting (3DGS). Extensive experiments demonstrate that our\\nmethod effectively enhances the rendering performance of neural point fields\\nand 3DGS.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.CV                |cs.CV           |\n",
      "|http://arxiv.org/abs/2505.19565v1|Few-Shot Class-Incremental Learning For Efficient SAR Automatic Target\\n  Recognition Synthetic aperture radar automatic target recognition (SAR-ATR) systems have\\nrapidly evolved to tackle incremental recognition challenges in operational\\nsettings. Data scarcity remains a major hurdle that conventional SAR-ATR\\ntechniques struggle to address. To cope with this challenge, we propose a\\nfew-shot class-incremental learning (FSCIL) framework based on a dual-branch\\narchitecture that focuses on local feature extraction and leverages the\\ndiscrete Fourier transform and global filters to capture long-term spatial\\ndependencies. This incorporates a lightweight cross-attention mechanism that\\nfuses domain-specific features with global dependencies to ensure robust\\nfeature interaction, while maintaining computational efficiency by introducing\\nminimal scale-shift parameters. The framework combines focal loss for class\\ndistinction under imbalance and center loss for compact intra-class\\ndistributions to enhance class separation boundaries. Experimental results on\\nthe MSTAR benchmark dataset demonstrate that the proposed framework\\nconsistently outperforms state-of-the-art methods in FSCIL SAR-ATR, attesting\\nto its effectiveness in real-world scenarios.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.CV                |cs.CV           |\n",
      "|http://arxiv.org/abs/2505.19566v1|Integrated Finite Element Neural Network (IFENN) for Phase-Field\\n  Fracture with Minimal Input and Generalized Geometry-Load Handling We present a novel formulation for modeling phase-field fracture propagation\\nbased on the Integrated Finite Element Neural Network (IFENN) framework. IFENN\\nis a hybrid solver scheme that utilizes neural networks as PDE solvers within\\nFEM, preserving accuracy via residual minimization while achieving speed-up via\\nswift network predictions and reduction of the size of system of equations in\\ncoupled problems. In this work, we introduce a radically new formulation of\\nIFENN in which the phase-field variable is calculated using physics-informed\\nconvolutional networks (PICNNs), while the equilibrium equation is still solved\\nusing FEM to maintain the solver robustness. Unlike conventional approaches,\\nwhich rely on sequence or time-dependent models, we eliminate the need to\\ninclude temporal features in the training setup and inference stage. Instead,\\nwe show that it is sufficient to learn only the spatial coupling between the\\nstrain energy density and the phase-field variable in the vicinity of the\\nfracture process zone, and utilize this information along the advancing crack\\nsimulation. We train a single CNN in a purely physics-based, unsupervised\\nmanner on just two load increments from a single-notch tension problem, with a\\ntotal training time of only 5 minutes. Following this exceptionally minimal and\\nfast training, we show that the same PICNN can (when embedded within IFENN)\\nmodel crack propagation in a very wide range of unseen scenarios, including\\narbitrarily rectangular domains, single and multiple interacting cracks,\\nvarying mesh densities, and arbitrary loading paths. The proposed formulation\\ndelivers breakthroughs that address many of the limitations in the existing\\nliterature of hybrid modeling, introducing a new paradigm for the development\\nof generalizable, physics-consistent hybrid models that are applicable to\\nfracture and other coupled problems.|cs.CE                |cs.LG           |\n",
      "|http://arxiv.org/abs/2505.19567v1|LLM-Agent-Controller: A Universal Multi-Agent Large Language Model\\n  System as a Control Engineer This study presents the LLM-Agent-Controller, a multi-agent large language\\nmodel (LLM) system developed to address a wide range of problems in control\\nengineering (Control Theory). The system integrates a central controller agent\\nwith multiple specialized auxiliary agents, responsible for tasks such as\\ncontroller design, model representation, control analysis, time-domain\\nresponse, and simulation. A supervisor oversees high-level decision-making and\\nworkflow coordination, enhancing the system's reliability and efficiency. The\\nLLM-Agent-Controller incorporates advanced capabilities, including\\nRetrieval-Augmented Generation (RAG), Chain-of-Thought reasoning,\\nself-criticism and correction, efficient memory handling, and user-friendly\\nnatural language communication. It is designed to function without requiring\\nusers to have prior knowledge of Control Theory, enabling them to input\\nproblems in plain language and receive complete, real-time solutions. To\\nevaluate the system, we propose new performance metrics assessing both\\nindividual agents and the system as a whole. We test five categories of Control\\nTheory problems and benchmark performance across three advanced LLMs.\\nAdditionally, we conduct a comprehensive qualitative conversational analysis\\ncovering all key services. Results show that the LLM-Agent-Controller\\nsuccessfully solved 83% of general tasks, with individual agents achieving an\\naverage success rate of 87%. Performance improved with more advanced LLMs. This\\nresearch demonstrates the potential of multi-agent LLM architectures to solve\\ncomplex, domain-specific problems. By integrating specialized agents,\\nsupervisory control, and advanced reasoning, the LLM-Agent-Controller offers a\\nscalable, robust, and accessible solution framework that can be extended to\\nvarious technical domains.                                                                                                     |cs.AI,cs.MA          |cs.AI           |\n",
      "|http://arxiv.org/abs/2505.19568v1|MSD-LLM: Predicting Ship Detention in Port State Control Inspections\\n  with Large Language Model Maritime transportation is the backbone of global trade, making ship\\ninspection essential for ensuring maritime safety and environmental protection.\\nPort State Control (PSC), conducted by national ports, enforces compliance with\\nsafety regulations, with ship detention being the most severe consequence,\\nimpacting both ship schedules and company reputations. Traditional machine\\nlearning methods for ship detention prediction are limited by the capacity of\\nrepresentation learning and thus suffer from low accuracy. Meanwhile,\\nautoencoder-based deep learning approaches face challenges due to the severe\\ndata imbalance in learning historical PSC detention records. To address these\\nlimitations, we propose Maritime Ship Detention with Large Language Models\\n(MSD-LLM), integrating a dual robust subspace recovery (DSR) layer-based\\nautoencoder with a progressive learning pipeline to handle imbalanced data and\\nextract meaningful PSC representations. Then, a large language model groups and\\nranks features to identify likely detention cases, enabling dynamic\\nthresholding for flexible detention predictions. Extensive evaluations on\\n31,707 PSC inspection records from the Asia-Pacific region show that MSD-LLM\\noutperforms state-of-the-art methods more than 12\\% on Area Under the Curve\\n(AUC) for Singapore ports. Additionally, it demonstrates robustness to\\nreal-world challenges, making it adaptable to diverse maritime risk assessment\\nscenarios.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.AI,cs.LG          |cs.LG           |\n",
      "|http://arxiv.org/abs/2505.19570v1|Eliciting Informed Preferences If people find it costly to evaluate the options available to them, their\\nchoices may not directly reveal their preferences. Yet, it is conceivable that\\na researcher can still learn about a population's preferences with careful\\nexperiment design. We formalize the researcher's problem in a model of robust\\nmechanism design where it is costly for individuals to learn about how much\\nthey value a product. We characterize the statistics that the researcher can\\nidentify, and find that they are quite restricted. Finally, we apply our\\npositive results to social choice and propose a way to combat uninformed\\nvoting.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |econ.TH,cs.GT        |econ.TH         |\n",
      "|http://arxiv.org/abs/2505.19569v1|What You Perceive Is What You Conceive: A Cognition-Inspired Framework\\n  for Open Vocabulary Image Segmentation Open vocabulary image segmentation tackles the challenge of recognizing\\ndynamically adjustable, predefined novel categories at inference time by\\nleveraging vision-language alignment. However, existing paradigms typically\\nperform class-agnostic region segmentation followed by category matching, which\\ndeviates from the human visual system's process of recognizing objects based on\\nsemantic concepts, leading to poor alignment between region segmentation and\\ntarget concepts. To bridge this gap, we propose a novel Cognition-Inspired\\nFramework for open vocabulary image segmentation that emulates the human visual\\nrecognition process: first forming a conceptual understanding of an object,\\nthen perceiving its spatial extent. The framework consists of three core\\ncomponents: (1) A Generative Vision-Language Model (G-VLM) that mimics human\\ncognition by generating object concepts to provide semantic guidance for region\\nsegmentation. (2) A Concept-Aware Visual Enhancer Module that fuses textual\\nconcept features with global visual representations, enabling adaptive visual\\nperception based on target concepts. (3) A Cognition-Inspired Decoder that\\nintegrates local instance features with G-VLM-provided semantic cues, allowing\\nselective classification over a subset of relevant categories. Extensive\\nexperiments demonstrate that our framework achieves significant improvements,\\nreaching $27.2$ PQ, $17.0$ mAP, and $35.3$ mIoU on A-150. It further attains\\n$56.2$, $28.2$, $15.4$, $59.2$, $18.7$, and $95.8$ mIoU on Cityscapes,\\nMapillary Vistas, A-847, PC-59, PC-459, and PAS-20, respectively. In addition,\\nour framework supports vocabulary-free segmentation, offering enhanced\\nflexibility in recognizing unseen categories. Code will be public.                                                                                                                                                                     |cs.CV                |cs.CV           |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-33-40.json\n",
      "\n",
      "========= 2025-05-29 21:33:50 =========\n",
      "+---------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------+-----------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |true_label                     |pred       |\n",
      "+---------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------+-----------+\n",
      "|http://arxiv.org/abs/2505.19576v1|Mel-McNet: A Mel-Scale Framework for Online Multichannel Speech\\n  Enhancement Online multichannel speech enhancement has been intensively studied recently.\\nThough Mel-scale frequency is more matched with human auditory perception and\\ncomputationally efficient than linear frequency, few works are implemented in a\\nMel-frequency domain. To this end, this work proposes a Mel-scale framework\\n(namely Mel-McNet). It processes spectral and spatial information with two key\\ncomponents: an effective STFT-to-Mel module compressing multi-channel STFT\\nfeatures into Mel-frequency representations, and a modified McNet backbone\\ndirectly operating in the Mel domain to generate enhanced LogMel spectra. The\\nspectra can be directly fed to vocoders for waveform reconstruction or ASR\\nsystems for transcription. Experiments on CHiME-3 show that Mel-McNet can\\nreduce computational complexity by 60% while maintaining comparable enhancement\\nand ASR performance to the original McNet. Mel-McNet also outperforms other\\nSOTA methods, verifying the potential of Mel-scale speech enhancement.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |eess.AS,cs.SD,eess.SP          |cs.SD      |\n",
      "|http://arxiv.org/abs/2505.19577v1|MFA-KWS: Effective Keyword Spotting with Multi-head Frame-asynchronous\\n  Decoding Keyword spotting (KWS) is essential for voice-driven applications, demanding\\nboth accuracy and efficiency. Traditional ASR-based KWS methods, such as greedy\\nand beam search, explore the entire search space without explicitly\\nprioritizing keyword detection, often leading to suboptimal performance. In\\nthis paper, we propose an effective keyword-specific KWS framework by\\nintroducing a streaming-oriented CTC-Transducer-combined frame-asynchronous\\nsystem with multi-head frame-asynchronous decoding (MFA-KWS). Specifically,\\nMFA-KWS employs keyword-specific phone-synchronous decoding for CTC and\\nreplaces conventional RNN-T with Token-and-Duration Transducer to enhance both\\nperformance and efficiency. Furthermore, we explore various score fusion\\nstrategies, including single-frame-based and consistency-based methods.\\nExtensive experiments demonstrate the superior performance of MFA-KWS, which\\nachieves state-of-the-art results on both fixed keyword and arbitrary keywords\\ndatasets, such as Snips, MobvoiHotwords, and LibriKWS-20, while exhibiting\\nstrong robustness in noisy environments. Among fusion strategies, the\\nconsistency-based CDC-Last method delivers the best performance. Additionally,\\nMFA-KWS achieves a 47% to 63% speed-up over the frame-synchronous baselines\\nacross various datasets. Extensive experimental results confirm that MFA-KWS is\\nan effective and efficient KWS framework, making it well-suited for on-device\\ndeployment.                                                                                                                                                                                                                                                                                                                                                                                                       |eess.AS,cs.SD                  |eess.AS    |\n",
      "|http://arxiv.org/abs/2505.19578v1|Accelerating Prefilling for Long-Context LLMs via Sparse Pattern Sharing Sparse attention methods exploit the inherent sparsity in attention to speed\\nup the prefilling phase of long-context inference, mitigating the quadratic\\ncomplexity of full attention computation. While existing sparse attention\\nmethods rely on predefined patterns or inaccurate estimations to approximate\\nattention behavior, they often fail to fully capture the true dynamics of\\nattention, resulting in reduced efficiency and compromised accuracy. Instead,\\nwe propose a highly accurate sparse attention mechanism that shares similar yet\\nprecise attention patterns across heads, enabling a more realistic capture of\\nthe dynamic behavior of attention. Our approach is grounded in two key\\nobservations: (1) attention patterns demonstrate strong inter-head similarity,\\nand (2) this similarity remains remarkably consistent across diverse inputs. By\\nstrategically sharing computed accurate patterns across attention heads, our\\nmethod effectively captures actual patterns while requiring full attention\\ncomputation for only a small subset of heads. Comprehensive evaluations\\ndemonstrate that our approach achieves superior or comparable speedup relative\\nto state-of-the-art methods while delivering the best overall accuracy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.LG,cs.AI,cs.CL              |cs.LG      |\n",
      "|http://arxiv.org/abs/2505.19579v1|Quasi-triangular Novikov bialgebras and related bialgebra structures We introduce the notion of quasi-triangular Novikov bialgebras, which\\nconstructed from solutions of the Novikov Yang-Baxter equation whose symmetric\\nparts are invariant. Triangular Novikov bialgebras and factorizable Novikov\\nbialgebras are important subclasses of quasi-triangular Novikov bialgebras. A\\nfactorizable Novikov bialgebra induces a factorization of the underlying\\nNovikov algebra and the double of any Novikov bialgebra naturally admits a\\nfactorizable Novikov bialgebra structure. Moreover, we introduce the notion of\\nquadratic Rota-Baxter Novikov algebras and show that there is an one-to-one\\ncorrespondence between factorizable Novikov bialgebras and quadratic\\nRota-Baxter Novikov algebras of nonzero weights. Finally, we obtain that the\\nLie bialgebra induced by a Novikov bialgebra and a quadratic right Novikov\\nalgebra is quasi-triangular (resp. triangular, factorizable) if the Novikov\\nbialgebra is quasi-triangular (resp. triangular, factorizable), and under\\ncertain conditions, the Novikov bialgebra induced by a differential\\ninfinitesimal bialgebra is quasi-triangular (resp. triangular, factorizable) if\\nthe differential infinitesimal bialgebra is quasi-triangular (resp. triangular,\\nfactorizable).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |math.RA,math.QA                |math.RA    |\n",
      "|http://arxiv.org/abs/2505.19580v1|Whole-body Multi-contact Motion Control for Humanoid Robots Based on\\n  Distributed Tactile Sensors To enable humanoid robots to work robustly in confined environments,\\nmulti-contact motion that makes contacts not only at extremities, such as hands\\nand feet, but also at intermediate areas of the limbs, such as knees and\\nelbows, is essential. We develop a method to realize such whole-body\\nmulti-contact motion involving contacts at intermediate areas by a humanoid\\nrobot. Deformable sheet-shaped distributed tactile sensors are mounted on the\\nsurface of the robot's limbs to measure the contact force without significantly\\nchanging the robot body shape. The multi-contact motion controller developed\\nearlier, which is dedicated to contact at extremities, is extended to handle\\ncontact at intermediate areas, and the robot motion is stabilized by feedback\\ncontrol using not only force/torque sensors but also distributed tactile\\nsensors. Through verification on dynamics simulations, we show that the\\ndeveloped tactile feedback improves the stability of whole-body multi-contact\\nmotion against disturbances and environmental errors. Furthermore, the\\nlife-sized humanoid RHP Kaleido demonstrates whole-body multi-contact motions,\\nsuch as stepping forward while supporting the body with forearm contact and\\nbalancing in a sitting posture with thigh contacts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.RO                          |cs.RO      |\n",
      "|http://arxiv.org/abs/2505.19581v1|Self-testing in a constrained prepare-measure scenario sans assuming\\n  quantum dimension We present a device-independent (DI) self-testing protocol in a constrained\\nprepare-measure scenario, based on the $n-$bit parity-oblivious multiplexing\\n(POM) task. In this scenario, a parity-oblivious constraint is imposed on the\\npreparations, allowing us to define a classical bound derived from a\\npreparation noncontextual ontological model. We derive the optimal quantum\\nsuccess probability in the POM task devoid of assuming the dimension of the\\nquantum system, an essential step towards DI self-testing, which has hitherto\\nnot been demonstrated in prepare-measure scenario. We demonstrate that the\\noptimal quantum value exceeds preparation noncontextual bound and, as a result,\\nthis establishes DI self-testing of the preparations and the measurement\\ndevices. Furthermore, by explicitly constructing the required unitaries, we\\nshow that the optimal preparations and measurements in an unknown but finite\\ndimensional Hilbert space, responsible for the observed input-output\\ncorrelations, can be mapped, via an unitary, onto a known finite-dimensional\\nquantum system. Our results thus pave the way for scalable, single system based\\nDI certification protocols in the prepare-measure scenario.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |quant-ph                       |quant-ph   |\n",
      "|http://arxiv.org/abs/2505.19582v1|Guard Me If You Know Me: Protecting Specific Face-Identity from\\n  Deepfakes Securing personal identity against deepfake attacks is increasingly critical\\nin the digital age, especially for celebrities and political figures whose\\nfaces are easily accessible and frequently targeted. Most existing deepfake\\ndetection methods focus on general-purpose scenarios and often ignore the\\nvaluable prior knowledge of known facial identities, e.g., \"VIP individuals\"\\nwhose authentic facial data are already available. In this paper, we propose\\n\\textbf{VIPGuard}, a unified multimodal framework designed to capture\\nfine-grained and comprehensive facial representations of a given identity,\\ncompare them against potentially fake or similar-looking faces, and reason over\\nthese comparisons to make accurate and explainable predictions. Specifically,\\nour framework consists of three main stages. First, fine-tune a multimodal\\nlarge language model (MLLM) to learn detailed and structural facial attributes.\\nSecond, we perform identity-level discriminative learning to enable the model\\nto distinguish subtle differences between highly similar faces, including real\\nand fake variations. Finally, we introduce user-specific customization, where\\nwe model the unique characteristics of the target face identity and perform\\nsemantic reasoning via MLLM to enable personalized and explainable deepfake\\ndetection. Our framework shows clear advantages over previous detection works,\\nwhere traditional detectors mainly rely on low-level visual cues and provide no\\nhuman-understandable explanations, while other MLLM-based models often lack a\\ndetailed understanding of specific face identities. To facilitate the\\nevaluation of our method, we built a comprehensive identity-aware benchmark\\ncalled \\textbf{VIPBench} for personalized deepfake detection, involving the\\nlatest 7 face-swapping and 7 entire face synthesis techniques for generation.|cs.CV                          |cs.CV      |\n",
      "|http://arxiv.org/abs/2505.19583v1|Identifying lopsidedness in spiral galaxies using a Deep Convolutional\\n  Neural Network About 30\\% of disk galaxies show lopsidedness in their stellar disk. Although\\nsuch a large-scale asymmetry in the disk can be primarily looked upon as a\\nlong-lived mode ($m=1$), the physical origin of the lopsidedness in the disk\\ncontinues to be a puzzle. In this work, we develop an automated approach to\\nidentify lopsided galaxies from the SDSS DR18 using a Deep Convolutional Neural\\nNetwork (DCNN) based on the publicly available AlexNet architecture. We select\\nnearly face-on spiral galaxies from SDSS DR18 with the Petrosian 90\\% light\\nradius (\\textit{petroR90\\_i}) greater than $20^{''}$. Based on the visual\\ninspection, we choose 106 lopsided spiral galaxies and 105 symmetric spiral\\ngalaxies, as our training set. Our trained model achieves a testing accuracy of\\n92.8\\% at the end of 150 epochs. We then employ the trained model on a set of\\n813 face-on spiral galaxies from SDSS DR18 with $17^{''} \\le petroR90\\_i \\le\\n20^{''} $ and identify 452 new lopsided spiral galaxies. We next investigate\\nthe cosmic web environments in which the galaxies are located, using the\\nHessian matrix of the density field. We find that 39\\% of the lopsided galaxies\\nare located in sparser environments such as sheets and voids. This may provide\\ninteresting clues towards understanding the origin of lopsidedness in isolated\\ngalaxies, where distortion due to the tidal interactions is less frequent.                                                                                                                                                                                                                                                                                                                                                                                                                                                           |astro-ph.GA                    |astro-ph.GA|\n",
      "|http://arxiv.org/abs/2505.19584v1|The Bubble Wall Velocity in Local Thermal Equilibrium with Full\\n  Effective Potential In cosmological phase transitions, the bubble wall velocity is essential for\\nelectroweak baryogenesis and gravitational wave predictions. We develop a\\ncomputational framework that directly determines the velocity within the local\\nthermal equilibrium approximation, utilizing the full one-loop\\nfinite-temperature effective potential. This approach mitigates the errors\\nintroduced by using simplified bag model. We estimate the errors by comparing\\nthe results obtained using derived velocities-with kinetic energy fractions\\ncalculated from hydrodynamic integration-against those using fixed velocities,\\nwhere kinetic energy fractions are derived from fitting formulas. We find that\\nthe fitting formulas retain reasonable accuracy when the assumed velocities\\nalign with the computed values. However, deviations grow as the velocity\\ndiscrepancies increase, particularly in the deflagration regime, where relative\\nerrors reach 48% in peak frequency and 90% in peak value of gravitational wave\\nspectrum. In contrast, the detonation regime exhibits significantly smaller\\ndiscrepancies, with maximum deviations limited to 6% in peak frequency and 18%\\nin peak spectrum.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |hep-ph                         |gr-qc      |\n",
      "|http://arxiv.org/abs/2505.19585v1|Beyond Segmentation: Confidence-Aware and Debiased Estimation of\\n  Ratio-based Biomarkers Ratio-based biomarkers -- such as the proportion of necrotic tissue within a\\ntumor -- are widely used in clinical practice to support diagnosis, prognosis\\nand treatment planning. These biomarkers are typically estimated from soft\\nsegmentation outputs by computing region-wise ratios. Despite the high-stakes\\nnature of clinical decision making, existing methods provide only point\\nestimates, offering no measure of uncertainty. In this work, we propose a\\nunified \\textit{confidence-aware} framework for estimating ratio-based\\nbiomarkers. We conduct a systematic analysis of error propagation in the\\nsegmentation-to-biomarker pipeline and identify model miscalibration as the\\ndominant source of uncertainty. To mitigate this, we incorporate a lightweight,\\npost-hoc calibration module that can be applied using internal hospital data\\nwithout retraining. We leverage a tunable parameter $Q$ to control the\\nconfidence level of the derived bounds, allowing adaptation towards clinical\\npractice. Extensive experiments show that our method produces statistically\\nsound confidence intervals, with tunable confidence levels, enabling more\\ntrustworthy application of predictive biomarkers in clinical workflows.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.CV                          |eess.IV    |\n",
      "|http://arxiv.org/abs/2505.19586v1|TailorKV: A Hybrid Framework for Long-Context Inference via Tailored KV\\n  Cache Optimization The Key-Value (KV) cache in generative large language models (LLMs)\\nintroduces substantial memory overhead. Existing works mitigate this burden by\\noffloading or compressing the KV cache. However, loading the entire cache\\nincurs significant latency due to PCIe bandwidth bottlenecks in CPU-GPU\\ncommunication, while aggressive compression causes notable performance\\ndegradation. We identify that certain layers in the LLM need to maintain global\\ninformation and are unsuitable for selective loading. In contrast, other layers\\nprimarily focus on a few tokens with dominant activations that potentially\\nincur substantial quantization error. This observation leads to a key insight\\nthat loading dominant tokens and quantizing all tokens can complement each\\nother. Building on this insight, we propose a hybrid compression method,\\nTailorKV, which seamlessly integrates quantization and offloading. TailorKV\\ndevelops an inference framework along with a hardware-friendly implementation\\nthat leverages these complementary characteristics. Extensive long-context\\nevaluations exhibit that TailorKV achieves nearly lossless performance under\\naggressive compression settings, outperforming the state-of-the-art.\\nParticularly, the Llama-3.1-8B with 128k context can be served within a single\\nRTX 3090 GPU, reaching 82 ms per token during decoding.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |cs.CL                          |cs.CL      |\n",
      "|http://arxiv.org/abs/2505.19587v1|WQLCP: Weighted Adaptive Conformal Prediction for Robust Uncertainty\\n  Quantification Under Distribution Shifts Conformal prediction (CP) provides a framework for constructing prediction\\nsets with guaranteed coverage, assuming exchangeable data. However, real-world\\nscenarios often involve distribution shifts that violate exchangeability,\\nleading to unreliable coverage and inflated prediction sets. To address this\\nchallenge, we first introduce Reconstruction Loss-Scaled Conformal Prediction\\n(RLSCP), which utilizes reconstruction losses derived from a Variational\\nAutoencoder (VAE) as an uncertainty metric to scale score functions. While\\nRLSCP demonstrates performance improvements, mainly resulting in better\\ncoverage, it quantifies quantiles based on a fixed calibration dataset without\\nconsidering the discrepancies between test and train datasets in an\\nunexchangeable setting. In the next step, we propose Weighted Quantile\\nLoss-scaled Conformal Prediction (WQLCP), which refines RLSCP by incorporating\\na weighted notion of exchangeability, adjusting the calibration quantile\\nthreshold based on weights with respect to the ratio of calibration and test\\nloss values. This approach improves the CP-generated prediction set outputs in\\nthe presence of distribution shifts. Experiments on large-scale datasets,\\nincluding ImageNet variants, demonstrate that WQLCP outperforms existing\\nbaselines by consistently maintaining coverage while reducing prediction set\\nsizes, providing a robust solution for CP under distribution shifts.                                                                                                                                                                                                                                                                                                                                                                                                 |cs.LG,cs.CV                    |cs.LG      |\n",
      "|http://arxiv.org/abs/2505.19588v1|LogiCoL: Logically-Informed Contrastive Learning for Set-based Dense\\n  Retrieval While significant progress has been made with dual- and bi-encoder dense\\nretrievers, they often struggle on queries with logical connectives, a use case\\nthat is often overlooked yet important in downstream applications. Current\\ndense retrievers struggle with such queries, such that the retrieved results do\\nnot respect the logical constraints implied in the queries. To address this\\nchallenge, we introduce LogiCoL, a logically-informed contrastive learning\\nobjective for dense retrievers. LogiCoL builds upon in-batch supervised\\ncontrastive learning, and learns dense retrievers to respect the subset and\\nmutually-exclusive set relation between query results via two sets of soft\\nconstraints expressed via t-norm in the learning objective. We evaluate the\\neffectiveness of LogiCoL on the task of entity retrieval, where the model is\\nexpected to retrieve a set of entities in Wikipedia that satisfy the implicit\\nlogical constraints in the query. We show that models trained with LogiCoL\\nyield improvement both in terms of retrieval performance and logical\\nconsistency in the results. We provide detailed analysis and insights to\\nuncover why queries with logical connectives are challenging for dense\\nretrievers and why LogiCoL is most effective.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.IR,cs.AI                    |cs.CL      |\n",
      "|http://arxiv.org/abs/2505.19589v1|Model Agnostic Differentially Private Causal Inference Estimating causal effects from observational data is essential in fields such\\nas medicine, economics and social sciences, where privacy concerns are\\nparamount. We propose a general, model-agnostic framework for differentially\\nprivate estimation of average treatment effects (ATE) that avoids strong\\nstructural assumptions on the data-generating process or the models used to\\nestimate propensity scores and conditional outcomes. In contrast to prior work,\\nwhich enforces differential privacy by directly privatizing these nuisance\\ncomponents and results in a privacy cost that scales with model complexity, our\\napproach decouples nuisance estimation from privacy protection. This separation\\nallows the use of flexible, state-of-the-art black-box models, while\\ndifferential privacy is achieved by perturbing only predictions and aggregation\\nsteps within a fold-splitting scheme with ensemble techniques. We instantiate\\nthe framework for three classical estimators -- the G-formula, inverse\\npropensity weighting (IPW), and augmented IPW (AIPW) -- and provide formal\\nutility and privacy guarantees. Empirical results show that our methods\\nmaintain competitive performance under realistic privacy budgets. We further\\nextend our framework to support meta-analysis of multiple private ATE\\nestimates. Our results bridge a critical gap between causal inference and\\nprivacy-preserving data analysis.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |cs.LG,stat.ML                  |stat.ME    |\n",
      "|http://arxiv.org/abs/2505.19590v1|Learning to Reason without External Rewards Training large language models (LLMs) for complex reasoning via Reinforcement\\nLearning with Verifiable Rewards (RLVR) is effective but limited by reliance on\\ncostly, domain-specific supervision. We explore Reinforcement Learning from\\nInternal Feedback (RLIF), a framework that enables LLMs to learn from intrinsic\\nsignals without external rewards or labeled data. We propose Intuitor, an RLIF\\nmethod that uses a model's own confidence, termed self-certainty, as its sole\\nreward signal. Intuitor replaces external rewards in Group Relative Policy\\nOptimization (GRPO) with self-certainty scores, enabling fully unsupervised\\nlearning. Experiments demonstrate that Intuitor matches GRPO's performance on\\nmathematical benchmarks while achieving superior generalization to\\nout-of-domain tasks like code generation, without requiring gold solutions or\\ntest cases. Our findings show that intrinsic model signals can drive effective\\nlearning across domains, offering a scalable alternative to RLVR for autonomous\\nAI systems where verifiable rewards are unavailable. Code is available at\\nhttps://github.com/sunblaze-ucb/Intuitor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |cs.LG,cs.CL                    |cs.LG      |\n",
      "|http://arxiv.org/abs/2505.19591v1|Multi-Agent Collaboration via Evolving Orchestration Large language models (LLMs) have achieved remarkable results across diverse\\ndownstream tasks, but their monolithic nature restricts scalability and\\nefficiency in complex problem-solving. While recent research explores\\nmulti-agent collaboration among LLMs, most approaches rely on static\\norganizational structures that struggle to adapt as task complexity and agent\\nnumbers grow, resulting in coordination overhead and inefficiencies. To this\\nend, we propose a puppeteer-style paradigm for LLM-based multi-agent\\ncollaboration, where a centralized orchestrator (\"puppeteer\") dynamically\\ndirects agents (\"puppets\") in response to evolving task states. This\\norchestrator is trained via reinforcement learning to adaptively sequence and\\nprioritize agents, enabling flexible and evolvable collective reasoning.\\nExperiments on closed- and open-domain scenarios show that this method achieves\\nsuperior performance with reduced computational costs. Analyses further reveal\\nthat the key improvements consistently stem from the emergence of more compact,\\ncyclic reasoning structures under the orchestrator's evolution.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.CL,cs.AI,cs.MA              |cs.AI      |\n",
      "|http://arxiv.org/abs/2505.19592v1|Occurrence of fast neutrino flavor conversions in QCD phase-transition\\n  supernovae Core-collapse supernovae undergoing a first-order quantum chromodynamics\\n(QCD) phase transition experience the collapse of the central proto-neutron\\nstar that leads to a second bounce. This event is accompanied by the release of\\na second neutrino burst. Unlike the first stellar core bounce neutrino burst\\nwhich consists exclusively of electron neutrinos, the second burst is dominated\\nby electron antineutrinos. Such a condition makes QCD supernovae an ideal site\\nfor the occurrence of fast neutrino flavor conversion (FFC), which can lead to\\nrapid flavor equilibration and significantly impact the related neutrino\\nsignal. In this work, we perform a detailed analysis of the conditions for fast\\nflavor instability (FFI) around and after the second neutrino burst in a QCD\\nphase transition supernova model launched from a 25~$M_\\odot$ progenitor mass.\\nWe evaluate the relevant instability criteria and find two major phases of FFC.\\nThe first phase is closely associated with the collapse and the rapidly\\nexpanding shock wave, which is a direct consequence of the proto-neutron star\\ncollapse due to the phase transition. The second phase takes place a few\\nmilliseconds later when electron degeneracy is restored near the proto-neutron\\nstar surface. We also characterize the growth rate of FFI and estimate its\\nimpact on the evolution of the neutrino flavor content. The potential\\nobservational consequences on neutrino signals are evaluated by comparing a\\nscenario assuming complete flavor equipartition with other scenarios without\\nFFC. Finally, we investigate how FFC may influences $r$-process nucleosynthesis\\nassociated with QCD phase transition driven supernova explosions.                                                                                                                                                         |astro-ph.HE,hep-ph             |hep-ph     |\n",
      "|http://arxiv.org/abs/2505.19593v1|On quotients of ideals of weighted holomorphic mappings We explore the procedure given by left-hand quotients in the context of\\nweighted holomorphic ideals. On the one hand, we show that this procedure does\\nnot generate new ideals other than the ideal of weighted holomorphic mappings\\nwhen considering the left-hand quotients induced by the ideals of $p$-compact,\\nweakly $p$-compact, unconditionally $p$-compact, approximable or right\\n$p$-nuclear operators with their respective weighted holomorphic ideals. On the\\nother hand, the procedure is of interest when considering other operators\\nideals as it provides new weighted holomorphic ideals. This is the case of the\\nideal of Grothendieck weighted holomorphic mappings or the ideal of Rosenthal\\nweighted holomorphic mappings, where the applicability of this construction is\\nshown.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |math.CV,math.FA                |math.CV    |\n",
      "|http://arxiv.org/abs/2505.19594v1|On novel Hamiltonian description of the nonholonomic Suslov problem We present some new Poisson bivectors that are invariants by the flow of the\\nnonholonomic Suslov problem. Two rank four invariant Poisson bivectors have\\nglobally defined Casimir functions and, therefore, define cubic Poisson\\nbrackets on the five dimensional state space with standard symplectic leaves.\\nFor the Suslov gyrostat in the potential field we found rank two Poisson\\nbivectors having only two globally defined Casimir functions and, therefore, we\\nsay about formal Hamiltonian description in these cases.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |nlin.SI,math-ph,math.DS,math.MP|math-ph    |\n",
      "|http://arxiv.org/abs/2505.19595v1|Accelerating Diffusion-based Text-to-Speech Model Training with Dual\\n  Modality Alignment The goal of this paper is to optimize the training process of diffusion-based\\ntext-to-speech models. While recent studies have achieved remarkable\\nadvancements, their training demands substantial time and computational costs,\\nlargely due to the implicit guidance of diffusion models in learning complex\\nintermediate representations. To address this, we propose A-DMA, an effective\\nstrategy for Accelerating training with Dual Modality Alignment. Our method\\nintroduces a novel alignment pipeline leveraging both text and speech\\nmodalities: text-guided alignment, which incorporates contextual\\nrepresentations, and speech-guided alignment, which refines semantic\\nrepresentations. By aligning hidden states with discriminative features, our\\ntraining scheme reduces the reliance on diffusion models for learning complex\\nrepresentations. Extensive experiments demonstrate that A-DMA doubles the\\nconvergence speed while achieving superior performance over baselines. Code and\\ndemo samples are available at: https://github.com/ZhikangNiu/A-DMA                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |eess.AS,cs.SD                  |cs.CL      |\n",
      "+---------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-33-50.json\n",
      "\n",
      "========= 2025-05-29 21:34:00 =========\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-----------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |true_label                       |pred             |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-----------------+\n",
      "|http://arxiv.org/abs/2505.19601v1|Preference Optimization by Estimating the Ratio of the Data Distribution Direct preference optimization (DPO) is widely used as a simple and stable\\nmethod for aligning large language models (LLMs) with human preferences. This\\npaper investigates a generalized DPO loss that enables a policy model to match\\nthe target policy from a likelihood ratio estimation perspective. The ratio of\\nthe target policy provides a unique identification of the policy distribution\\nwithout relying on reward models or partition functions. This allows the\\ngeneralized loss to retain both simplicity and theoretical guarantees, which\\nprior work such as $f$-PO fails to achieve simultaneously. We propose Bregman\\npreference optimization (BPO), a generalized framework for ratio matching that\\nprovides a family of objective functions achieving target policy optimality.\\nBPO subsumes DPO as a special case and offers tractable forms for all\\ninstances, allowing implementation with a few lines of code. We further develop\\nscaled Basu's power divergence (SBA), a gradient scaling method that can be\\nused for BPO instances. The BPO framework complements other DPO variants and is\\napplicable to target policies defined by these variants. In experiments, unlike\\nother probabilistic loss extensions such as $f$-DPO or $f$-PO, which exhibit a\\ntrade-off between generation fidelity and diversity, instances of BPO improve\\nboth win rate and entropy compared with DPO. When applied to\\nLlama-3-Instruct-8B, BPO achieves state-of-the-art performance among Llama-3-8B\\nbackbones, with a 55.9\\% length-controlled win rate on AlpacaEval2.                                                                                                                                                                                                                                                                                                                                                                                                          |cs.LG,cs.AI,cs.CL                |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19602v1|Memory-Efficient Visual Autoregressive Modeling with Scale-Aware KV\\n  Cache Compression Visual Autoregressive (VAR) modeling has garnered significant attention for\\nits innovative next-scale prediction approach, which yields substantial\\nimprovements in efficiency, scalability, and zero-shot generalization.\\nNevertheless, the coarse-to-fine methodology inherent in VAR results in\\nexponential growth of the KV cache during inference, causing considerable\\nmemory consumption and computational redundancy. To address these bottlenecks,\\nwe introduce ScaleKV, a novel KV cache compression framework tailored for VAR\\narchitectures. ScaleKV leverages two critical observations: varying cache\\ndemands across transformer layers and distinct attention patterns at different\\nscales. Based on these insights, ScaleKV categorizes transformer layers into\\ntwo functional groups: drafters and refiners. Drafters exhibit dispersed\\nattention across multiple scales, thereby requiring greater cache capacity.\\nConversely, refiners focus attention on the current token map to process local\\ndetails, consequently necessitating substantially reduced cache capacity.\\nScaleKV optimizes the multi-scale inference pipeline by identifying\\nscale-specific drafters and refiners, facilitating differentiated cache\\nmanagement tailored to each scale. Evaluation on the state-of-the-art\\ntext-to-image VAR model family, Infinity, demonstrates that our approach\\neffectively reduces the required KV cache memory to 10% while preserving\\npixel-level fidelity.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.LG                            |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19603v1|Rep3D: Re-parameterize Large 3D Kernels with Low-Rank Receptive Modeling\\n  for Medical Imaging In contrast to vision transformers, which model long-range dependencies\\nthrough global self-attention, large kernel convolutions provide a more\\nefficient and scalable alternative, particularly in high-resolution 3D\\nvolumetric settings. However, naively increasing kernel size often leads to\\noptimization instability and degradation in performance. Motivated by the\\nspatial bias observed in effective receptive fields (ERFs), we hypothesize that\\ndifferent kernel elements converge at variable rates during training. To\\nsupport this, we derive a theoretical connection between element-wise gradients\\nand first-order optimization, showing that structurally re-parameterized\\nconvolution blocks inherently induce spatially varying learning rates. Building\\non this insight, we introduce Rep3D, a 3D convolutional framework that\\nincorporates a learnable spatial prior into large kernel training. A\\nlightweight two-stage modulation network generates a receptive-biased scaling\\nmask, adaptively re-weighting kernel updates and enabling local-to-global\\nconvergence behavior. Rep3D adopts a plain encoder design with large depthwise\\nconvolutions, avoiding the architectural complexity of multi-branch\\ncompositions. We evaluate Rep3D on five challenging 3D segmentation benchmarks\\nand demonstrate consistent improvements over state-of-the-art baselines,\\nincluding transformer-based and fixed-prior re-parameterization methods. By\\nunifying spatial inductive bias with optimization-aware learning, Rep3D offers\\nan interpretable, and scalable solution for 3D medical image analysis. The\\nsource code is publicly available at https://github.com/leeh43/Rep3D.                                                                                                                                                                                                                                                            |cs.CV,cs.LG                      |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19604v1|Evaluating Machine Translation Models for English-Hindi Language Pairs:\\n  A Comparative Analysis Machine translation has become a critical tool in bridging linguistic gaps,\\nespecially between languages as diverse as English and Hindi. This paper\\ncomprehensively evaluates various machine translation models for translating\\nbetween English and Hindi. We assess the performance of these models using a\\ndiverse set of automatic evaluation metrics, both lexical and machine\\nlearning-based metrics. Our evaluation leverages an 18000+ corpus of English\\nHindi parallel dataset and a custom FAQ dataset comprising questions from\\ngovernment websites. The study aims to provide insights into the effectiveness\\nof different machine translation approaches in handling both general and\\nspecialized language domains. Results indicate varying performance levels\\nacross different metrics, highlighting strengths and areas for improvement in\\ncurrent translation systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |cs.CL,cs.LG                      |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19605v1|Kuramoto-FedAvg: Using Synchronization Dynamics to Improve Federated\\n  Learning Optimization under Statistical Heterogeneity Federated learning on heterogeneous (non-IID) client data experiences slow\\nconvergence due to client drift. To address this challenge, we propose\\nKuramoto-FedAvg, a federated optimization algorithm that reframes the weight\\naggregation step as a synchronization problem inspired by the Kuramoto model of\\ncoupled oscillators. The server dynamically weighs each client's update based\\non its phase alignment with the global update, amplifying contributions that\\nalign with the global gradient direction while minimizing the impact of updates\\nthat are out of phase. We theoretically prove that this synchronization\\nmechanism reduces client drift, providing a tighter convergence bound compared\\nto the standard FedAvg under heterogeneous data distributions. Empirical\\nvalidation supports our theoretical findings, showing that Kuramoto-FedAvg\\nsignificantly accelerates convergence and improves accuracy across multiple\\nbenchmark datasets. Our work highlights the potential of coordination and\\nsynchronization-based strategies for managing gradient diversity and\\naccelerating federated optimization in realistic non-IID settings.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |cs.LG                            |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19606v1|Languages in Multilingual Speech Foundation Models Align Both\\n  Phonetically and Semantically Cross-lingual alignment in pretrained language models (LMs) has enabled\\nefficient transfer in text-based LMs. Such an alignment has also been observed\\nin speech foundation models. However, it remains an open question whether\\nfindings and methods from text-based cross-lingual alignment apply to speech.\\nBuilding on prior work on spoken translation retrieval, we perform\\npronunciation-controlled experiments to observe if cross-lingual alignment can\\nindeed occur in such models on a semantic basis, instead of relying on phonetic\\nsimilarities. Our findings indicate that even in the absence of phonetic cues,\\nspoken translation retrieval accuracy remains relatively stable. We follow up\\nwith a controlled experiment on a word-level dataset of cross-lingual synonyms\\nand near-homophones, confirming the existence of both phonetic and semantic\\nknowledge in the encoder. Finally, we qualitatively examine the transcriptions\\nproduced by early exiting the encoder, where we observe that speech translation\\nproduces semantic errors that are characterized by phonetic similarities to\\ncorresponding words in the source language. We apply this insight from early\\nexiting to speech recognition in seven low-resource languages unsupported by\\nthe Whisper model, and achieve improved accuracy in all languages examined,\\nparticularly for languages with transparent orthographies.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |cs.CL                            |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19607v1|Energy-based Preference Optimization for Test-time Adaptation Test-Time Adaptation (TTA) enhances model robustness by enabling adaptation\\nto target distributions that differ from training distributions, improving\\nreal-world generalizability. Existing TTA approaches focus on adjusting the\\nconditional distribution; however these methods often depend on uncertain\\npredictions in the absence of label information, leading to unreliable\\nperformance. Energy-based frameworks suggest a promising alternative to address\\ndistribution shifts without relying on uncertain predictions, instead computing\\nthe marginal distribution of target data. However, they involve the critical\\nchallenge of requiring extensive SGLD sampling, which is impractical for\\ntest-time scenarios requiring immediate adaptation. In this work, we propose\\nEnergy-based Preference Optimization for Test-time Adaptation (EPOTTA), which\\nis based on a sampling free strategy. We first parameterize the target model\\nusing a pretrained model and residual energy function, enabling marginal\\nlikelihood maximization of target data without sampling. Building on the\\nobservation that the parameterization is mathematically equivalent to DPO\\nobjective, we then directly adapt the model to a target distribution without\\nexplicitly training the residual. Our experiments verify that EPOTTA is\\nwell-calibrated and performant while achieving computational efficiency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.LG,cs.AI                      |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19608v1|Solving Implicit Inverse Problems with Homotopy-Based Regularization\\n  Path Implicit inverse problems, in which noisy observations of a physical quantity\\nare used to infer a nonlinear functional applied to an associated function, are\\ninherently ill posed and often exhibit non uniqueness of solutions. Such\\nproblems arise in a range of domains, including the identification of systems\\ngoverned by Ordinary and Partial Differential Equations (ODEs/PDEs), optimal\\ncontrol, and data assimilation. Their solution is complicated by the nonlinear\\nnature of the underlying constraints and the instability introduced by noise.\\nIn this paper, we propose a homotopy based optimization method for solving such\\nproblems. Beginning with a regularized constrained formulation that includes a\\nsparsity promoting regularization term, we employ a gradient based algorithm in\\nwhich gradients with respect to the model parameters are efficiently computed\\nusing the adjoint state method. Nonlinear constraints are handled through a\\nNewton Raphson procedure. By solving a sequence of problems with decreasing\\nregularization, we trace a solution path that improves stability and enables\\nthe exploration of multiple candidate solutions. The method is applied to the\\nlatent dynamics discovery problem in simulation, highlighting performance as a\\nfunction of ground truth sparsity and semi convergence behavior.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |math.NA,cs.NA,math.OC            |math.OC          |\n",
      "|http://arxiv.org/abs/2505.19609v1|Skrull: Towards Efficient Long Context Fine-tuning through Dynamic Data\\n  Scheduling Long-context supervised fine-tuning (Long-SFT) plays a vital role in\\nenhancing the performance of large language models (LLMs) on long-context\\ntasks. To smoothly adapt LLMs to long-context scenarios, this process typically\\nentails training on mixed datasets containing both long and short sequences.\\nHowever, this heterogeneous sequence length distribution poses significant\\nchallenges for existing training systems, as they fail to simultaneously\\nachieve high training efficiency for both long and short sequences, resulting\\nin sub-optimal end-to-end system performance in Long-SFT. In this paper, we\\npresent a novel perspective on data scheduling to address the challenges posed\\nby the heterogeneous data distributions in Long-SFT. We propose Skrull, a\\ndynamic data scheduler specifically designed for efficient long-SFT. Through\\ndynamic data scheduling, Skrull balances the computation requirements of long\\nand short sequences, improving overall training efficiency. Furthermore, we\\nformulate the scheduling process as a joint optimization problem and thoroughly\\nanalyze the trade-offs involved. Based on those analysis, Skrull employs a\\nlightweight scheduling algorithm to achieve near-zero cost online scheduling in\\nLong-SFT. Finally, we implement Skrull upon DeepSpeed, a state-of-the-art\\ndistributed training system for LLMs. Experimental results demonstrate that\\nSkrull outperforms DeepSpeed by 3.76x on average (up to 7.54x) in real-world\\nlong-SFT scenarios.                                                                                                                                                                                                                                                                                                                                                                                                                                                      |cs.LG,cs.AI                      |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19610v1|JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language\\n  Models Vision-Language Models (VLMs) exhibit impressive performance, yet the\\nintegration of powerful vision encoders has significantly broadened their\\nattack surface, rendering them increasingly susceptible to jailbreak attacks.\\nHowever, lacking well-defined attack objectives, existing jailbreak methods\\noften struggle with gradient-based strategies prone to local optima and lacking\\nprecise directional guidance, and typically decouple visual and textual\\nmodalities, thereby limiting their effectiveness by neglecting crucial\\ncross-modal interactions. Inspired by the Eliciting Latent Knowledge (ELK)\\nframework, we posit that VLMs encode safety-relevant information within their\\ninternal fusion-layer representations, revealing an implicit safety decision\\nboundary in the latent space. This motivates exploiting boundary to steer model\\nbehavior. Accordingly, we propose JailBound, a novel latent space jailbreak\\nframework comprising two stages: (1) Safety Boundary Probing, which addresses\\nthe guidance issue by approximating decision boundary within fusion layer's\\nlatent space, thereby identifying optimal perturbation directions towards the\\ntarget region; and (2) Safety Boundary Crossing, which overcomes the\\nlimitations of decoupled approaches by jointly optimizing adversarial\\nperturbations across both image and text inputs. This latter stage employs an\\ninnovative mechanism to steer the model's internal state towards\\npolicy-violating outputs while maintaining cross-modal semantic consistency.\\nExtensive experiments on six diverse VLMs demonstrate JailBound's efficacy,\\nachieves 94.32% white-box and 67.28% black-box attack success averagely, which\\nare 6.17% and 21.13% higher than SOTA methods, respectively. Our findings\\nexpose a overlooked safety risk in VLMs and highlight the urgent need for more\\nrobust defenses. Warning: This paper contains potentially sensitive, harmful\\nand offensive content.|cs.CV                            |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19611v1|Align and Surpass Human Camouflaged Perception: Visual Refocus\\n  Reinforcement Fine-Tuning Current multi-modal models exhibit a notable misalignment with the human\\nvisual system when identifying objects that are visually assimilated into the\\nbackground. Our observations reveal that these multi-modal models cannot\\ndistinguish concealed objects, demonstrating an inability to emulate human\\ncognitive processes which effectively utilize foreground-background similarity\\nprinciples for visual analysis. To analyze this hidden human-model visual\\nthinking discrepancy, we build a visual system that mimicks human visual\\ncamouflaged perception to progressively and iteratively `refocus' visual\\nconcealed content. The refocus is a progressive guidance mechanism enabling\\nmodels to logically localize objects in visual images through stepwise\\nreasoning. The localization process of concealed objects requires hierarchical\\nattention shifting with dynamic adjustment and refinement of prior cognitive\\nknowledge. In this paper, we propose a visual refocus reinforcement framework\\nvia the policy optimization algorithm to encourage multi-modal models to think\\nand refocus more before answering, and achieve excellent reasoning abilities to\\nalign and even surpass human camouflaged perception systems. Our extensive\\nexperiments on camouflaged perception successfully demonstrate the emergence of\\nrefocus visual phenomena, characterized by multiple reasoning tokens and\\ndynamic adjustment of the detection box. Besides, experimental results on both\\ncamouflaged object classification and detection tasks exhibit significantly\\nsuperior performance compared to Supervised Fine-Tuning (SFT) baselines.                                                                                                                                                                                                                                                                                                                 |cs.CV,cs.AI                      |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19612v1|Optimal Intervention for Self-triggering Spatial Networks with\\n  Application to Urban Crime Analytics In many network systems, events at one node trigger further activity at other\\nnodes, e.g., social media users reacting to each other's posts or the\\nclustering of criminal activity in urban environments. These systems are\\ntypically referred to as self-exciting networks. In such systems, targeted\\nintervention at critical nodes can be an effective strategy for mitigating\\nundesirable consequences such as further propagation of criminal activity or\\nthe spreading of misinformation on social media. In our work, we develop an\\noptimal network intervention model to explore how targeted interventions at\\ncritical nodes can mitigate cascading effects throughout a Spatiotemporal\\nHawkes network. Similar models have been studied previously in the literature\\nin purely temporal Hawkes networks, but in our work, we extend them to a\\nspatiotemporal setup and demonstrate the efficacy of our methods by comparing\\nthe post-intervention reduction in intensity to other heuristic strategies in\\nsimulated networks. Subsequently, we use our method on crime data from the LA\\npolice department database to find neighborhoods for strategic intervention to\\ndemonstrate an application in predictive policing.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.SI,stat.ME                    |cs.SI            |\n",
      "|http://arxiv.org/abs/2505.19613v1|TESSER: Transfer-Enhancing Adversarial Attacks from Vision Transformers\\n  via Spectral and Semantic Regularization Adversarial transferability remains a critical challenge in evaluating the\\nrobustness of deep neural networks. In security-critical applications,\\ntransferability enables black-box attacks without access to model internals,\\nmaking it a key concern for real-world adversarial threat assessment. While\\nVision Transformers (ViTs) have demonstrated strong adversarial performance,\\nexisting attacks often fail to transfer effectively across architectures,\\nespecially from ViTs to Convolutional Neural Networks (CNNs) or hybrid models.\\nIn this paper, we introduce \\textbf{TESSER} -- a novel adversarial attack\\nframework that enhances transferability via two key strategies: (1)\\n\\textit{Feature-Sensitive Gradient Scaling (FSGS)}, which modulates gradients\\nbased on token-wise importance derived from intermediate feature activations,\\nand (2) \\textit{Spectral Smoothness Regularization (SSR)}, which suppresses\\nhigh-frequency noise in perturbations using a differentiable Gaussian prior.\\nThese components work in tandem to generate perturbations that are both\\nsemantically meaningful and spectrally smooth. Extensive experiments on\\nImageNet across 12 diverse architectures demonstrate that TESSER achieves\\n+10.9\\% higher attack succes rate (ASR) on CNNs and +7.2\\% on ViTs compared to\\nthe state-of-the-art Adaptive Token Tuning (ATT) method. Moreover, TESSER\\nsignificantly improves robustness against defended models, achieving 53.55\\%\\nASR on adversarially trained CNNs. Qualitative analysis shows strong alignment\\nbetween TESSER's perturbations and salient visual regions identified via\\nGrad-CAM, while frequency-domain analysis reveals a 12\\% reduction in\\nhigh-frequency energy, confirming the effectiveness of spectral regularization.                                                                                                                                               |cs.CV                            |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19614v1|Multiplicity is an Inevitable and Inherent Challenge in Multimodal\\n  Learning Multimodal learning has seen remarkable progress, particularly with the\\nemergence of large-scale pre-training across various modalities. However, most\\ncurrent approaches are built on the assumption of a deterministic, one-to-one\\nalignment between modalities. This oversimplifies real-world multimodal\\nrelationships, where their nature is inherently many-to-many. This phenomenon,\\nnamed multiplicity, is not a side-effect of noise or annotation error, but an\\ninevitable outcome of semantic abstraction, representational asymmetry, and\\ntask-dependent ambiguity in multimodal tasks. This position paper argues that\\nmultiplicity is a fundamental bottleneck that manifests across all stages of\\nthe multimodal learning pipeline: from data construction to training and\\nevaluation. This paper examines the causes and consequences of multiplicity,\\nand highlights how multiplicity introduces training uncertainty, unreliable\\nevaluation, and low dataset quality. This position calls for new research\\ndirections on multimodal learning: novel multiplicity-aware learning frameworks\\nand dataset construction protocols considering multiplicity.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.LG,cs.CV                      |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19615v1|$b$-axis and $c$-axis Knight shift measurements in the superconducting\\n  state on ultraclean UTe$_2$ with $T_c$ = 2.1 K Knight shifts along the $b$ and $c$ axes ($K_b$ and $K_c$) at two\\ncrystallographically distinct Te sites were measured down to 70 mK using\\n$^{125}$Te nuclear magnetic resonance (NMR) on an ultraclean UTe$_2$ single\\ncrystal with a superconducting (SC) transition temperature $T_{\\mathrm{c}}$ =\\n2.1 K. This was carried out to determine the $\\boldsymbol{d}$-vector\\ncomponents, which are the order parameter in the spin-triplet pairing. Although\\nthe decrease in $K_b$ and $K_c$ is comparable to the theoretical estimation of\\nthe SC diamagnetic shielding effect, it is confirmed, by taking the difference\\nbetween two Knight shifts at the distinct Te sites, that the spin\\nsusceptibility along the $b$ and $c$ axes decreases in the SC state. Taking\\ninto account the large decrease in $K_a$ in the SC state, we conclude that the\\n$\\boldsymbol{d}$ vector has components along all three crystal axes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cond-mat.supr-con,cond-mat.str-el|cond-mat.supr-con|\n",
      "|http://arxiv.org/abs/2505.19616v1|Diagnosing and Mitigating Modality Interference in Multimodal Large\\n  Language Models Multimodal Large Language Models (MLLMs) have demonstrated impressive\\ncapabilities across tasks, yet they often exhibit difficulty in distinguishing\\ntask-relevant from irrelevant signals, particularly in tasks like Visual\\nQuestion Answering (VQA), which can lead to susceptibility to misleading or\\nspurious inputs. We refer to this broader limitation as the Cross-Modality\\nCompetency Problem: the model's inability to fairly evaluate all modalities.\\nThis vulnerability becomes more evident in modality-specific tasks such as\\nimage classification or pure text question answering, where models are expected\\nto rely solely on one modality. In such tasks, spurious information from\\nirrelevant modalities often leads to significant performance degradation. We\\nrefer to this failure as Modality Interference, which serves as a concrete and\\nmeasurable instance of the cross-modality competency problem. We further design\\na perturbation-based causal diagnostic experiment to verify and quantify this\\nproblem. To mitigate modality interference, we propose a novel framework to\\nfine-tune MLLMs, including perturbation-based data augmentations with both\\nheuristic perturbations and adversarial perturbations via Projected Gradient\\nDescent (PGD), and a consistency regularization strategy applied to model\\noutputs with original and perturbed inputs. Experiments on multiple benchmark\\ndatasets (image-heavy, text-heavy, and VQA tasks) and multiple model families\\nwith different scales demonstrate significant improvements in robustness and\\ncross-modality competency, indicating our method's effectiveness in boosting\\nunimodal reasoning ability while enhancing performance on multimodal tasks.                                                                                                                                                                                                                               |cs.LG,cs.AI,cs.CV                |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19617v1|Hybrid Models for Financial Forecasting: Combining Econometric, Machine\\n  Learning, and Deep Learning Models This research systematically develops and evaluates various hybrid modeling\\napproaches by combining traditional econometric models (ARIMA and ARFIMA\\nmodels) with machine learning and deep learning techniques (SVM, XGBoost, and\\nLSTM models) to forecast financial time series. The empirical analysis is based\\non two distinct financial assets: the S&P 500 index and Bitcoin. By\\nincorporating over two decades of daily data for the S&P 500 and almost ten\\nyears of Bitcoin data, the study provides a comprehensive evaluation of\\nforecasting methodologies across different market conditions and periods of\\nfinancial distress. Models' training and hyperparameter tuning procedure is\\nperformed using a novel three-fold dynamic cross-validation method. The\\napplicability of applied models is evaluated using both forecast error metrics\\nand trading performance indicators. The obtained findings indicate that the\\nproper construction process of hybrid models plays a crucial role in developing\\nprofitable trading strategies, outperforming their individual components and\\nthe benchmark Buy&Hold strategy. The most effective hybrid model architecture\\nwas achieved by combining the econometric ARIMA model with either SVM or LSTM,\\nunder the assumption of a non-additive relationship between the linear and\\nnonlinear components.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |q-fin.TR                         |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19618v1|Rotation-Equivariant Self-Supervised Method in Image Denoising Self-supervised image denoising methods have garnered significant research\\nattention in recent years, for this kind of method reduces the requirement of\\nlarge training datasets. Compared to supervised methods, self-supervised\\nmethods rely more on the prior embedded in deep networks themselves. As a\\nresult, most of the self-supervised methods are designed with Convolution\\nNeural Networks (CNNs) architectures, which well capture one of the most\\nimportant image prior, translation equivariant prior. Inspired by the great\\nsuccess achieved by the introduction of translational equivariance, in this\\npaper, we explore the way to further incorporate another important image prior.\\nSpecifically, we first apply high-accuracy rotation equivariant convolution to\\nself-supervised image denoising. Through rigorous theoretical analysis, we have\\nproved that simply replacing all the convolution layers with rotation\\nequivariant convolution layers would modify the network into its rotation\\nequivariant version. To the best of our knowledge, this is the first time that\\nrotation equivariant image prior is introduced to self-supervised image\\ndenoising at the network architecture level with a comprehensive theoretical\\nanalysis of equivariance errors, which offers a new perspective to the field of\\nself-supervised image denoising. Moreover, to further improve the performance,\\nwe design a new mask mechanism to fusion the output of rotation equivariant\\nnetwork and vanilla CNN-based network, and construct an adaptive rotation\\nequivariant framework. Through extensive experiments on three typical methods,\\nwe have demonstrated the effectiveness of the proposed method.                                                                                                                                                                                                                                                                          |cs.CV                            |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19619v1|SESaMo: Symmetry-Enforcing Stochastic Modulation for Normalizing Flows Deep generative models have recently garnered significant attention across\\nvarious fields, from physics to chemistry, where sampling from unnormalized\\nBoltzmann-like distributions represents a fundamental challenge. In particular,\\nautoregressive models and normalizing flows have become prominent due to their\\nappealing ability to yield closed-form probability densities. Moreover, it is\\nwell-established that incorporating prior knowledge - such as symmetries - into\\ndeep neural networks can substantially improve training performances. In this\\ncontext, recent advances have focused on developing symmetry-equivariant\\ngenerative models, achieving remarkable results. Building upon these\\nfoundations, this paper introduces Symmetry-Enforcing Stochastic Modulation\\n(SESaMo). Similar to equivariant normalizing flows, SESaMo enables the\\nincorporation of inductive biases (e.g., symmetries) into normalizing flows\\nthrough a novel technique called stochastic modulation. This approach enhances\\nthe flexibility of the generative model, allowing to effectively learn a\\nvariety of exact and broken symmetries. Our numerical experiments benchmark\\nSESaMo in different scenarios, including an 8-Gaussian mixture model and\\nphysically relevant field theories, such as the $\\phi^4$ theory and the Hubbard\\nmodel.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.LG,physics.comp-ph            |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19620v1|Decoupling Spatio-Temporal Prediction: When Lightweight Large Models\\n  Meet Adaptive Hypergraphs Spatio-temporal prediction is a pivotal task with broad applications in\\ntraffic management, climate monitoring, energy scheduling, etc. However,\\nexisting methodologies often struggle to balance model expressiveness and\\ncomputational efficiency, especially when scaling to large real-world datasets.\\nTo tackle these challenges, we propose STH-SepNet (Spatio-Temporal Hypergraph\\nSeparation Networks), a novel framework that decouples temporal and spatial\\nmodeling to enhance both efficiency and precision. Therein, the temporal\\ndimension is modeled using lightweight large language models, which effectively\\ncapture low-rank temporal dynamics. Concurrently, the spatial dimension is\\naddressed through an adaptive hypergraph neural network, which dynamically\\nconstructs hyperedges to model intricate, higher-order interactions. A\\ncarefully designed gating mechanism is integrated to seamlessly fuse temporal\\nand spatial representations. By leveraging the fundamental principles of\\nlow-rank temporal dynamics and spatial interactions, STH-SepNet offers a\\npragmatic and scalable solution for spatio-temporal prediction in real-world\\napplications. Extensive experiments on large-scale real-world datasets across\\nmultiple benchmarks demonstrate the effectiveness of STH-SepNet in boosting\\npredictive performance while maintaining computational efficiency. This work\\nmay provide a promising lightweight framework for spatio-temporal prediction,\\naiming to reduce computational demands and while enhancing predictive\\nperformance. Our code is avaliable at\\nhttps://github.com/SEU-WENJIA/ST-SepNet-Lightweight-LLMs-Meet-Adaptive-Hypergraphs.                                                                                                                                                                                                                                                                       |cs.LG,cs.AI                      |cs.LG            |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-34-00.json\n",
      "\n",
      "========= 2025-05-29 21:34:10 =========\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-----------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |true_label                   |pred             |\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-----------------+\n",
      "|http://arxiv.org/abs/2505.19625v1|Search-Based Software Engineering in the Landscape of AI Foundation\\n  Models Search-based software engineering (SBSE), at the intersection of artificial\\nintelligence (AI) and software engineering, has been an active area of research\\nfor about 25 years. It has been applied to solve numerous problems across the\\nentire software engineering lifecycle and has demonstrated its versatility in\\nmultiple domains. With the recent advancements in AI, particularly the\\nemergence of foundation models (FMs), the evolution of SBSE alongside FMs\\nremains undetermined. In this window of opportunity, we propose a research\\nroadmap that articulates the current landscape of SBSE in relation to\\nfoundation models (FMs), highlights open challenges, and outlines potential\\nresearch directions for advancing SBSE through its interplay with FMs. This\\nroadmap aims to establish a forward-thinking and innovative perspective for the\\nfuture of SBSE in the era of FMs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.SE,cs.AI                  |cs.SE            |\n",
      "|http://arxiv.org/abs/2505.19626v1|Decoding Speaker-Normalized Pitch from EEG for Mandarin Perception The same speech content produced by different speakers exhibits significant\\ndifferences in pitch contour, yet listeners' semantic perception remains\\nunaffected. This phenomenon may stem from the brain's perception of pitch\\ncontours being independent of individual speakers' pitch ranges. In this work,\\nwe recorded electroencephalogram (EEG) while participants listened to Mandarin\\nmonosyllables with varying tones, phonemes, and speakers. The CE-ViViT model is\\nproposed to decode raw or speaker-normalized pitch contours directly from EEG.\\nExperimental results demonstrate that the proposed model can decode pitch\\ncontours with modest errors, achieving performance comparable to\\nstate-of-the-art EEG regression methods. Moreover, speaker-normalized pitch\\ncontours were decoded more accurately, supporting the neural encoding of\\nrelative pitch.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.SD,eess.AS                |eess.AS          |\n",
      "|http://arxiv.org/abs/2505.19627v1|In-depth Investigation of Conduction Mechanism on Defect-induced\\n  Proton-conducting Electrolytes BaHfO$_3$ This study utilizes first-principles computational methods to comprehensively\\nanalyze the impact of A-site doping on the proton conduction properties of\\nBaHfO$_3$. The goal is to offer theoretical support for the advancement of\\nelectrolyte materials for solid oxide fuel cells. Our research has uncovered\\nthat BaHfO$_3$ demonstrates promising potential for proton conduction, with a\\nlow proton migration barrier of 0.28 eV, suggesting efficient proton conduction\\ncan be achieved at lower temperatures. Through A-site doping, particularly with\\nlow-valence state ions and the introduction of Ba vacancies, we can effectively\\ndecrease the formation energy of oxygen vacancies (Evac), leading to an\\nincrease in proton concentration. Additionally, our study reveals that the\\nprimary mechanism for proton migration in BaHfO$_3$ is the Grotthuss mechanism\\nrather than the Vehicle mechanism. Examination of the changes in lattice\\nparameters during proton migration indicates that while doping or vacancy\\ncontrol strategies do not alter the mode of H+ migration, they do influence the\\nmigration pathway and barrier. These findings provide valuable insights into\\noptimizing the proton conduction properties of BaHfO$_3$ through A-site doping\\nand lay a solid theoretical foundation for the development of novel, highly\\nefficient Solid oxide fuel cell electrolyte materials.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cond-mat.mtrl-sci            |cond-mat.mtrl-sci|\n",
      "|http://arxiv.org/abs/2505.19628v1|HomeBench: Evaluating LLMs in Smart Homes with Valid and Invalid\\n  Instructions Across Single and Multiple Devices Large language models (LLMs) have the potential to revolutionize smart home\\nassistants by enhancing their ability to accurately understand user needs and\\nrespond appropriately, which is extremely beneficial for building a smarter\\nhome environment. While recent studies have explored integrating LLMs into\\nsmart home systems, they primarily focus on handling straightforward, valid\\nsingle-device operation instructions. However, real-world scenarios are far\\nmore complex and often involve users issuing invalid instructions or\\ncontrolling multiple devices simultaneously. These have two main challenges:\\nLLMs must accurately identify and rectify errors in user instructions and\\nexecute multiple user instructions perfectly. To address these challenges and\\nadvance the development of LLM-based smart home assistants, we introduce\\nHomeBench, the first smart home dataset with valid and invalid instructions\\nacross single and multiple devices in this paper. We have experimental results\\non 13 distinct LLMs; e.g., GPT-4o achieves only a 0.0% success rate in the\\nscenario of invalid multi-device instructions, revealing that the existing\\nstate-of-the-art LLMs still cannot perform well in this situation even with the\\nhelp of in-context learning, retrieval-augmented generation, and fine-tuning.\\nOur code and dataset are publicly available at\\nhttps://github.com/BITHLP/HomeBench.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |cs.CL                        |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19629v1|Software Engineering for Self-Adaptive Robotics: A Research Agenda Self-adaptive robotic systems are designed to operate autonomously in dynamic\\nand uncertain environments, requiring robust mechanisms to monitor, analyse,\\nand adapt their behaviour in real-time. Unlike traditional robotic software,\\nwhich follows predefined logic, self-adaptive robots leverage artificial\\nintelligence, machine learning, and model-driven engineering to continuously\\nadjust to changing operational conditions while ensuring reliability, safety,\\nand performance. This paper presents a research agenda for software engineering\\nin self-adaptive robotics, addressing critical challenges across two key\\ndimensions: (1) the development phase, including requirements engineering,\\nsoftware design, co-simulation, and testing methodologies tailored to adaptive\\nrobotic systems, and (2) key enabling technologies, such as digital twins,\\nmodel-driven engineering, and AI-driven adaptation, which facilitate runtime\\nmonitoring, fault detection, and automated decision-making. We discuss open\\nresearch challenges, including verifying adaptive behaviours under uncertainty,\\nbalancing trade-offs between adaptability, performance, and safety, and\\nintegrating self-adaptation frameworks like MAPE-K. By providing a structured\\nroadmap, this work aims to advance the software engineering foundations for\\nself-adaptive robotic systems, ensuring they remain trustworthy, efficient, and\\ncapable of handling real-world complexities.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.SE,cs.RO                  |cs.RO            |\n",
      "|http://arxiv.org/abs/2505.19630v1|DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning\\n  System for Multi-Turn Clinical Dialogue Large language models (LLMs) have demonstrated excellent capabilities in the\\nfield of biomedical question answering, but their application in real-world\\nclinical consultations still faces core challenges. Existing systems rely on a\\none-way information transmission mode where patients must fully describe their\\nsymptoms in a single round, leading to nonspecific diagnostic recommendations\\nwhen complaints are vague. Traditional multi-turn dialogue methods based on\\nsupervised learning are constrained by static data-driven paradigms, lacking\\ngeneralizability and struggling to intelligently extract key clinical\\ninformation. To address these limitations, we propose DoctorAgent-RL, a\\nreinforcement learning (RL)-based multi-agent collaborative framework that\\nmodels medical consultations as a dynamic decision-making process under\\nuncertainty. The doctor agent continuously optimizes its questioning strategy\\nwithin the RL framework through multi-turn interactions with the patient agent,\\ndynamically adjusting its information-gathering path based on comprehensive\\nrewards from the Consultation Evaluator. This RL fine-tuning mechanism enables\\nLLMs to autonomously develop interaction strategies aligned with clinical\\nreasoning logic, rather than superficially imitating patterns in existing\\ndialogue data. Notably, we constructed MTMedDialog, the first English\\nmulti-turn medical consultation dataset capable of simulating patient\\ninteractions. Experiments demonstrate that DoctorAgent-RL outperforms existing\\nmodels in both multi-turn reasoning capability and final diagnostic\\nperformance, demonstrating practical value in assisting clinical consultations.\\nhttps://github.com/JarvisUSTC/DoctorAgent-RL                                                                                                                                                                                                  |cs.CL                        |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19631v1|Segment First or Comprehend First? Explore the Limit of Unsupervised\\n  Word Segmentation with Large Language Models Word segmentation stands as a cornerstone of Natural Language Processing\\n(NLP). Based on the concept of \"comprehend first, segment later\", we propose a\\nnew framework to explore the limit of unsupervised word segmentation with Large\\nLanguage Models (LLMs) and evaluate the semantic understanding capabilities of\\nLLMs based on word segmentation. We employ current mainstream LLMs to perform\\nword segmentation across multiple languages to assess LLMs' \"comprehension\".\\nOur findings reveal that LLMs are capable of following simple prompts to\\nsegment raw text into words. There is a trend suggesting that models with more\\nparameters tend to perform better on multiple languages. Additionally, we\\nintroduce a novel unsupervised method, termed LLACA ($\\textbf{L}$arge\\n$\\textbf{L}$anguage Model-Inspired $\\textbf{A}$ho-$\\textbf{C}$orasick\\n$\\textbf{A}$utomaton). Leveraging the advanced pattern recognition capabilities\\nof Aho-Corasick automata, LLACA innovatively combines these with the deep\\ninsights of well-pretrained LLMs. This approach not only enables the\\nconstruction of a dynamic $n$-gram model that adjusts based on contextual\\ninformation but also integrates the nuanced understanding of LLMs, offering\\nsignificant improvements over traditional methods. Our source code is available\\nat https://github.com/hkr04/LLACA                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.CL,cs.AI                  |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19632v1|Krein space quantization and New Quantum Algorithms Krein space quantization and the ambient space formalism have been\\nsuccessfully applied to address challenges in quantum geometry (e.g., quantum\\ngravity) and the axiomatic formulation of quantum Yang-Mills theory, including\\nphenomena such as color confinement and the mass gap. Building on these\\nadvancements, we aim to extend these methods to develop novel quantum\\nalgorithms for quantum computation, particularly targeting underdetermined or\\nill-conditioned linear systems of equations, as well as quantum systems\\ncharacterized by non-unitary evolution and open quantum dynamics. This approach\\nrepresents a significant step beyond commonly used techniques, such as Quantum\\nSingular Value Decomposition, Sz.-Nagy dilation, and Unitary Operator\\nDecomposition. The proposed algorithm has the potential to establish a unified\\nframework for quantum algorithms.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |gr-qc                        |quant-ph         |\n",
      "|http://arxiv.org/abs/2505.19633v1|Weak-Jamming Detection in IEEE 802.11 Networks: Techniques, Scenarios\\n  and Mobility State-of-the-art solutions detect jamming attacks ex-post, i.e., only when\\njamming has already disrupted the wireless communication link. In many\\nscenarios, e.g., mobile networks or static deployments distributed over a large\\ngeographical area, it is often desired to detect jamming at the early stage,\\nwhen it affects the communication link enough to be detected but not\\nsufficiently to disrupt it (detection of weak jamming signals). Under such\\nassumptions, devices can enhance situational awareness and promptly apply\\nmitigation, e.g., moving away from the jammed area in mobile scenarios or\\nchanging communication frequency in static deployments, before jamming fully\\ndisrupts the communication link. Although some contributions recently\\ndemonstrated the feasibility of detecting low-power and weak jamming signals,\\nthey make simplistic assumptions far from real-world deployments. Given the\\ncurrent state of the art, no evidence exists that detection of weak jamming can\\nbe considered with real-world communication technologies. In this paper, we\\nprovide and comprehensively analyze new general-purpose strategies for\\ndetecting weak jamming signals, compatible by design with one of the most\\nrelevant communication technologies used by commercial-off-the-shelf devices,\\ni.e., IEEE 802.11. We describe two operational modes: (i) binary classification\\nvia Convolutional Neural Networks and (ii) one-class classification via Sparse\\nAutoencoders. We evaluate and compare the proposed approaches with the current\\nstate-of-the-art using data collected through an extensive real-world\\nexperimental campaign in three relevant environments. At the same time, we made\\nthe dataset available to the public. Our results demonstrate that detecting\\nweak jamming signals is feasible in all considered real-world environments, and\\nwe provide an in-depth analysis considering different techniques, scenarios,\\nand mobility patterns.|cs.CR                        |cs.NI            |\n",
      "|http://arxiv.org/abs/2505.19634v1|Faster and Better LLMs via Latency-Aware Test-Time Scaling Test-Time Scaling (TTS) has proven effective in improving the performance of\\nLarge Language Models (LLMs) during inference. However, existing research has\\noverlooked the efficiency of TTS from a latency-sensitive perspective. Through\\na latency-aware evaluation of representative TTS methods, we demonstrate that a\\ncompute-optimal TTS does not always result in the lowest latency in scenarios\\nwhere latency is critical. To address this gap and achieve latency-optimal TTS,\\nwe propose two key approaches by optimizing the concurrency configurations: (1)\\nbranch-wise parallelism, which leverages multiple concurrent inference\\nbranches, and (2) sequence-wise parallelism, enabled by speculative decoding.\\nBy integrating these two approaches and allocating computational resources\\nproperly to each, our latency-optimal TTS enables a 32B model to reach 82.3%\\naccuracy on MATH-500 within 1 minute and a smaller 3B model to achieve 72.4%\\nwithin 10 seconds. Our work emphasizes the importance of latency-aware TTS and\\ndemonstrates its ability to deliver both speed and accuracy in\\nlatency-sensitive scenarios.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |cs.CL                        |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19635v1|When fractional quasi p-norms concentrate Concentration of distances in high dimension is an important factor for the\\ndevelopment and design of stable and reliable data analysis algorithms. In this\\npaper, we address the fundamental long-standing question about the\\nconcentration of distances in high dimension for fractional quasi $p$-norms,\\n$p\\in(0,1)$. The topic has been at the centre of various theoretical and\\nempirical controversies. Here we, for the first time, identify conditions when\\nfractional quasi $p$-norms concentrate and when they don't. We show that\\ncontrary to some earlier suggestions, for broad classes of distributions,\\nfractional quasi $p$-norms admit exponential and uniform in $p$ concentration\\nbounds. For these distributions, the results effectively rule out previously\\nproposed approaches to alleviate concentration by \"optimal\" setting the values\\nof $p$ in $(0,1)$. At the same time, we specify conditions and the\\ncorresponding families of distributions for which one can still control\\nconcentration rates by appropriate choices of $p$. We also show that in an\\narbitrarily small vicinity of a distribution from a large class of\\ndistributions for which uniform concentration occurs, there are uncountably\\nmany other distributions featuring anti-concentration properties. Importantly,\\nthis behavior enables devising relevant data encoding or representation schemes\\nfavouring or discouraging distance concentration. The results shed new light on\\nthis long-standing problem and resolve the tension around the topic in both\\ntheory and empirical evidence reported in the literature.                                                                                                                                                                                                                                                                                                                                                                                                                     |cs.LG,math.ST,stat.ML,stat.TH|math.ST          |\n",
      "|http://arxiv.org/abs/2505.19636v1|Longitudinal magnetoconductivity in chiral multifold semimetals\\n  exemplified by pseudospin-1 nodal points We embark on computing the longitudinal magnetoconductivity within the\\nsemiclassical Boltzmann formalism, where an isotropic triple-point semimetal\\n(TSM) is subjected to collinear electric ($\\boldsymbol E $) and magnetic\\n($\\boldsymbol B$) fields. Except for the Drude part, the $B$-dependence arises\\nexclusively from topological properties like the Berry curvature and the\\norbital magnetic moment. We solve the Boltzmann equations exactly in the\\nlinear-response regime, applicable in the limit of weak/nonquantising magnetic\\nfields. The novelty of our investigation lies in the consideration of the truly\\nmultifold character of the TSMs, where the so-called flat-band (flatness being\\nmerely an artifact of linear-order approximations) is made dispersive by\\nincorporating the appropriate quadratic-in-momentum correction in the effective\\nHamiltonian. It necessitates the consideration of interband scatterings within\\nthe same node as well, providing a complex interplay of intraband, interband,\\nintranode, and internode processes. The exact results are compared with those\\nobtained from a naive relaxation-time approximation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cond-mat.mes-hall,hep-th     |cond-mat.str-el  |\n",
      "|http://arxiv.org/abs/2505.19637v1|Adaptive Episode Length Adjustment for Multi-agent Reinforcement\\n  Learning In standard reinforcement learning, an episode is defined as a sequence of\\ninteractions between agents and the environment, which terminates upon reaching\\na terminal state or a pre-defined episode length. Setting a shorter episode\\nlength enables the generation of multiple episodes with the same number of data\\nsamples, thereby facilitating an exploration of diverse states. While shorter\\nepisodes may limit the collection of long-term interactions, they may offer\\nsignificant advantages when properly managed. For example, trajectory\\ntruncation in single-agent reinforcement learning has shown how the benefits of\\nshorter episodes can be leveraged despite the trade-off of reduced long-term\\ninteraction experiences. However, this approach remains underexplored in MARL.\\nThis paper proposes a novel MARL approach, Adaptive Episode Length Adjustment\\n(AELA), where the episode length is initially limited and gradually increased\\nbased on an entropy-based assessment of learning progress. By starting with\\nshorter episodes, agents can focus on learning effective strategies for initial\\nstates and minimize time spent in dead-end states. The use of entropy as an\\nassessment metric prevents premature convergence to suboptimal policies and\\nensures balanced training over varying episode lengths. We validate our\\napproach using the StarCraft Multi-agent Challenge (SMAC) and a modified\\npredator-prey environment, demonstrating significant improvements in both\\nconvergence speed and overall performance compared to existing methods. To the\\nbest of our knowledge, this is the first study to adaptively adjust episode\\nlength in MARL based on learning progress.                                                                                                                                                                                                                                                                                        |cs.MA,I.2.11                 |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19638v1|HF-VTON: High-Fidelity Virtual Try-On via Consistent Geometric and\\n  Semantic Alignment Virtual try-on technology has become increasingly important in the fashion\\nand retail industries, enabling the generation of high-fidelity garment images\\nthat adapt seamlessly to target human models. While existing methods have\\nachieved notable progress, they still face significant challenges in\\nmaintaining consistency across different poses. Specifically, geometric\\ndistortions lead to a lack of spatial consistency, mismatches in garment\\nstructure and texture across poses result in semantic inconsistency, and the\\nloss or distortion of fine-grained details diminishes visual fidelity. To\\naddress these challenges, we propose HF-VTON, a novel framework that ensures\\nhigh-fidelity virtual try-on performance across diverse poses. HF-VTON consists\\nof three key modules: (1) the Appearance-Preserving Warp Alignment Module\\n(APWAM), which aligns garments to human poses, addressing geometric\\ndeformations and ensuring spatial consistency; (2) the Semantic Representation\\nand Comprehension Module (SRCM), which captures fine-grained garment attributes\\nand multi-pose data to enhance semantic representation, maintaining structural,\\ntextural, and pattern consistency; and (3) the Multimodal Prior-Guided\\nAppearance Generation Module (MPAGM), which integrates multimodal features and\\nprior knowledge from pre-trained models to optimize appearance generation,\\nensuring both semantic and geometric consistency. Additionally, to overcome\\ndata limitations in existing benchmarks, we introduce the SAMP-VTONS dataset,\\nfeaturing multi-pose pairs and rich textual annotations for a more\\ncomprehensive evaluation. Experimental results demonstrate that HF-VTON\\noutperforms state-of-the-art methods on both VITON-HD and SAMP-VTONS, excelling\\nin visual fidelity, semantic consistency, and detail preservation.                                                                                                                          |cs.CV                        |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19639v1|Range Space or Null Space: Least-Squares Methods for the Realization\\n  Problem This contribution revisits the classical approximate realization problem,\\nwhich involves determining matrices of a state-space model based on estimates\\nof a truncated series of Markov parameters. A Hankel matrix built up by these\\nMarkov parameters plays a fundamental role in this problem, leveraging the fact\\nthat both its range space and left null space encode critical information about\\nthe state-space model. We examine two prototype realization algorithms based on\\nthe Hankel matrix: the classical range-space-based (SVD-based) method and the\\nmore recent null-space-based method. It is demonstrated that the\\nrange-space-based method corresponds to a total least-squares solution, whereas\\nthe null-space-based method corresponds to an ordinary least-squares solution.\\nBy analyzing the differences in sensitivity of the two algorithms, we determine\\nthe conditions when one or the other realization algorithm is to be preferred,\\nand identify factors that contribute to an ill-conditioned realization problem.\\nFurthermore, recognizing that both methods are suboptimal, we argue that the\\noptimal realization is obtained through a weighted least-squares approach. A\\nstatistical analysis of these methods, including their consistency and\\nasymptotic normality is also provided.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |eess.SY,cs.SY                |eess.SY          |\n",
      "|http://arxiv.org/abs/2505.19640v1|Interleaved Reasoning for Large Language Models via Reinforcement\\n  Learning Long chain-of-thought (CoT) significantly enhances large language models'\\n(LLM) reasoning capabilities. However, the extensive reasoning traces lead to\\ninefficiencies and an increased time-to-first-token (TTFT). We propose a novel\\ntraining paradigm that uses reinforcement learning (RL) to guide reasoning LLMs\\nto interleave thinking and answering for multi-hop questions. We observe that\\nmodels inherently possess the ability to perform interleaved reasoning, which\\ncan be further enhanced through RL. We introduce a simple yet effective\\nrule-based reward to incentivize correct intermediate steps, which guides the\\npolicy model toward correct reasoning paths by leveraging intermediate signals\\ngenerated during interleaved reasoning. Extensive experiments conducted across\\nfive diverse datasets and three RL algorithms (PPO, GRPO, and REINFORCE++)\\ndemonstrate consistent improvements over traditional think-answer reasoning,\\nwithout requiring external tools. Specifically, our approach reduces TTFT by\\nover 80% on average and improves up to 19.3% in Pass@1 accuracy. Furthermore,\\nour method, trained solely on question answering and logical reasoning\\ndatasets, exhibits strong generalization ability to complex reasoning datasets\\nsuch as MATH, GPQA, and MMLU. Additionally, we conduct in-depth analysis to\\nreveal several valuable insights into conditional reward modeling.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.CL                        |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19641v1|SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning\\n  Logical Reasoning and Beyond Recent advances such as OpenAI-o1 and DeepSeek R1 have demonstrated the\\npotential of Reinforcement Learning (RL) to enhance reasoning abilities in\\nLarge Language Models (LLMs). While open-source replication efforts have\\nprimarily focused on mathematical and coding domains, methods and resources for\\ndeveloping general reasoning capabilities remain underexplored. This gap is\\npartly due to the challenge of collecting diverse and verifiable reasoning data\\nsuitable for RL. We hypothesize that logical reasoning is critical for\\ndeveloping general reasoning capabilities, as logic forms a fundamental\\nbuilding block of reasoning. In this work, we present SynLogic, a data\\nsynthesis framework and dataset that generates diverse logical reasoning data\\nat scale, encompassing 35 diverse logical reasoning tasks. The SynLogic\\napproach enables controlled synthesis of data with adjustable difficulty and\\nquantity. Importantly, all examples can be verified by simple rules, making\\nthem ideally suited for RL with verifiable rewards. In our experiments, we\\nvalidate the effectiveness of RL training on the SynLogic dataset based on 7B\\nand 32B models. SynLogic leads to state-of-the-art logical reasoning\\nperformance among open-source datasets, surpassing DeepSeek-R1-Distill-Qwen-32B\\nby 6 points on BBEH. Furthermore, mixing SynLogic data with mathematical and\\ncoding tasks improves the training efficiency of these domains and\\nsignificantly enhances reasoning generalization. Notably, our mixed training\\nmodel outperforms DeepSeek-R1-Zero-Qwen-32B across multiple benchmarks. These\\nfindings position SynLogic as a valuable resource for advancing the broader\\nreasoning capabilities of LLMs. We open-source both the data synthesis pipeline\\nand the SynLogic dataset at https://github.com/MiniMax-AI/SynLogic.                                                                                                          |cs.AI,cs.CL                  |cs.AI            |\n",
      "|http://arxiv.org/abs/2505.19642v1|On the weak $k$-metric dimension of Hamming graphs Given a connected graph $G$, a set of vertices $X\\subset V(G)$ is a weak\\n$k$-resolving set of $G$ if for each two vertices $y,z\\in V(G)$, the sum of the\\nvalues $|d_G(y,x)-d_G(z,x)|$ over all $x\\in X$ is at least $k$, where\\n$d_G(u,v)$ stands for the length of a shortest path between $u$ and $v$. The\\ncardinality of a smallest weak $k$-resolving set of $G$ is the weak $k$-metric\\ndimension of $G$, and is denoted by $\\mathrm{wdim}_k(G)$. In this paper,\\n$\\mathrm{wdim}_k(K_n\\,\\square\\,K_n)$ is determined for every $n\\ge 3$ and every\\n$2\\le k\\le 2n$. An improvement of a known integer linear programming\\nformulation for this problem is developed and implemented for the graphs\\n$K_n\\,\\square\\,K_m$. Conjectures regarding these general situations are posed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |math.CO                      |math.CO          |\n",
      "|http://arxiv.org/abs/2505.19643v1|Online activity prediction via generalized Indian buffet process models Online A/B experiments generate millions of user-activity records each day,\\nyet experimenters need timely forecasts to guide roll-outs and safeguard user\\nexperience. Motivated by the problem of activity prediction for A/B tests at\\nAmazon, we introduce a Bayesian nonparametric model for predicting both\\nfirst-time and repeat triggers in web experiments. The model is based on the\\nstable beta-scaled process prior, which allows for capturing heavy-tailed\\nbehaviour without strict parametric assumptions. All posterior and predictive\\nquantities are available in closed form, allowing for fast inference even on\\nlarge-scale datasets. Simulation studies and a retrospective analysis of 1,774\\nproduction experiments show improved accuracy in forecasting new users and\\ntotal triggers compared with state-of-the-art competitors, especially when only\\na few pilot days are observed. The framework enables shorter tests while\\npreserving calibrated uncertainty estimates. Although motivated by Amazon's\\nexperimentation platform, the method extends to other applications that require\\nrapid, distribution-free prediction of sparse count processes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |stat.AP                      |stat.ME          |\n",
      "|http://arxiv.org/abs/2505.19644v1|STOPA: A Database of Systematic VariaTion Of DeePfake Audio for Open-Set\\n  Source Tracing and Attribution A key research area in deepfake speech detection is source tracing -\\ndetermining the origin of synthesised utterances. The approaches may involve\\nidentifying the acoustic model (AM), vocoder model (VM), or other\\ngeneration-specific parameters. However, progress is limited by the lack of a\\ndedicated, systematically curated dataset. To address this, we introduce STOPA,\\na systematically varied and metadata-rich dataset for deepfake speech source\\ntracing, covering 8 AMs, 6 VMs, and diverse parameter settings across 700k\\nsamples from 13 distinct synthesisers. Unlike existing datasets, which often\\nfeature limited variation or sparse metadata, STOPA provides a systematically\\ncontrolled framework covering a broader range of generative factors, such as\\nthe choice of the vocoder model, acoustic model, or pretrained weights,\\nensuring higher attribution reliability. This control improves attribution\\naccuracy, aiding forensic analysis, deepfake detection, and generative model\\ntransparency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |cs.SD,cs.AI,cs.CR,eess.AS    |cs.SD            |\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-34-10.json\n",
      "\n",
      "========= 2025-05-29 21:34:20 =========\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------+--------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |true_label                                     |pred    |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------+--------+\n",
      "|http://arxiv.org/abs/2505.19649v1|A just-infinite iterated monodromy group without the congruence subgroup\\n  property We prove that the iterated monodromy group of the polynomial $z^2+i$ is\\njust-infinite, regular branch and does not have the congruence subgroup\\nproperty. This yields the first example of an iterated monodromy group of a\\npolynomial with these properties. Additional information is provided about the\\ncongruence kernel, rigid kernel and branch kernel of this group.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |math.GR                                        |math.GR |\n",
      "|http://arxiv.org/abs/2505.19650v1|Modality Curation: Building Universal Embeddings for Advanced Multimodal\\n  Information Retrieval Multimodal information retrieval (MIR) faces inherent challenges due to the\\nheterogeneity of data sources and the complexity of cross-modal alignment.\\nWhile previous studies have identified modal gaps in feature spaces, a\\nsystematic approach to address these challenges remains unexplored. In this\\nwork, we introduce UNITE, a universal framework that tackles these challenges\\nthrough two critical yet underexplored aspects: data curation and\\nmodality-aware training configurations. Our work provides the first\\ncomprehensive analysis of how modality-specific data properties influence\\ndownstream task performance across diverse scenarios. Moreover, we propose\\nModal-Aware Masked Contrastive Learning (MAMCL) to mitigate the competitive\\nrelationships among the instances of different modalities. Our framework\\nachieves state-of-the-art results on multiple multimodal retrieval benchmarks,\\noutperforming existing methods by notable margins. Through extensive\\nexperiments, we demonstrate that strategic modality curation and tailored\\ntraining protocols are pivotal for robust cross-modal representation learning.\\nThis work not only advances MIR performance but also provides a foundational\\nblueprint for future research in multimodal systems. Our project is available\\nat https://friedrichor.github.io/projects/UNITE.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.CV,cs.IR,cs.MM                              |cs.CV   |\n",
      "|http://arxiv.org/abs/2505.19651v1|Greybody factors as robust gravitational observables: insights into\\n  post-merger signals and echoes from ultracompact object The quasinormal mode spectrum plays a central role in modeling the\\npost-merger ringdown phase of binary coalescences of compact objects. However,\\nits interpretation is subject to certain ambiguities. Motivated by a recently\\ndiscovered connection between greybody factors and post-merger black hole\\nsignals, we investigate the robustness of greybody factors as gravitational\\nobservables, offering a complementary perspective to quasinormal mode analysis.\\nWe show that greybody factors are stable under small perturbations and are not\\naffected by the specific ambiguities that limit the reliability of quasinormal\\nmodes. Furthermore, we demonstrate that greybody factors are equally relevant\\nfor characterizing the signals emitted by wormholes and other horizonless\\nultracompact objects, providing a natural explanation for the echoes observed\\nin the time-domain response of such object.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |gr-qc                                          |gr-qc   |\n",
      "|http://arxiv.org/abs/2505.19652v1|SACM: SEEG-Audio Contrastive Matching for Chinese Speech Decoding Speech disorders such as dysarthria and anarthria can severely impair the\\npatient's ability to communicate verbally. Speech decoding brain-computer\\ninterfaces (BCIs) offer a potential alternative by directly translating speech\\nintentions into spoken words, serving as speech neuroprostheses. This paper\\nreports an experimental protocol for Mandarin Chinese speech decoding BCIs,\\nalong with the corresponding decoding algorithms. Stereo-electroencephalography\\n(SEEG) and synchronized audio data were collected from eight drug-resistant\\nepilepsy patients as they conducted a word-level reading task. The proposed\\nSEEG and Audio Contrastive Matching (SACM), a contrastive learning-based\\nframework, achieved decoding accuracies significantly exceeding chance levels\\nin both speech detection and speech decoding tasks. Electrode-wise analysis\\nrevealed that a single sensorimotor cortex electrode achieved performance\\ncomparable to that of the full electrode array. These findings provide valuable\\ninsights for developing more accurate online speech decoding BCIs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |cs.HC,cs.SD,eess.AS                            |q-bio.NC|\n",
      "|http://arxiv.org/abs/2505.19653v1|Token-Importance Guided Direct Preference Optimization Ensuring that large language models (LLMs) generate outputs aligned with\\nhuman preferences is important for safe and effective AI interactions. While\\nDirect Preference Optimization (DPO) employs an implicit reward function to\\noptimize the policy model, however, it and its related variants overlook the\\ndifferential importance of individual tokens and are sensitive to judgment\\nnoise in preference datasets during generation. Although recent methods attempt\\nto assess the important weight of tokens via probability prediction or\\nsimplistic weighting schemes, these evaluation methods are prone to biases and\\nstill cannot fully address these issues. To solve this problem, we propose the\\nToken-Importance Guided Direct Preference Optimization (TI-DPO), which\\nintroduces two key innovations: the gradient-based token-importance weights\\nthat dynamically prioritize critical tokens, and a triple loss that explicitly\\nguides model outputs to approach human-preferred responses and stay away from\\nnon-preferred responses. Experimental results show that TI-DPO achieves higher\\naccuracy and stronger generative diversity, providing more stable and\\ncomputationally efficient solutions compared with DPO and other RLHF methods.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cs.AI                                          |cs.LG   |\n",
      "|http://arxiv.org/abs/2505.19654v1|A Short Character Sum in $\\mathbb{F}_{p^3}$ We establish a new bound for short character sums in finite fields,\\nparticularly over two-dimensional grids in $\\mathbb{F}_{p^3}$ and\\nhigher-dimensional lattices in $\\mathbb{F}_{p^d}$, extending an earlier work of\\nMei-Chu Chang on Burgess inequality in \\(\\mathbb{F}_{p^2}\\). In particular, we\\nshow that for intervals of size $p^{3/8+\\varepsilon}$, the sum $\\sum_{x, y}\\n\\chi(x + \\omega y)$, with $\\omega \\in \\mathbb{F}_{p^3} \\setminus \\mathbb{F}_p$,\\nexhibits nontrivial cancellation uniformly in $\\omega$. This is further\\ngeneralized to codimension-one sublattices in $\\mathbb{F}_{p^d}$, and applied\\nto obtain an alternative estimate for character sums on binary cubic forms.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |math.NT                                        |math.NT |\n",
      "|http://arxiv.org/abs/2505.19655v1|Flow approach on Riesz type nonlocal energies Via continuous deformations based on natural flow evolutions, we prove\\nseveral novel monotonicity results for Riesz-type nonlocal energies on\\ntriangles and quadrilaterals. Some of these results imply new and simpler\\nproofs for known theorems without relying on any symmetrization arguments.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |math.AP                                        |math.AP |\n",
      "|http://arxiv.org/abs/2505.19656v1|ReDDiT: Rehashing Noise for Discrete Visual Generation Discrete diffusion models are gaining traction in the visual generative area\\nfor their efficiency and compatibility. However, the pioneered attempts still\\nfall behind the continuous counterparts, which we attribute to the noise\\n(absorbing state) design and sampling heuristics. In this study, we propose the\\nrehashing noise framework for discrete diffusion transformer, termed ReDDiT, to\\nextend absorbing states and improve expressive capacity of discrete diffusion\\nmodels. ReDDiT enriches the potential paths that latent variables can traverse\\nduring training with randomized multi-index corruption. The derived rehash\\nsampler, which reverses the randomized absorbing paths, guarantees the\\ndiversity and low discrepancy of the generation process. These reformulations\\nlead to more consistent and competitive generation quality, mitigating the need\\nfor heavily tuned randomness. Experiments show that ReDDiT significantly\\noutperforms the baseline (reducing gFID from 6.18 to 1.61) and is on par with\\nthe continuous counterparts with higher efficiency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |cs.CV                                          |cs.CV   |\n",
      "|http://arxiv.org/abs/2505.19657v1|Autonomous Flights inside Narrow Tunnels Multirotors are usually desired to enter confined narrow tunnels that are\\nbarely accessible to humans in various applications including inspection,\\nsearch and rescue, and so on. This task is extremely challenging since the lack\\nof geometric features and illuminations, together with the limited field of\\nview, cause problems in perception; the restricted space and significant ego\\nairflow disturbances induce control issues. This paper introduces an autonomous\\naerial system designed for navigation through tunnels as narrow as 0.5 m in\\ndiameter. The real-time and online system includes a virtual omni-directional\\nperception module tailored for the mission and a novel motion planner that\\nincorporates perception and ego airflow disturbance factors modeled using\\ncamera projections and computational fluid dynamics analyses, respectively.\\nExtensive flight experiments on a custom-designed quadrotor are conducted in\\nmultiple realistic narrow tunnels to validate the superior performance of the\\nsystem, even over human pilots, proving its potential for real applications.\\nAdditionally, a deployment pipeline on other multirotor platforms is outlined\\nand open-source packages are provided for future developments.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.RO                                          |cs.RO   |\n",
      "|http://arxiv.org/abs/2505.19658v1|Large Language Models in Code Co-generation for Safe Autonomous Vehicles Software engineers in various industrial domains are already using Large\\nLanguage Models (LLMs) to accelerate the process of implementing parts of\\nsoftware systems. When considering its potential use for ADAS or AD systems in\\nthe automotive context, there is a need to systematically assess this new\\nsetup: LLMs entail a well-documented set of risks for safety-related systems'\\ndevelopment due to their stochastic nature. To reduce the effort for code\\nreviewers to evaluate LLM-generated code, we propose an evaluation pipeline to\\nconduct sanity-checks on the generated code. We compare the performance of six\\nstate-of-the-art LLMs (CodeLlama, CodeGemma, DeepSeek-r1, DeepSeek-Coders,\\nMistral, and GPT-4) on four safety-related programming tasks. Additionally, we\\nqualitatively analyse the most frequent faults generated by these LLMs,\\ncreating a failure-mode catalogue to support human reviewers. Finally, the\\nlimitations and capabilities of LLMs in code generation, and the use of the\\nproposed pipeline in the existing process, are discussed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.SE,cs.AI                                    |cs.SE   |\n",
      "|http://arxiv.org/abs/2505.19659v1|LangDAug: Langevin Data Augmentation for Multi-Source Domain\\n  Generalization in Medical Image Segmentation Medical image segmentation models often struggle to generalize across\\ndifferent domains due to various reasons. Domain Generalization (DG) methods\\novercome this either through representation learning or data augmentation\\n(DAug). While representation learning methods seek domain-invariant features,\\nthey often rely on ad-hoc techniques and lack formal guarantees. DAug methods,\\nwhich enrich model representations through synthetic samples, have shown\\ncomparable or superior performance to representation learning approaches. We\\npropose LangDAug, a novel $\\textbf{Lang}$evin $\\textbf{D}$ata\\n$\\textbf{Aug}$mentation for multi-source domain generalization in 2D medical\\nimage segmentation. LangDAug leverages Energy-Based Models (EBMs) trained via\\ncontrastive divergence to traverse between source domains, generating\\nintermediate samples through Langevin dynamics. Theoretical analysis shows that\\nLangDAug induces a regularization effect, and for GLMs, it upper-bounds the\\nRademacher complexity by the intrinsic dimensionality of the data manifold.\\nThrough extensive experiments on Fundus segmentation and 2D MRI prostate\\nsegmentation benchmarks, we show that LangDAug outperforms state-of-the-art\\ndomain generalization methods and effectively complements existing\\ndomain-randomization approaches. The codebase for our method is available at\\nhttps://github.com/backpropagator/LangDAug.                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.CV                                          |cs.CV   |\n",
      "|http://arxiv.org/abs/2505.19660v1|GenKI: Enhancing Open-Domain Question Answering with Knowledge\\n  Integration and Controllable Generation in Large Language Models Open-domain question answering (OpenQA) represents a cornerstone in natural\\nlanguage processing (NLP), primarily focused on extracting answers from\\nunstructured textual data. With the rapid advancements in Large Language Models\\n(LLMs), LLM-based OpenQA methods have reaped the benefits of emergent\\nunderstanding and answering capabilities enabled by massive parameters compared\\nto traditional methods. However, most of these methods encounter two critical\\nchallenges: how to integrate knowledge into LLMs effectively and how to\\nadaptively generate results with specific answer formats for various task\\nsituations. To address these challenges, we propose a novel framework named\\nGenKI, which aims to improve the OpenQA performance by exploring Knowledge\\nIntegration and controllable Generation on LLMs simultaneously. Specifically,\\nwe first train a dense passage retrieval model to retrieve associated knowledge\\nfrom a given knowledge base. Subsequently, we introduce a novel knowledge\\nintegration model that incorporates the retrieval knowledge into instructions\\nduring fine-tuning to intensify the model. Furthermore, to enable controllable\\ngeneration in LLMs, we leverage a certain fine-tuned LLM and an ensemble based\\non text consistency incorporating all coherence, fluency, and answer format\\nassurance. Finally, extensive experiments conducted on the TriviaQA, MSMARCO,\\nand CMRC2018 datasets, featuring diverse answer formats, have demonstrated the\\neffectiveness of GenKI with comparison of state-of-the-art baselines. Moreover,\\nablation studies have disclosed a linear relationship between the frequency of\\nretrieved knowledge and the model's ability to recall knowledge accurately\\nagainst the ground truth. Our code of GenKI is available at\\nhttps://github.com/USTC-StarTeam/GenKI|cs.CL,cs.AI                                    |cs.CL   |\n",
      "|http://arxiv.org/abs/2505.19661v1|A duality of Bethe algebras for general linear Lie (super)algebras We study the joint action of the Bethe algebra $\\mathcal{B}_d^{\\bf{w}}$ for\\nthe general linear Lie algebra $\\mathfrak{gl}_d$ with respect to ${\\bf w} \\in\\n\\mathbb{C}^d$ and the Bethe algebra $\\mathcal{B}_{p+m|q+n}^{\\bf{z}}$ for the\\ngeneral linear Lie superalgebra $\\mathfrak{gl}_{p+m|q+n}$ with respect to ${\\bf\\nz} \\in \\mathbb{C}^{p+q+m+n}$ on the Fock space of $d(p+m)$ bosonic and $d(q+n)$\\nfermionic oscillators. We establish a duality, called the Bethe duality of\\n$(\\mathfrak{gl}_d, \\mathfrak{gl}_{p+m|q+n})$, which is an equivalence between\\nthe actions of the algebras $\\mathcal{B}_d^{\\bf{w}}$ and\\n$\\mathcal{B}_{p+m|q+n}^{\\bf{z}}$ on the Fock space. As an application, we show\\nthat the action of $\\mathcal{B}_{p+m|q+n}^{\\bf{z}}$ on each weight space of the\\nevaluation module $\\underline{M}({\\bf w})$, where $\\underline{M}$ is a $d$-fold\\ntensor product of certain classes of infinite-dimensional unitarizable highest\\nweight $\\mathfrak{gl}_{p+m|q+n}$-modules, is a cyclic\\n$\\mathcal{B}_{p+m|q+n}^{\\bf{z}}$-module, and that\\n$\\mathcal{B}_{p+m|q+n}^{\\bf{z}}$ is diagonalizable with a simple spectrum on\\nthe weight space for generic $\\bf{w}$ and $\\bf{z}$.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |math.RT,math-ph,math.MP                        |math.RT |\n",
      "|http://arxiv.org/abs/2505.19662v1|FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks This paper proposes FieldWorkArena, a benchmark for agentic AI targeting\\nreal-world field work. With the recent increase in demand for agentic AI, they\\nare required to monitor and report safety and health incidents, as well as\\nmanufacturing-related incidents, that may occur in real-world work\\nenvironments. Existing agentic AI benchmarks have been limited to evaluating\\nweb tasks and are insufficient for evaluating agents in real-world work\\nenvironments, where complexity increases significantly. In this paper, we\\ndefine a new action space that agentic AI should possess for real world work\\nenvironment benchmarks and improve the evaluation function from previous\\nmethods to assess the performance of agentic AI in diverse real-world tasks.\\nThe dataset consists of videos captured on-site and documents actually used in\\nfactories and warehouses, and tasks were created based on interviews with\\non-site workers and managers. Evaluation results confirmed that performance\\nevaluation considering the characteristics of Multimodal LLM (MLLM) such as\\nGPT-4o is feasible. Additionally, the effectiveness and limitations of the\\nproposed new evaluation method were identified. The complete dataset\\n(HuggingFace) and evaluation program (GitHub) can be downloaded from the\\nfollowing website:\\nhttps://en-documents.research.global.fujitsu.com/fieldworkarena/.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cs.AI,cs.CV                                    |cs.AI   |\n",
      "|http://arxiv.org/abs/2505.19663v1|A Comprehensive Real-World Assessment of Audio Watermarking Algorithms:\\n  Will They Survive Neural Codecs? We present a framework to foster the evaluation of deep learning-based audio\\nwatermarking algorithms, establishing a standardized benchmark and allowing\\nsystematic comparisons. To simulate real-world usage, we introduce a\\ncomprehensive audio attack pipeline, featuring various distortions such as\\ncompression, background noise, and reverberation, and propose a diverse test\\ndataset, including speech, environmental sounds, and music recordings. By\\nassessing the performance of four existing watermarking algorithms on our\\nframework, two main insights stand out: (i) neural compression techniques pose\\nthe most significant challenge, even when algorithms are trained with such\\ncompressions; and (ii) training with audio attacks generally improves\\nrobustness, although it is insufficient in some cases. Furthermore, we find\\nthat specific distortions, such as polarity inversion, time stretching, or\\nreverb, seriously affect certain algorithms. Our contributions strengthen the\\nrobustness and perceptual assessment of audio watermarking algorithms across a\\nwide range of applications, while ensuring a fair and consistent evaluation\\napproach. The evaluation framework, including the attack pipeline, is\\naccessible at github.com/SonyResearch/wm_robustness_eval.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.SD,cs.AI,cs.CR,cs.LG,eess.AS                |cs.SD   |\n",
      "|http://arxiv.org/abs/2505.19664v1|Probabilistic Analysis of Graphon Mean Field Control Motivated by recent interest in graphon mean field games and their\\napplications, this paper provides a comprehensive probabilistic analysis of\\ngraphon mean field control (GMFC) problems, where the controlled dynamics are\\ngoverned by a graphon mean field stochastic differential equation with\\nheterogeneous mean field interactions. We formulate the GMFC problem with\\ngeneral graphon mean field dependence and establish the existence and\\nuniqueness of the associated graphon mean field forward-backward stochastic\\ndifferential equations (FBSDEs). We then derive a version of the Pontryagin\\nstochastic maximum principle tailored to GMFC problems. Furthermore, we analyze\\nthe solvability of the GMFC problem for linear dynamics and study the\\ncontinuity and stability of the graphon mean field FBSDEs under the optimal\\ncontrol profile. Finally, we show that the solution to the GMFC problem\\nprovides an approximately optimal solution for large systems with heterogeneous\\nmean field interactions, based on a propagation of chaos result.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |math.OC,math.PR                                |math.OC |\n",
      "|http://arxiv.org/abs/2505.19665v1|Spin-Waves without Spin-Waves: A Case for Soliton Propagation in\\n  Starling Flocks Collective turns in starling flocks propagate linearly with negligible\\nattenuation, indicating the existence of an underdamped sector in the\\ndispersion relation. Beside granting linear propagation of the phase\\nperturbations, the real part of the frequency should also yield a spin-wave\\nform of the unperturbed correlation function. However, new high-resolution\\nexperiments on real flocks show that underdamped traveling waves coexist with\\nan overdamped Lorentzian correlation. Theory and experiments are reconciled\\nonce we add to the dynamics a Fermi-Pasta-Ulam-Tsingou term.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cond-mat.stat-mech,cond-mat.soft,physics.bio-ph|hep-ph  |\n",
      "|http://arxiv.org/abs/2505.19666v1|Computation of statistical power and sample size for in vivo research\\n  models Sample size calculation is crucial in biomedical in vivo research\\ninvestigations mainly for two reasons: to design the most resource-efficient\\nstudies and to safeguard ethical issues when alive animals are subjects of\\ntesting. In this context, power analysis has been widely applied to compute the\\nsample size by predetermining the desired statistical power and the\\nsignificance level. To verify whether the assumption of a null hypothesis is\\ntrue, repeated measures analysis of variance (ANOVA) is used to test the\\ndifferences between multiple experimental groups and control group(s). In this\\narticle, we focus on the a priori power analysis, for testing multiple\\nparameters and calculating the power of experimental designs, which is suitable\\nto compute the sample size of trial groups in repeated measures ANOVA. We first\\ndescribe repeated measures ANOVA and the statistical power from a practical\\naspect of biomedical research. Furthermore, we apply the G*Power software to\\nconduct the a priori power analysis using examples of repeated measures ANOVA\\nwith three groups and five time points. We aim not to use the typical\\ntechnically adapted statistical language. This will enable experimentalists to\\nconfidently formulate power calculation and sample size calculation easier and\\nmore accurately.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |stat.AP                                        |stat.ME |\n",
      "|http://arxiv.org/abs/2505.19667v1|LeCoDe: A Benchmark Dataset for Interactive Legal Consultation Dialogue\\n  Evaluation Legal consultation is essential for safeguarding individual rights and\\nensuring access to justice, yet remains costly and inaccessible to many\\nindividuals due to the shortage of professionals. While recent advances in\\nLarge Language Models (LLMs) offer a promising path toward scalable, low-cost\\nlegal assistance, current systems fall short in handling the interactive and\\nknowledge-intensive nature of real-world consultations. To address these\\nchallenges, we introduce LeCoDe, a real-world multi-turn benchmark dataset\\ncomprising 3,696 legal consultation dialogues with 110,008 dialogue turns,\\ndesigned to evaluate and improve LLMs' legal consultation capability. With\\nLeCoDe, we innovatively collect live-streamed consultations from short-video\\nplatforms, providing authentic multi-turn legal consultation dialogues. The\\nrigorous annotation by legal experts further enhances the dataset with\\nprofessional insights and expertise. Furthermore, we propose a comprehensive\\nevaluation framework that assesses LLMs' consultation capabilities in terms of\\n(1) clarification capability and (2) professional advice quality. This unified\\nframework incorporates 12 metrics across two dimensions. Through extensive\\nexperiments on various general and domain-specific LLMs, our results reveal\\nsignificant challenges in this task, with even state-of-the-art models like\\nGPT-4 achieving only 39.8% recall for clarification and 59% overall score for\\nadvice quality, highlighting the complexity of professional consultation\\nscenarios. Based on these findings, we further explore several strategies to\\nenhance LLMs' legal consultation abilities. Our benchmark contributes to\\nadvancing research in legal domain dialogue systems, particularly in simulating\\nmore real-world user-expert interactions.                                                    |cs.CL,cs.AI,I.2.7                              |cs.CL   |\n",
      "|http://arxiv.org/abs/2505.19668v1|Burst Image Super-Resolution via Multi-Cross Attention Encoding and\\n  Multi-Scan State-Space Decoding Multi-image super-resolution (MISR) can achieve higher image quality than\\nsingle-image super-resolution (SISR) by aggregating sub-pixel information from\\nmultiple spatially shifted frames. Among MISR tasks, burst super-resolution\\n(BurstSR) has gained significant attention due to its wide range of\\napplications. Recent methods have increasingly adopted Transformers over\\nconvolutional neural networks (CNNs) in super-resolution tasks, due to their\\nsuperior ability to capture both local and global context. However, most\\nexisting approaches still rely on fixed and narrow attention windows that\\nrestrict the perception of features beyond the local field. This limitation\\nhampers alignment and feature aggregation, both of which are crucial for\\nhigh-quality super-resolution. To address these limitations, we propose a novel\\nfeature extractor that incorporates two newly designed attention mechanisms:\\noverlapping cross-window attention and cross-frame attention, enabling more\\nprecise and efficient extraction of sub-pixel information across multiple\\nframes. Furthermore, we introduce a Multi-scan State-Space Module with the\\ncross-frame attention mechanism to enhance feature aggregation. Extensive\\nexperiments on both synthetic and real-world benchmarks demonstrate the\\nsuperiority of our approach. Additional evaluations on ISO 12233 resolution\\ntest charts further confirm its enhanced super-resolution performance.                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CV                                          |cs.CV   |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-34-20.json\n",
      "\n",
      "========= 2025-05-29 21:34:30 =========\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+-----------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |true_label         |pred             |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+-----------------+\n",
      "|http://arxiv.org/abs/2505.19673v1|Magnon-Driven Phononic Frequency Comb in Linear Elastic Media Phononic frequency combs (PFCs) typically require nonlinear elastic media,\\nlimiting their frequency range and stability. Here, we propose a transformative\\napproach to generate PFCs in purely linear elastic media by harnessing the\\nmagnon nonlinearities, offering a new paradigm for frequency comb physics. By\\ntuning the magnon-phonon coupling confined in a magnetic disk of a vortex state\\ninto the strong coupling regime, we demonstrate an efficient nonlinearity\\ntransfer from magnons to phonons. This mechanism is able to produce GHz-range\\nPFCs with comb spacing set by the vortex core's gyration frequency. Full\\nmicromagnetic simulations verify our theoretical predictions, confirming robust\\ncomb formation at 3.5 GHz with 0.4 GHz spacing. This approach overcomes the\\nsub-MHz constraints of conventional PFCs, enabling applications in\\nhigh-precision metrology, nanoscale sensing, and quantum technologies. Our\\nfindings also deepen the understanding of the nonlinear dynamics in hybrid\\nmagnon-phonon systems and provide a versatile platform for exploring frequency\\ncombs in diverse physical systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |cond-mat.mes-hall  |cond-mat.mes-hall|\n",
      "|http://arxiv.org/abs/2505.19674v1|Comparing Moral Values in Western English-speaking societies and LLMs\\n  with Word Associations As the impact of large language models increases, understanding the moral\\nvalues they reflect becomes ever more important. Assessing the nature of moral\\nvalues as understood by these models via direct prompting is challenging due to\\npotential leakage of human norms into model training data, and their\\nsensitivity to prompt formulation. Instead, we propose to use word\\nassociations, which have been shown to reflect moral reasoning in humans, as\\nlow-level underlying representations to obtain a more robust picture of LLMs'\\nmoral reasoning. We study moral differences in associations from western\\nEnglish-speaking communities and LLMs trained predominantly on English data.\\nFirst, we create a large dataset of LLM-generated word associations, resembling\\nan existing data set of human word associations. Next, we propose a novel\\nmethod to propagate moral values based on seed words derived from Moral\\nFoundation Theory through the human and LLM-generated association graphs.\\nFinally, we compare the resulting moral conceptualizations, highlighting\\ndetailed but systematic differences between moral values emerging from English\\nspeakers and LLM associations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.CL              |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19675v1|Calibrating Pre-trained Language Classifiers on LLM-generated Noisy\\n  Labels via Iterative Refinement The traditional process of creating labeled datasets is labor-intensive and\\nexpensive. Recent breakthroughs in open-source large language models (LLMs)\\nhave opened up a new avenue in generating labeled datasets automatically for\\nvarious natural language processing (NLP) tasks, providing an alternative to\\nsuch an expensive annotation process. However, the reliability of such\\nauto-generated labels remains a significant concern due to inherent\\ninaccuracies. When learning from noisy labels, the model's generalization is\\nlikely to be harmed as it is prone to overfit to those label noises. While\\nprevious studies in learning from noisy labels mainly focus on synthetic noise\\nand real-world noise, LLM-generated label noise receives less attention. In\\nthis paper, we propose SiDyP: Simplex Label Diffusion with Dynamic Prior to\\ncalibrate the classifier's prediction, thus enhancing its robustness towards\\nLLM-generated noisy labels. SiDyP retrieves potential true label candidates by\\nneighborhood label distribution in text embedding space and iteratively refines\\nnoisy candidates using a simplex diffusion model. Our framework can increase\\nthe performance of the BERT classifier fine-tuned on both zero-shot and\\nfew-shot LLM-generated noisy label datasets by an average of 7.21% and 7.30%\\nrespectively. We demonstrate the effectiveness of SiDyP by conducting extensive\\nbenchmarking for different LLMs over a variety of NLP tasks. Our code is\\navailable on Github.                                                                                                                                                                                                                                                                 |cs.CL,cs.AI        |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19676v1|Large Language Models' Reasoning Stalls: An Investigation into the\\n  Capabilities of Frontier Models Empirical methods to examine the capability of Large Language Models (LLMs)\\nto use Automated Theorem Prover (ATP) reasoning strategies are studied. We\\nevaluate the performance of State of the Art models from December 2023 and\\nAugust 2024 on PRONTOQA steamroller reasoning problems. For that, we develop\\nmethods for assessing LLM response accuracy and correct answer correlation.\\n  Our results show that progress in improving LLM reasoning abilities has\\nstalled over the nine month period. By tracking completion tokens, we show that\\nalmost all improvement in reasoning ability since GPT-4 was released can be\\nattributed to either hidden system prompts or the training of models to\\nautomatically use generic Chain of Thought prompting strategies. Among the ATP\\nreasoning strategies tried, we found that current frontier LLMs are best able\\nto follow the bottom-up (also known as forward-chaining) strategy. A low\\npositive correlation was found between an LLM response containing correct\\nreasoning and arriving at the correct conclusion.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |cs.AI              |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19677v1|Perfect codes in quartic Cayley graphs of generalized dihedral groups For a graph $\\Gamma=(V\\Gamma,E\\Gamma)$, a subset $D$ of $V\\Gamma$ is a\\nperfect code in $\\Gamma$ if every vertex of $\\Gamma$ is dominated by exactly\\none vertex in $D$. In this paper, we classify all connected quartic Cayley\\ngraphs on generalized dihedral groups admitting a perfect code, and determine\\nall perfect codes in such graphs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |math.CO            |math.CO          |\n",
      "|http://arxiv.org/abs/2505.19678v1|Grounding Language with Vision: A Conditional Mutual Information\\n  Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs Large Vision-Language Models (LVLMs) are susceptible to hallucinations, where\\ngenerated responses seem semantically plausible yet exhibit little or no\\nrelevance to the input image. Previous studies reveal that this issue primarily\\nstems from LVLMs' over-reliance on language priors while disregarding the\\nvisual information during decoding. To alleviate this issue, we introduce a\\nnovel Conditional Pointwise Mutual Information (C-PMI) calibrated decoding\\nstrategy, which adaptively strengthens the mutual dependency between generated\\ntexts and input images to mitigate hallucinations. Unlike existing methods\\nsolely focusing on text token sampling, we propose to jointly model the\\ncontributions of visual and textual tokens to C-PMI, formulating hallucination\\nmitigation as a bi-level optimization problem aimed at maximizing mutual\\ninformation. To solve it, we design a token purification mechanism that\\ndynamically regulates the decoding process by sampling text tokens remaining\\nmaximally relevant to the given image, while simultaneously refining image\\ntokens most pertinent to the generated response. Extensive experiments across\\nvarious benchmarks reveal that the proposed method significantly reduces\\nhallucinations in LVLMs while preserving decoding efficiency.                                                                                                                                                                                                                                                                                                                                                                                                                                      |cs.CL,cs.CV        |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19679v1|KIT's Low-resource Speech Translation Systems for IWSLT2025: System\\n  Enhancement with Synthetic Data and Model Regularization This paper presents KIT's submissions to the IWSLT 2025 low-resource track.\\nWe develop both cascaded systems, consisting of Automatic Speech Recognition\\n(ASR) and Machine Translation (MT) models, and end-to-end (E2E) Speech\\nTranslation (ST) systems for three language pairs: Bemba, North Levantine\\nArabic, and Tunisian Arabic into English. Building upon pre-trained models, we\\nfine-tune our systems with different strategies to utilize resources\\nefficiently. This study further explores system enhancement with synthetic data\\nand model regularization. Specifically, we investigate MT-augmented ST by\\ngenerating translations from ASR data using MT models. For North Levantine,\\nwhich lacks parallel ST training data, a system trained solely on synthetic\\ndata slightly surpasses the cascaded system trained on real data. We also\\nexplore augmentation using text-to-speech models by generating synthetic speech\\nfrom MT data, demonstrating the benefits of synthetic data in improving both\\nASR and ST performance for Bemba. Additionally, we apply intra-distillation to\\nenhance model performance. Our experiments show that this approach consistently\\nimproves results across ASR, MT, and ST tasks, as well as across different\\npre-trained models. Finally, we apply Minimum Bayes Risk decoding to combine\\nthe cascaded and end-to-end systems, achieving an improvement of approximately\\n1.5 BLEU points.                                                                                                                                                                                                                                                                                                                   |cs.CL,cs.AI        |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19680v1|Cut out and Replay: A Simple yet Versatile Strategy for Multi-Label\\n  Online Continual Learning Multi-Label Online Continual Learning (MOCL) requires models to learn\\ncontinuously from endless multi-label data streams, facing complex challenges\\nincluding persistent catastrophic forgetting, potential missing labels, and\\nuncontrollable imbalanced class distributions. While existing MOCL methods\\nattempt to address these challenges through various techniques, \\textit{they\\nall overlook label-specific region identifying and feature learning} - a\\nfundamental solution rooted in multi-label learning but challenging to achieve\\nin the online setting with incremental and partial supervision. To this end, we\\nfirst leverage the inherent structural information of input data to evaluate\\nand verify the innate localization capability of different pre-trained models.\\nThen, we propose CUTER (CUT-out-and-Experience-Replay), a simple yet versatile\\nstrategy that provides fine-grained supervision signals by further identifying,\\nstrengthening and cutting out label-specific regions for efficient experience\\nreplay. It not only enables models to simultaneously address catastrophic\\nforgetting, missing labels, and class imbalance challenges, but also serves as\\nan orthogonal solution that seamlessly integrates with existing approaches.\\nExtensive experiments on multiple multi-label image benchmarks demonstrate the\\nsuperiority of our proposed method. The code is available at\\n\\href{https://github.com/wxr99/Cut-Replay}{https://github.com/wxr99/Cut-Replay}                                                                                                                                                                                                                                                                                      |cs.LG              |cs.CV            |\n",
      "|http://arxiv.org/abs/2505.19681v1|Coherent Control of Ion-Photoelectron Dynamics through Rabi\\n  Oscillations: An ab initio study We present first-principles numerical simulations of photoionization in neon\\ninduced by bichromatic extreme ultraviolet pulses with frequencies $\\omega$ and\\n$2\\omega$, specially chosen to make $\\omega$ equal to the energy difference\\nbetween the $2s$ and $2p$ subshells. This allows for the production of\\nphotoelectrons from the $2s$ shell by $2\\omega$ pulse and from the $2p$ shell\\nby $\\omega$ pulse with the same energy. Using the multi-configurational\\ntime-dependent Hartree-Fock method, we explore how Rabi coupling between\\nsubshells generates coherence between the corresponding photoelectron wave\\npackets. Our \\textit{ab initio} calculations confirm the analytical results\\nderived from the essential-states approach in [K. L. Ishikawa, K. C. Prince,\\nand K. Ueda, J. Phys. Chem. A 127, 10638 (2023)], validating the theoretical\\npredictions. Although we focus on the Ne $2p$ and $2s$ subshells, our approach\\nis applicable to a broad range of systems exhibiting photoionization from\\nmultiple subshells. The laser parameters employed in our simulations are\\navailable in modern Free Electron Lasers (FELs), and we anticipate that this\\nwork could stimulate experimental investigations using FELs to study\\nion-photoelectron coherence and entanglement.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |physics.atom-ph    |physics.atom-ph  |\n",
      "|http://arxiv.org/abs/2505.19682v1|Deep Actor-Critics with Tight Risk Certificates After a period of research, deep actor-critic algorithms have reached a level\\nwhere they influence our everyday lives. They serve as the driving force behind\\nthe continual improvement of large language models through user-collected\\nfeedback. However, their deployment in physical systems is not yet widely\\nadopted, mainly because no validation scheme that quantifies their risk of\\nmalfunction. We demonstrate that it is possible to develop tight risk\\ncertificates for deep actor-critic algorithms that predict generalization\\nperformance from validation-time observations. Our key insight centers on the\\neffectiveness of minimal evaluation data. Surprisingly, a small feasible of\\nevaluation roll-outs collected from a pretrained policy suffices to produce\\naccurate risk certificates when combined with a simple adaptation of PAC-Bayes\\ntheory. Specifically, we adopt a recently introduced recursive PAC-Bayes\\napproach, which splits validation data into portions and recursively builds\\nPAC-Bayes bounds on the excess loss of each portion's predictor, using the\\npredictor from the previous portion as a data-informed prior. Our empirical\\nresults across multiple locomotion tasks and policy expertise levels\\ndemonstrate risk certificates that are tight enough to be considered for\\npractical use.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.LG              |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19683v1|Large Language Models for Planning: A Comprehensive and Systematic\\n  Survey Planning represents a fundamental capability of intelligent agents, requiring\\ncomprehensive environmental understanding, rigorous logical reasoning, and\\neffective sequential decision-making. While Large Language Models (LLMs) have\\ndemonstrated remarkable performance on certain planning tasks, their broader\\napplication in this domain warrants systematic investigation. This paper\\npresents a comprehensive review of LLM-based planning. Specifically, this\\nsurvey is structured as follows: First, we establish the theoretical\\nfoundations by introducing essential definitions and categories about automated\\nplanning. Next, we provide a detailed taxonomy and analysis of contemporary\\nLLM-based planning methodologies, categorizing them into three principal\\napproaches: 1) External Module Augmented Methods that combine LLMs with\\nadditional components for planning, 2) Finetuning-based Methods that involve\\nusing trajectory data and feedback signals to adjust LLMs in order to improve\\ntheir planning abilities, and 3) Searching-based Methods that break down\\ncomplex tasks into simpler components, navigate the planning space, or enhance\\ndecoding strategies to find the best solutions. Subsequently, we systematically\\nsummarize existing evaluation frameworks, including benchmark datasets,\\nevaluation metrics and performance comparisons between representative planning\\nmethods. Finally, we discuss the underlying mechanisms enabling LLM-based\\nplanning and outline promising research directions for this rapidly evolving\\nfield. We hope this survey will serve as a valuable resource to inspire\\ninnovation and drive progress in this field.                                                                                                                  |cs.AI,cs.CL        |cs.AI            |\n",
      "|http://arxiv.org/abs/2505.19684v1|VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal\\n  Large Language Models The emergence of Multimodal Large Language Models (MLRMs) has enabled\\nsophisticated visual reasoning capabilities by integrating reinforcement\\nlearning and Chain-of-Thought (CoT) supervision. However, while these enhanced\\nreasoning capabilities improve performance, they also introduce new and\\nunderexplored safety risks. In this work, we systematically investigate the\\nsecurity implications of advanced visual reasoning in MLRMs. Our analysis\\nreveals a fundamental trade-off: as visual reasoning improves, models become\\nmore vulnerable to jailbreak attacks. Motivated by this critical finding, we\\nintroduce VisCRA (Visual Chain Reasoning Attack), a novel jailbreak framework\\nthat exploits the visual reasoning chains to bypass safety mechanisms. VisCRA\\ncombines targeted visual attention masking with a two-stage reasoning induction\\nstrategy to precisely control harmful outputs. Extensive experiments\\ndemonstrate VisCRA's significant effectiveness, achieving high attack success\\nrates on leading closed-source MLRMs: 76.48% on Gemini 2.0 Flash Thinking,\\n68.56% on QvQ-Max, and 56.60% on GPT-4o. Our findings highlight a critical\\ninsight: the very capability that empowers MLRMs -- their visual reasoning --\\ncan also serve as an attack vector, posing significant security risks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |cs.CV              |cs.CR            |\n",
      "|http://arxiv.org/abs/2505.19685v1|Graph Guided Diffusion: Unified Guidance for Conditional Graph\\n  Generation Diffusion models have emerged as powerful generative models for graph\\ngeneration, yet their use for conditional graph generation remains a\\nfundamental challenge. In particular, guiding diffusion models on graphs under\\narbitrary reward signals is difficult: gradient-based methods, while powerful,\\nare often unsuitable due to the discrete and combinatorial nature of graphs,\\nand non-differentiable rewards further complicate gradient-based guidance. We\\npropose Graph Guided Diffusion (GGDiff), a novel guidance framework that\\ninterprets conditional diffusion on graphs as a stochastic control problem to\\naddress this challenge. GGDiff unifies multiple guidance strategies, including\\ngradient-based guidance (for differentiable rewards), control-based guidance\\n(using control signals from forward reward evaluations), and zero-order\\napproximations (bridging gradient-based and gradient-free optimization). This\\ncomprehensive, plug-and-play framework enables zero-shot guidance of\\npre-trained diffusion models under both differentiable and non-differentiable\\nreward functions, adapting well-established guidance techniques to graph\\ngeneration--a direction largely unexplored. Our formulation balances\\ncomputational efficiency, reward alignment, and sample quality, enabling\\npractical conditional generation across diverse reward types. We demonstrate\\nthe efficacy of GGDiff in various tasks, including constraints on graph motifs,\\nfairness, and link prediction, achieving superior alignment with target rewards\\nwhile maintaining diversity and fidelity.                                                                                                                                                                                                    |cs.LG              |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19686v1|Symmetry-broken charge-ordered ground state in CsV$_3$Sb$_5$ Kagome\\n  metal The newly discovered family of non-magnetic Kagome metals AV$_3$Sb$_5$\\n(A=K,Rb,Cs) offers a unique platform for studying the interplay between a\\ncharge density wave transition with superconductivity, non-trivial topology,\\nand spontaneous time-reversal symmetry.Despite characterizing the charge\\ndensity wave phase is crucial to understand and model all these exotic\\nproperties, it remains unresolved. In this work, we use first-principles\\ncalculations of the free-energy, incorporating both ionic kinetic energy and\\nanharmonic effects, to resolve the atomistic phase diagram of CsV$_3$Sb$_5$ and\\nits charge ordering structure. Our results reveal a competition between\\nmetastable stacking orders of the reconstructed vanadium Kagome layers, which\\nare energetically favored to form exclusively a triangular-hexagonal\\narrangement, allowing the possibility of competitive different domains and\\nchiral order. Consistent with experimental observations, we find that the\\n$2\\times2\\times2$ and $2\\times2\\times4$ modulations are nearly degenerate in\\nfree energy, and are abruptly melted into the high-symmetry hexagonal phase\\naround 90 K. The transition is first-order but compatible with a measurable\\nphonon-softening. Remarkably, even if the six-fold and inversion symmetry are\\nintrinsically broken by the out-of-plane stacking, this does not lead to\\nmeasurable anisotropy in the in-plane conductivity as suggested by\\nmeasurements.                                                                                                                                                                                                                                                                                                                                  |cond-mat.mtrl-sci  |cond-mat.str-el  |\n",
      "|http://arxiv.org/abs/2505.19687v1|DiEmo-TTS: Disentangled Emotion Representations via Self-Supervised\\n  Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech Cross-speaker emotion transfer in speech synthesis relies on extracting\\nspeaker-independent emotion embeddings for accurate emotion modeling without\\nretaining speaker traits. However, existing timbre compression methods fail to\\nfully separate speaker and emotion characteristics, causing speaker leakage and\\ndegraded synthesis quality. To address this, we propose DiEmo-TTS, a\\nself-supervised distillation method to minimize emotional information loss and\\npreserve speaker identity. We introduce cluster-driven sampling and information\\nperturbation to preserve emotion while removing irrelevant factors. To\\nfacilitate this process, we propose an emotion clustering and matching approach\\nusing emotional attribute prediction and speaker embeddings, enabling\\ngeneralization to unlabeled data. Additionally, we designed a dual conditioning\\ntransformer to integrate style features better. Experimental results confirm\\nthe effectiveness of our method in learning speaker-irrelevant emotion\\nembeddings.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |cs.SD,cs.AI,eess.AS|cs.SD            |\n",
      "|http://arxiv.org/abs/2505.19688v1|GeoPF: Infusing Geometry into Potential Fields for Reactive Planning in\\n  Non-trivial Environments Reactive intelligence remains one of the cornerstones of versatile robotics\\noperating in cluttered, dynamic, and human-centred environments. Among reactive\\napproaches, potential fields (PF) continue to be widely adopted due to their\\nsimplicity and real-time applicability. However, existing PF methods typically\\noversimplify environmental representations by relying on isotropic, point- or\\nsphere-based obstacle approximations. In human-centred settings, this\\nsimplification results in overly conservative paths, cumbersome tuning, and\\ncomputational overhead -- even breaking real-time requirements. In response, we\\npropose the Geometric Potential Field (GeoPF), a reactive motion-planning\\nframework that explicitly infuses geometric primitives - points, lines, planes,\\ncubes, and cylinders - into real-time planning. By leveraging precise\\nclosed-form distance functions, GeoPF significantly reduces computational\\ncomplexity and parameter tuning effort. Extensive quantitative analyses\\nconsistently show GeoPF's higher success rates, reduced tuning complexity (a\\nsingle parameter set across experiments), and substantially lower computational\\ncosts (up to 2 orders of magnitude) compared to traditional PF methods.\\nReal-world experiments further validate GeoPF's robustness and practical ease\\nof deployment. GeoPF provides a fresh perspective on reactive planning problems\\ndriving geometric-aware temporal motion generation, enabling flexible and\\nlow-latency motion planning suitable for modern robotic applications.                                                                                                                                                                                                               |cs.RO              |cs.RO            |\n",
      "|http://arxiv.org/abs/2505.19689v1|Transforming jet flavour tagging at ATLAS Jet flavour tagging enables the identification of jets originating from\\nheavy-flavour quarks in proton-proton collisions at the Large Hadron Collider,\\nplaying a critical role in its physics programmes. This paper presents GN2, a\\nnovel transformer-based flavour tagging algorithm deployed by the ATLAS\\nCollaboration that represents a paradigm shift from previous approaches.\\nDesigned to classify jets based on the flavour of their constituent particles,\\nGN2 processes low-level tracking information in an end-to-end architecture and\\nincorporates physics-informed auxiliary training objectives to enhance both\\ninterpretability and performance. Its performance is validated in both\\nsimulation and collision data. The GN2 algorithm provides substantial benefits\\nfor physics analyses involving heavy-flavour jets, such as measurements of\\nHiggs boson pair production and the couplings of bottom and charm quarks to the\\nHiggs boson, and demonstrates the impact of advanced machine learning methods\\nin experimental particle physics.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |hep-ex             |hep-ph           |\n",
      "|http://arxiv.org/abs/2505.19690v1|Beyond Safe Answers: A Benchmark for Evaluating True Risk Awareness in\\n  Large Reasoning Models Despite the remarkable proficiency of \\textit{Large Reasoning Models} (LRMs)\\nin handling complex reasoning tasks, their reliability in safety-critical\\nscenarios remains uncertain. Existing evaluations primarily assess\\nresponse-level safety, neglecting a critical issue we identify as\\n\\textbf{\\textit{Superficial Safety Alignment} (SSA)} -- a phenomenon where\\nmodels produce superficially safe outputs while internal reasoning processes\\nfail to genuinely detect and mitigate underlying risks, resulting in\\ninconsistent safety behaviors across multiple sampling attempts. To\\nsystematically investigate SSA, we introduce \\textbf{Beyond Safe Answers (BSA)}\\nbench, a novel benchmark comprising 2,000 challenging instances organized into\\nthree distinct SSA scenario types and spanning nine risk categories, each\\nmeticulously annotated with risk rationales. Evaluations of 19 state-of-the-art\\nLRMs demonstrate the difficulty of this benchmark, with top-performing models\\nachieving only 38.0\\% accuracy in correctly identifying risk rationales. We\\nfurther explore the efficacy of safety rules, specialized fine-tuning on safety\\nreasoning data, and diverse decoding strategies in mitigating SSA. Our work\\nprovides a comprehensive assessment tool for evaluating and improving safety\\nreasoning fidelity in LRMs, advancing the development of genuinely risk-aware\\nand reliably safe AI systems.                                                                                                                                                                                                                                                                                                                                                           |cs.AI              |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19691v1|Alternative Derivations of Hawking Radiation Since the original derivation of Hawking radiation, there have been lots of\\nalternative approaches to show the same fact that black holes emit particles as\\nhot bodies with a temperature. These alternative methods generally rely on\\ndifferent conditions and physical quantities to manifest the radiation,\\nproviding various points of view of this effect in the intersection of gravity\\nand quantum theory. This chapter presents some alternative derivations of\\nHawking radiation in the literature, including the tunneling, anomaly and\\nGreen's function methods. From these methods, various features of the black\\nhole system can be seen, such as the gravitational and trace anomalies of the\\n$(1+1)$-dimensional effective theory and the analytical continuation of the\\ncomplexified spacetime.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |gr-qc              |gr-qc            |\n",
      "|http://arxiv.org/abs/2505.19692v1|DriveCamSim: Generalizable Camera Simulation via Explicit Camera\\n  Modeling for Autonomous Driving Camera sensor simulation serves as a critical role for autonomous driving\\n(AD), e.g. evaluating vision-based AD algorithms. While existing approaches\\nhave leveraged generative models for controllable image/video generation, they\\nremain constrained to generating multi-view video sequences with fixed camera\\nviewpoints and video frequency, significantly limiting their downstream\\napplications. To address this, we present a generalizable camera simulation\\nframework DriveCamSim, whose core innovation lies in the proposed Explicit\\nCamera Modeling (ECM) mechanism. Instead of implicit interaction through\\nvanilla attention, ECM establishes explicit pixel-wise correspondences across\\nmulti-view and multi-frame dimensions, decoupling the model from overfitting to\\nthe specific camera configurations (intrinsic/extrinsic parameters, number of\\nviews) and temporal sampling rates presented in the training data. For\\ncontrollable generation, we identify the issue of information loss inherent in\\nexisting conditional encoding and injection pipelines, proposing an\\ninformation-preserving control mechanism. This control mechanism not only\\nimproves conditional controllability, but also can be extended to be\\nidentity-aware to enhance temporal consistency in foreground object rendering.\\nWith above designs, our model demonstrates superior performance in both visual\\nquality and controllability, as well as generalization capability across\\nspatial-level (camera parameters variations) and temporal-level (video frame\\nrate variations), enabling flexible user-customizable camera simulation\\ntailored to diverse application scenarios. Code will be avaliable at\\nhttps://github.com/swc-17/DriveCamSim for facilitating future research.|cs.CV              |cs.CV            |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-34-30.json\n",
      "\n",
      "========= 2025-05-29 21:34:40 =========\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |true_label                   |pred   |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-------+\n",
      "|http://arxiv.org/abs/2505.19697v1|Study of $p_\\mathrm{T}$-differential radial flow in blast-wave model The transverse momentum-differential radial flow observable\\n$v_0(p_\\mathrm{T})$, recently proposed and measured by the ATLAS and ALICE\\ncollaborations, provides a novel tool to probe radial expansion dynamics in\\nhigh-energy heavy-ion collisions. In this work, we conduct a detailed study of\\n$v_0(p_\\mathrm{T})$ using a blast-wave model that incorporates\\nhydrodynamic-like expansion and thermal emission. We introduce event-by-event\\nfluctuations in the transverse expansion velocity and kinetic freeze-out\\ntemperature using Gaussian probability distributions. Our results show that\\nincreasing the mean expansion velocity leads to a clear mass ordering in\\n$v_0(p_\\mathrm{T})$, while fluctuations in both expansion velocity and\\nfreeze-out temperature significantly enhance the magnitude of\\n$v_0(p_\\mathrm{T})$, particularly at higher $p_\\mathrm{T}$. We fit blast-wave\\nmodel calculations for identified hadrons ($\\pi$, K, and p) to recent ALICE\\ndata from Pb--Pb collisions at $\\sqrt{s_\\mathrm{NN}}$ = 5.02 TeV using a\\nBayesian parameter estimation framework. The extracted mean transverse\\nexpansion velocity decreases, while the kinetic freeze-out temperature\\nincreases, from central to peripheral collisions. Additionally, the freeze-out\\ntemperatures inferred from $v_0(p_\\mathrm{T})$ are systematically higher than\\nthose obtained from conventional $p_\\mathrm{T}$-spectra fits, likely due to the\\nreduced sensitivity of $v_0(p_\\mathrm{T})$ to resonance decay contributions.                                                                                                                                                                                                                                                                                                                        |nucl-ex,hep-ex,hep-ph,nucl-th|nucl-th|\n",
      "|http://arxiv.org/abs/2505.19698v1|JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance\\n  Asymmetry in Model-Based Reinforcement Learning Recent advances in model-based reinforcement learning (MBRL) have achieved\\nsuper-human level performance on the Atari100k benchmark, driven by\\nreinforcement learning agents trained on powerful diffusion world models.\\nHowever, we identify that the current aggregates mask a major performance\\nasymmetry: MBRL agents dramatically outperform humans in some tasks despite\\ndrastically underperforming in others, with the former inflating the aggregate\\nmetrics. This is especially pronounced in pixel-based agents trained with\\ndiffusion world models. In this work, we address the pronounced asymmetry\\nobserved in pixel-based agents as an initial attempt to reverse the worrying\\nupward trend observed in them. We address the problematic aggregates by\\ndelineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal\\nimportance on metrics from both sets. Next, we hypothesize this pronounced\\nasymmetry is due to the lack of temporally-structured latent space trained with\\nthe World Model objective in pixel-based methods. Lastly, to address this\\nissue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion\\nworld model trained end-to-end with the self-consistency objective. JEDI\\noutperforms SOTA models in human-optimal tasks while staying competitive across\\nthe Atari100k benchmark, and runs 3 times faster with 43% lower memory than the\\nlatest pixel-based diffusion baseline. Overall, our work rethinks what it truly\\nmeans to cross human-level performance in Atari100k.                                                                                                                                                                                                                                             |cs.LG,cs.AI,cs.RO            |cs.LG  |\n",
      "|http://arxiv.org/abs/2505.19699v1|Mosaic: Data-Free Knowledge Distillation via Mixture-of-Experts for\\n  Heterogeneous Distributed Environments Federated Learning (FL) is a decentralized machine learning paradigm that\\nenables clients to collaboratively train models while preserving data privacy.\\nHowever, the coexistence of model and data heterogeneity gives rise to\\ninconsistent representations and divergent optimization dynamics across\\nclients, ultimately hindering robust global performance. To transcend these\\nchallenges, we propose Mosaic, a novel data-free knowledge distillation\\nframework tailored for heterogeneous distributed environments. Mosaic first\\ntrains local generative models to approximate each client's personalized\\ndistribution, enabling synthetic data generation that safeguards privacy\\nthrough strict separation from real data. Subsequently, Mosaic forms a\\nMixture-of-Experts (MoE) from client models based on their specialized\\nknowledge, and distills it into a global model using the generated data. To\\nfurther enhance the MoE architecture, Mosaic integrates expert predictions via\\na lightweight meta model trained on a few representative prototypes. Extensive\\nexperiments on standard image classification benchmarks demonstrate that Mosaic\\nconsistently outperforms state-of-the-art approaches under both model and data\\nheterogeneity. The source code has been published at\\nhttps://github.com/Wings-Of-Disaster/Mosaic.                                                                                                                                                                                                                                                                                                                                                                                                                                                           |cs.LG,cs.AI,cs.DC            |cs.LG  |\n",
      "|http://arxiv.org/abs/2505.19700v1|Leveraging Importance Sampling to Detach Alignment Modules from Large\\n  Language Models The widespread adoption of large language models (LLMs) across industries has\\nincreased the demand for high-quality and customizable outputs. However,\\ntraditional alignment methods often require retraining large pretrained models,\\nmaking it difficult to quickly adapt and optimize LLMs for diverse\\napplications. To address this limitation, we propose a novel \\textit{Residual\\nAlignment Model} (\\textit{RAM}) that formalizes the alignment process as a type\\nof importance sampling. In this framework, the unaligned upstream model serves\\nas the proposal distribution, while the alignment process is framed as\\nsecondary sampling based on an autoregressive alignment module that acts as an\\nestimator of the importance weights. This design enables a natural detachment\\nof the alignment module from the target aligned model, improving flexibility\\nand scalability. Based on this model, we derive an efficient sequence-level\\ntraining strategy for the alignment module, which operates independently of the\\nproposal module. Additionally, we develop a resampling algorithm with iterative\\ntoken-level decoding to address the common first-token latency issue in\\ncomparable methods. Experimental evaluations on two leading open-source LLMs\\nacross diverse tasks, including instruction following, domain adaptation, and\\npreference optimization, demonstrate that our approach consistently outperforms\\nbaseline models.                                                                                                                                                                                                                                                                                                                                                                          |cs.CL,cs.AI                  |cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19701v1|Accurate Radar-Based Detection of Sleep Apnea Using Overlapping\\n  Time-Interval Averaging Radar-based respiratory measurement is a promising tool for the noncontact\\ndetection of sleep apnea. Our team has reported that apnea events can be\\naccurately detected using the statistical characteristics of the amplitude of\\nrespiratory displacement. However, apnea and hypopnea events are often followed\\nby irregular breathing, reducing the detection accuracy. This study proposes a\\nnew method to overcome this performance degradation by repeatedly applying the\\ndetection method to radar data sets corresponding to multiple overlapping time\\nintervals. Averaging the detected classes over multiple time intervals gives an\\nanalog value between 0 and 1, which can be interpreted as the probability that\\nthere is an apnea event. We show that the proposed method can mitigate the\\neffect of irregular breathing that occurs after apnea / hypopnea events, and\\nits performance is confirmed by experimental data taken from seven patients.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |eess.SP                      |eess.SP|\n",
      "|http://arxiv.org/abs/2505.19702v1|Point-RFT: Improving Multimodal Reasoning with Visually Grounded\\n  Reinforcement Finetuning Recent advances in large language models have significantly improved textual\\nreasoning through the effective use of Chain-of-Thought (CoT) and reinforcement\\nlearning. However, extending these successes to vision-language tasks remains\\nchallenging due to inherent limitations in text-only CoT, such as visual\\nhallucinations and insufficient multimodal integration. In this paper, we\\nintroduce Point-RFT, a multimodal reasoning framework explicitly designed to\\nleverage visually grounded CoT reasoning for visual document understanding. Our\\napproach consists of two stages: First, we conduct format finetuning using a\\ncurated dataset of 71K diverse visual reasoning problems, each annotated with\\ndetailed, step-by-step rationales explicitly grounded to corresponding visual\\nelements. Second, we employ reinforcement finetuning targeting visual document\\nunderstanding. On ChartQA, our approach improves accuracy from 70.88%\\n(format-finetuned baseline) to 90.04%, surpassing the 83.92% accuracy achieved\\nby reinforcement finetuning relying solely on text-based CoT. The result shows\\nthat our grounded CoT is more effective for multimodal reasoning compared with\\nthe text-only CoT. Moreover, Point-RFT exhibits superior generalization\\ncapability across several out-of-domain visual document reasoning benchmarks,\\nincluding CharXiv, PlotQA, IconQA, TabMWP, etc., and highlights its potential\\nin complex real-world scenarios.                                                                                                                                                                                                                                                                                                                                                   |cs.CV                        |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19703v1|Model Predictive Online Monitoring of Dynamical Systems for Nested\\n  Signal Temporal Logic Specifications This paper investigates the online monitoring problem for cyber-physical\\nsystems under signal temporal logic (STL) specifications. The objective is to\\ndesign an online monitor that evaluates system correctness at runtime based on\\npartial signal observations up to the current time so that alarms can be issued\\nwhenever the specification is violated or will inevitably be violated in the\\nfuture. We consider a model-predictive setting where the system's dynamic model\\nis available and can be leveraged to enhance monitoring accuracy. However,\\nexisting approaches are limited to a restricted class of STL formulae,\\npermitting only a single application of temporal operators. This work addresses\\nthe challenge of nested temporal operators in the design of model-predictive\\nmonitors. Our method utilizes syntax tree structures to resolve dependencies\\nbetween temporal operators and introduces the concept of basic satisfaction\\nvectors. A new model-predictive monitoring algorithm is proposed by recursively\\nupdating these vectors online while incorporating pre-computed satisfaction\\nregions derived from offline model analysis. We prove that the proposed\\napproach is both sound and complete, ensuring no false alarms or missed alarms.\\nCase studies are provided to demonstrate the effectiveness of our method.                                                                                                                                                                                                                                                                                                                                                                                                                                                         |math.OC                      |eess.SY|\n",
      "|http://arxiv.org/abs/2505.19704v1|Existence results for Tzitz√©ica equation via topological degree method\\n  on graphs We derive some existence results for the solutions of the Tzitz\\'eica\\nequation\\n  \\begin{equation*}\\n  -\\Delta u + h_1(x)e^{Au} + h_2(x)e^{-Bu}=0\\n  \\end{equation*}\\n  and the generalized Tzitz\\'eica equation\\n  \\begin{equation*}\\n  -\\Delta u + h_1(x)e^{Au}(e^{Au}-1)+h_2(x)e^{-Bu}(e^{-Bu}-1)=0\\n  \\end{equation*}\\n  on any connected finite graph \\(G=(V, E)\\). Here, \\(h_1(x)>0\\), \\(h_2(x)>0\\)\\nare two given functions on \\(V\\), and \\(A, B>0\\) are two constants. Our\\napproach involves computing the topological degree and using the connection\\nbetween the degree and the critical group of an associated functional.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |math.AP                      |math.AP|\n",
      "|http://arxiv.org/abs/2505.19705v1|Efficient globalization of heavy-ball type methods for unconstrained\\n  optimization based on curve searches In this work, we deal with unconstrained nonlinear optimization problems.\\nSpecifically, we are interested in methods carrying out updates possibly along\\ndirections not of descent, like Polyak's heavy-ball algorithm. Instead of\\nenforcing convergence properties through line searches and modifications of\\nsearch direction when suitable safeguards are not satisfied, we propose a\\nstrategy based on searches along curve paths: a curve search starting from the\\nfirst tentative update allows to smoothly revert towards a gradient-related\\ndirection if a sufficient decrease condition is not met. The resulting\\nalgorithm provably possesses global convergence guarantees, even with a\\nnonmonotone decrease condition. While the presented framework is rather\\ngeneral, particularly of interest is the case of parabolic searches; in this\\ncase, under reasonable assumptions, the resulting algorithm can be shown to\\npossess optimal worst case complexity bounds for reaching approximate\\nstationarity in nonconvex settings. Practically, we show that the proposed\\nglobalization strategy allows to consistently accept (optimal) pure heavy-ball\\nsteps in the strongly convex case, while standard globalization approaches\\nwould at times negate them before even evaluating the objective function.\\nPreliminary computational experiments also suggest that the proposed framework\\nmight be more convenient than classical safeguard based approaches.                                                                                                                                                                                                                                                                                                                                  |math.OC                      |math.OC|\n",
      "|http://arxiv.org/abs/2505.19706v1|Error Typing for Smarter Rewards: Improving Process Reward Models with\\n  Error-Aware Hierarchical Supervision Large Language Models (LLMs) are prone to hallucination, especially during\\nmulti-hop and reasoning-intensive tasks such as mathematical problem solving.\\nWhile Outcome Reward Models verify only final answers, Process Reward Models\\n(PRMs) score each intermediate step to steer generation toward coherent\\nsolutions. We introduce PathFinder-PRM, a novel hierarchical, error-aware\\ndiscriminative PRM that first classifies math and consistency errors at each\\nstep, then combines these fine-grained signals to estimate step correctness. To\\ntrain PathFinder-PRM, we construct a 400K-sample dataset by enriching the\\nhuman-annotated PRM800K corpus and RLHFlow Mistral traces with\\nthree-dimensional step-level labels. On PRMBench, PathFinder-PRM achieves a new\\nstate-of-the-art PRMScore of 67.7, outperforming the prior best (65.5) while\\nusing 3 times less data. When applied to reward guided greedy search, our model\\nyields prm@8 48.3, a +1.5 point gain over the strongest baseline. These results\\ndemonstrate that decoupled error detection and reward estimation not only boost\\nfine-grained error detection but also substantially improve end-to-end,\\nreward-guided mathematical reasoning with greater data efficiency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |cs.CL,cs.AI                  |cs.CL  |\n",
      "|http://arxiv.org/abs/2505.19707v1|MLLM-Guided VLM Fine-Tuning with Joint Inference for Zero-Shot Composed\\n  Image Retrieval Existing Zero-Shot Composed Image Retrieval (ZS-CIR) methods typically train\\nadapters that convert reference images into pseudo-text tokens, which are\\nconcatenated with the modifying text and processed by frozen text encoders in\\npretrained VLMs or LLMs. While this design leverages the strengths of large\\npretrained models, it only supervises the adapter to produce encoder-compatible\\ntokens that loosely preserve visual semantics. Crucially, it does not directly\\noptimize the composed query representation to capture the full intent of the\\ncomposition or to align with the target semantics, thereby limiting retrieval\\nperformance, particularly in cases involving fine-grained or complex visual\\ntransformations. To address this problem, we propose MLLM-Guided VLM\\nFine-Tuning with Joint Inference (MVFT-JI), a novel approach that leverages a\\npretrained multimodal large language model (MLLM) to construct two\\ncomplementary training tasks using only unlabeled images: target text retrieval\\ntaskand text-to-image retrieval task. By jointly optimizing these tasks, our\\nmethod enables the VLM to inherently acquire robust compositional retrieval\\ncapabilities, supported by the provided theoretical justifications and\\nempirical validation. Furthermore, during inference, we further prompt the MLLM\\nto generate target texts from composed queries and compute retrieval scores by\\nintegrating similarities between (i) the composed query and candidate images,\\nand (ii) the MLLM-generated target text and candidate images. This strategy\\neffectively combines the VLM's semantic alignment strengths with the MLLM's\\nreasoning capabilities.                                                                                                                                   |cs.CV,cs.IR                  |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19708v1|Private MEV Protection RPCs: Benchmark Stud Decentralized Finance (DeFi) on Ethereum has undergone significant\\ntransformations since its emergence during the DeFi summer of 2020. With the\\nintroduction of Proof of Stake (PoS) and Proposer-Builder Separation (PBS), the\\ntransaction supply chain on Ethereum has shifted from relying entirely on the\\npublic mempool for DeFi interactions to an astonishing 80% usage of private\\nRPCs. These private RPCs submit transactions directly to builders, skipping the\\npublic mempool, while conducting Order Flow Auctions (OFAs) to capture MEV\\nbackrun rebates and gas rebates. Our findings reveal that not all RPCs OFAs\\nproduce the same outcomes. These insights underscore the significant\\nimplications of OFA design choices on transaction efficiency and execution\\nquality, and thus why an order flow originators should pay close attention to\\nwhich OFA they use.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |econ.GN,q-fin.EC             |cs.CR  |\n",
      "|http://arxiv.org/abs/2505.19709v1|Capacity-Optimized Pre-Equalizer Design for Visible Light Communication\\n  Systems Since commercial LEDs are primarily designed for illumination rather than\\ndata transmission, their modulation bandwidth is inherently limited to a few\\nMHz. This becomes a major bottleneck in the implementation of visible light\\ncommunication (VLC) systems necessiating the design of pre-equalizers. While\\nstate-of-the-art equalizer designs primarily focus on the data rate increasing\\nthrough bandwidth expansion, they often overlook the accompanying degradation\\nin signal-to-noise ratio (SNR). Achieving effective bandwidth extension without\\nintroducing excessive SNR penalties remains a significant challenge, since the\\nchannel capacity is a non-linear function of both parameters. In this paper, we\\npresent a fundamental analysis of how the parameters of the LED and\\npre-equalization circuits influence the channel capacity in intensity\\nmodulation and direct detection (IMDD)-based VLC systems. We derive a\\nclosed-form expression for channel capacity model that is an explicitly\\nfunction of analog pre-equalizer circuit parameters. Building upon the derived\\ncapacity expression, we propose a systematic design methodology for analog\\npre-equalizers that effectively balances bandwidth and SNR, thereby maximizing\\nthe overall channel capacity across a wide range of channel attenuations. We\\npresent extensive numerical results to validate the effectiveness of the\\nproposed design and demonstrate the improvements over conventional\\nbandwidth-optimized pre-equalizer designs.                                                                                                                                                                                                                                                                                                      |cs.IT,eess.SP,math.IT        |eess.SP|\n",
      "|http://arxiv.org/abs/2505.19710v1|Forward and inverse problems for a finite Krein-Stieltjes string.\\n  Approximation of constant density by point masses We consider a dynamic inverse problem for a dynamical system which describes\\nthe propagation of waves in a Krein string. The problem is reduced to an\\nintegral equation and an important special case is considered when the string\\ndensity is determined by a finite number of point masses distributed over the\\ninterval. We derive an equation of Krein type, with the help of which the\\nstring density is restored. We also consider the approximation of constant\\ndensity by point masses uniformly distributed over the interval and the effect\\nof the appearance of a finite wave propagation velocity in the dynamical\\nsystem.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |math.AP,math.SP              |math.NA|\n",
      "|http://arxiv.org/abs/2505.19711v1|Dynamical inverse problem for the discrete Schr√∂dinger operator We consider the inverse problem for the dynamical system with discrete\\nSchr\\\"odinger operator and discrete time. As an inverse data we take a\\n\\emph{response operator}, the natural analog of the dynamical\\nDirichlet-to-Neumann map. We derive two types of equations of inverse problem\\nand answer a question on the characterization of the inverse data, i.e. we\\ndescribe the set of operators, which are \\emph{response operators} of the\\ndynamical system governed by the discrete Schr\\\"odinger operator.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |math.AP,math.SP              |math.AP|\n",
      "|http://arxiv.org/abs/2505.19712v1|On the Relation between Rectified Flows and Optimal Transport This paper investigates the connections between rectified flows, flow\\nmatching, and optimal transport. Flow matching is a recent approach to learning\\ngenerative models by estimating velocity fields that guide transformations from\\na source to a target distribution. Rectified flow matching aims to straighten\\nthe learned transport paths, yielding more direct flows between distributions.\\nOur first contribution is a set of invariance properties of rectified flows and\\nexplicit velocity fields. In addition, we also provide explicit constructions\\nand analysis in the Gaussian (not necessarily independent) and Gaussian mixture\\nsettings and study the relation to optimal transport. Our second contribution\\naddresses recent claims suggesting that rectified flows, when constrained such\\nthat the learned velocity field is a gradient, can yield (asymptotically)\\nsolutions to optimal transport problems. We study the existence of solutions\\nfor this problem and demonstrate that they only relate to optimal transport\\nunder assumptions that are significantly stronger than those previously\\nacknowledged. In particular, we present several counter-examples that\\ninvalidate earlier equivalence results in the literature, and we argue that\\nenforcing a gradient constraint on rectified flows is, in general, not a\\nreliable method for computing optimal transport maps.                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.LG,math.PR,stat.ML        |cs.LG  |\n",
      "|http://arxiv.org/abs/2505.19713v1|CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric\\n  Reward In this work, we introduce CAD-Coder, a novel framework that reformulates\\ntext-to-CAD as the generation of CadQuery scripts - a Python-based, parametric\\nCAD language. This representation enables direct geometric validation, a richer\\nmodeling vocabulary, and seamless integration with existing LLMs. To further\\nenhance code validity and geometric fidelity, we propose a two-stage learning\\npipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2)\\nreinforcement learning with Group Reward Policy Optimization (GRPO), guided by\\na CAD-specific reward comprising both a geometric reward (Chamfer Distance) and\\na format reward. We also introduce a chain-of-thought (CoT) planning process to\\nimprove model reasoning, and construct a large-scale, high-quality dataset of\\n110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automated\\npipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs to\\ngenerate diverse, valid, and complex CAD models directly from natural language,\\nadvancing the state of the art of text-to-CAD generation and geometric\\nreasoning.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |cs.GR                        |cs.LG  |\n",
      "|http://arxiv.org/abs/2505.19714v1|MT$^{3}$: Scaling MLLM-based Text Image Machine Translation via\\n  Multi-Task Reinforcement Learning Text Image Machine Translation (TIMT)-the task of translating textual content\\nembedded in images-is critical for applications in accessibility, cross-lingual\\ninformation access, and real-world document understanding. However, TIMT\\nremains a complex challenge due to the need for accurate optical character\\nrecognition (OCR), robust visual-text reasoning, and high-quality translation,\\noften requiring cascading multi-stage pipelines. Recent advances in large-scale\\nReinforcement Learning (RL) have improved reasoning in Large Language Models\\n(LLMs) and Multimodal LLMs (MLLMs), but their application to end-to-end TIMT is\\nstill underexplored. To bridge this gap, we introduce MT$^{3}$, the first\\nframework to apply Multi-Task RL to MLLMs for end-to-end TIMT. MT$^{3}$ adopts\\na multi-task optimization paradigm targeting three key sub-skills: text\\nrecognition, context-aware reasoning, and translation. It is trained using a\\nnovel multi-mixed reward mechanism that adapts rule-based RL strategies to\\nTIMT's intricacies, offering fine-grained, non-binary feedback across tasks.\\nFurthermore, to facilitate the evaluation of TIMT in authentic cross-cultural\\nand real-world social media contexts, we introduced XHSPost, the first social\\nmedia TIMT benchmark. Our MT$^{3}$-7B-Zero achieves state-of-the-art results on\\nthe latest in-domain MIT-10M benchmark, outperforming strong baselines such as\\nQwen2.5-VL-72B and InternVL2.5-78B by notable margins across multiple metrics.\\nAdditionally, the model shows strong generalization to out-of-distribution\\nlanguage pairs and datasets. In-depth analyses reveal how multi-task synergy,\\nreinforcement learning initialization, curriculum design, and reward\\nformulation contribute to advancing MLLM-driven TIMT.|cs.CL,cs.AI,cs.LG            |cs.CV  |\n",
      "|http://arxiv.org/abs/2505.19715v1|Graceful Forgetting in Generative Language Models Recently, the pretrain-finetune paradigm has become a cornerstone in various\\ndeep learning areas. While in general the pre-trained model would promote both\\neffectiveness and efficiency of downstream tasks fine-tuning, studies have\\nshown that not all knowledge acquired during pre-training is beneficial. Some\\nof the knowledge may actually bring detrimental effects to the fine-tuning\\ntasks, which is also known as negative transfer. To address this problem,\\ngraceful forgetting has emerged as a promising approach. The core principle of\\ngraceful forgetting is to enhance the learning plasticity of the target task by\\nselectively discarding irrelevant knowledge. However, this approach remains\\nunderexplored in the context of generative language models, and it is often\\nchallenging to migrate existing forgetting algorithms to these models due to\\narchitecture incompatibility. To bridge this gap, in this paper we propose a\\nnovel framework, Learning With Forgetting (LWF), to achieve graceful forgetting\\nin generative language models. With Fisher Information Matrix weighting the\\nintended parameter updates, LWF computes forgetting confidence to evaluate\\nself-generated knowledge regarding the forgetting task, and consequently,\\nknowledge with high confidence is periodically unlearned during fine-tuning.\\nOur experiments demonstrate that, although thoroughly uncovering the mechanisms\\nof knowledge interaction remains challenging in pre-trained language models,\\napplying graceful forgetting can contribute to enhanced fine-tuning\\nperformance.                                                                                                                                                                                                                                                                |cs.CL,cs.AI,cs.LG            |cs.LG  |\n",
      "|http://arxiv.org/abs/2505.19716v1|Concise Reasoning, Big Gains: Pruning Long Reasoning Trace with\\n  Difficulty-Aware Prompting Existing chain-of-thought (CoT) distillation methods can effectively transfer\\nreasoning abilities to base models but suffer from two major limitations:\\nexcessive verbosity of reasoning traces and inadequate adaptability to problem\\ndifficulty. Long reasoning traces significantly increase inference costs, and\\nuniform-length solutions prevent base models from learning adaptive reasoning\\nstrategies. To address these issues, we propose a difficulty-aware prompting\\n(DAP) method to dynamically shorten reasoning traces without performance loss.\\nIn our approach, a large teacher model first judges each problem's difficulty\\nand then rewrites its reasoning traces to an appropriate shorter length,\\nyielding concise yet complete reasoning traces. Leveraging the DAP pipeline, we\\ncurate a distilled dataset called LiteCoT consisting of 100K concise reasoning\\nexamples, with solutions averaging only 720 tokens (an order of magnitude\\nshorter than typical CoTs). Using LiteCoT, we distilled a new family of\\nreasoning models called Liter (1.5B, 7B, and 32B) based on the Qwen2.5\\narchitecture. Experiments show that a student model fine-tuned on just 100K of\\nthese difficulty-pruned CoT samples outperforms a model distilled on 800K\\noriginal Long CoT samples, while significantly reducing training and inference\\ncosts. Our method also generalizes well: across 11 diverse benchmarks, the\\nshorter difficulty-aware CoTs achieve equal or better accuracy than Long\\nchains, using far fewer tokens. For example, on the challenging AIME24 exam,\\nour approach reaches $74.2\\%$ Pass@1 using only about 5K inference tokens,\\nsurpassing other methods that consume many more tokens. Our code and data are\\navailable at https://github.com/Evanwu1125/LiteCoT.                     |cs.AI                        |cs.CL  |\n",
      "+---------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-34-40.json\n",
      "\n",
      "========= 2025-05-29 21:34:50 =========\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+-----------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |true_label           |pred             |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+-----------------+\n",
      "|http://arxiv.org/abs/2505.19721v1|Observing Supernova Neutrino Light Curves with Super-Kamiokande.VI. A\\n  Practical Data Analysis Technique Considering Realistic Experimental\\n  Backgrounds Neutrinos from supernovae, especially those emitted during the late phase of\\ncore collapse, are essential for understanding the final stages of massive star\\nevolution. We have been dedicated to developing methods for the analysis of\\nneutrinos emitted during the late phase and observed at Super-Kamiokande (SK).\\nOur previous studies have successfully demonstrated the potential of various\\nanalysis methods in extracting essential physical properties; however, the lack\\nof background consideration has limited their practical application. In this\\nstudy, we address this issue by incorporating a realistic treatment of the\\nexperimental signal and background events with the on-going SK experiment. We\\ntherefore optimize our analysis framework to reflect realistic observational\\nconditions, including both signal and background events. Using this framework\\nwe study several long-time supernova models, simulating the late phase neutrino\\nobservation in SK and focusing in particular on the identification of the last\\nobserved event. We discuss the possibility of model discrimination methods\\nusing timing information from this last observed event.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |astro-ph.HE,hep-ex   |astro-ph.HE      |\n",
      "|http://arxiv.org/abs/2505.19722v1|Distilling Closed-Source LLM's Knowledge for Locally Stable and Economic\\n  Biomedical Entity Linking Biomedical entity linking aims to map nonstandard entities to standard\\nentities in a knowledge base. Traditional supervised methods perform well but\\nrequire extensive annotated data to transfer, limiting their usage in\\nlow-resource scenarios. Large language models (LLMs), especially closed-source\\nLLMs, can address these but risk stability issues and high economic costs:\\nusing these models is restricted by commercial companies and brings significant\\neconomic costs when dealing with large amounts of data. To address this, we\\npropose ``RPDR'', a framework combining closed-source LLMs and open-source LLMs\\nfor re-ranking candidates retrieved by a retriever fine-tuned with a small\\namount of data. By prompting a closed-source LLM to generate training data from\\nunannotated data and fine-tuning an open-source LLM for re-ranking, we\\neffectively distill the knowledge to the open-source LLM that can be deployed\\nlocally, thus avoiding the stability issues and the problem of high economic\\ncosts. We evaluate RPDR on two datasets, including one real-world dataset and\\none publicly available dataset involving two languages: Chinese and English.\\nRPDR achieves 0.019 Acc@1 improvement and 0.036 Acc@1 improvement on the Aier\\ndataset and the Ask A Patient dataset when the amount of training data is not\\nenough. The results demonstrate the superiority and generalizability of the\\nproposed framework.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.CL,cs.AI          |cs.CL            |\n",
      "|http://arxiv.org/abs/2505.19723v1|Catability as a metric for evaluating superposed coherent states Superposed coherent states are central to quantum technologies, yet their\\nreliable identification remains a challenge, especially in noisy or\\nresource-constrained settings. We introduce a novel, directly measurable\\ncriterion for detecting cat-like features in quantum states, rooted in the\\nconcept of nonlinear squeezing. This approach bypasses the need for full state\\ntomography and reveals structure where fidelity fails. The numerical results\\nconfirm its robustness under loss and its potential for experimental\\nimplementation. The method naturally generalizes to more exotic superpositions,\\nincluding multiheaded cat states.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |quant-ph             |quant-ph         |\n",
      "|http://arxiv.org/abs/2505.19724v1|Local near-quadratic convergence of Riemannian interior point methods We consider Riemannian optimization problems with inequality and equality\\nconstraints and analyze a class of Riemannian interior point methods for\\nsolving them. The algorithm of interest consists of outer and inner iterations.\\nWe show that, under standard assumptions, the algorithm achieves local\\nsuperlinear convergence by solving a linear system at each outer iteration,\\nremoving the need for further computations in the inner iterations. We also\\nprovide a specific update for the barrier parameters that achieves local\\nnear-quadratic convergence of the algorithm. We apply our results to the method\\nproposed by Obara, Okuno, and Takeda (2025) and show its local superlinear and\\nnear-quadratic convergence with an analysis of the second-order stationarity.\\nTo our knowledge, this is the first algorithm for constrained optimization on\\nRiemannian manifolds that achieves both local convergence and global\\nconvergence to a second-order stationary point.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |math.OC              |math.OC          |\n",
      "|http://arxiv.org/abs/2505.19725v1|Parametrized Tidal Dissipation Numbers of Non-rotating Black Holes A set of tidal dissipation numbers (TDNs) quantifies the absorption of the\\ntidal force exerted by a companion during an inspiralling phase of a binary\\ncompact object. This tidal dissipation generally affects the gravitational\\nwaveform, and measuring the TDNs of a black hole (BH) allows us to test the\\nnature of gravity in the strong-field regime. In this paper, we develop a\\nparametrized formalism for calculating the TDNs of static and spherically\\nsymmetric BH backgrounds using the Mano-Suzuki-Takasugi method, which connects\\nthe underlying perturbative equations with observable quantities in\\ngravitational-wave observations in a theory-agnostic manner. Our formalism\\napplies to any system where the master equation has the form of the\\nRegge-Wheeler/Zerilli equation with a small correction to the effective\\npotential. As an application of our formalism, we consider three examples: the\\neffective field theory of BH perturbations with timelike scalar profile, the\\nEinstein-Maxwell system, and a higher-curvature extension of general\\nrelativity. We also discuss the absence of logarithmic running for the TDNs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |gr-qc                |gr-qc            |\n",
      "|http://arxiv.org/abs/2505.19726v1|Reaction-diffusion equations in periodic media: convergence to pulsating\\n  fronts This paper is concerned with reaction-diffusion-advection equations in\\nspatially periodic media. Under an assumption of weak stability of the constant\\nstates 0 and 1, and of existence of pulsating traveling fronts connecting them,\\nwe show that fronts' profiles appear, along sequences of times and points, in\\nthe large-time dynamics of the solutions of the Cauchy problem, whether their\\ninitial supports are bounded or unbounded. The types of equations that fit into\\nour assumptions are the combustion and the bistable ones. We also show a\\ngeneralized Freidlin-G{\\\"a}rtner formula and other geometrical properties of\\nthe asymptotic invasion shapes, or spreading sets, of invading solutions, and\\nwe relate these sets to the upper level sets of the solutions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |math.AP              |math.AP          |\n",
      "|http://arxiv.org/abs/2505.19727v1|The biharmonic hypersurface flow and the Willmore flow in higher\\n  dimensions The biharmonic flow of hypersurfaces $M^n$ immersed in the Euclidean space\\n$\\mathbb {R}^{n+1}$ for $n\\geq 2$ is given by a fourth order geometric\\nevolution equation, which is similar to the Willmore flow. We apply the\\nMichael-Simon-Sobolev inequality to establish new Gagliardo-Nirenberg\\ninequalities on hypersurfaces. Based on these Gagliardo-Nirenberg inequalities,\\nwe apply local energy estimates to extend the solution by a covering argument\\nand obtain an estimate on the maximal existence time of the biharmonic flow of\\nhypersurfaces in higher dimensions. In particular, we solve a problem in\\n\\cite{BWW} on the biharmonic hypersurface flow for $n=4$. Finally, we apply our\\nnew approach to prove global existence of the Willmore flow in higher\\ndimensions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |math.DG              |math.AP          |\n",
      "|http://arxiv.org/abs/2505.19728v1|Local isometric immersions of pseudospherical surfaces described by a\\n  class of third order partial differential equations In this paper, we study the problem of local isometric immersion of\\npseudospherical surfaces determined by the solutions of a class of third order\\nnonlinear partial differential equations with the type $u_t - u_{xxt} = \\lambda\\nu^2 u_{xxx} + G(u, u_x, u_{xx}),(\\lambda\\in\\mathbb{R})$. We prove that there is\\nonly two subclasses of equations admitting a local isometric immersion into the\\nthree dimensional Euclidean space $\\mathbb{E}^3$ for which the coefficients of\\nthe second fundamental form depend on a jet of finite order of $u$, and\\nfurthermore, these coefficients are universal, namely, they are functions of\\n$x$ and $t$, independent of $u$. Finally, we show that the generalized\\nCamassa-Holm equation describing pseudospherical surfaces has a universal\\nsecond fundamental form.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |math-ph,math.MP      |math.AP          |\n",
      "|http://arxiv.org/abs/2505.19729v1|Sensing high-frequency AC fields via a two-qubit probe Quantum sensors allow us to measure weak oscillating fields with incredible\\nprecision. One common approach is to use the time evolution of a single\\ntwo-level system in conjunction with applied control pulses to measure the\\noscillating field. For high-frequency fields, the time interval required\\nbetween the applied pulses decreases, meaning that errors due to the finite\\nwidth of the pulses can become important. This paper presents an alternative\\nscheme that does not rely on applying pulses with short time intervals. Our\\nscheme uses two interacting two-level systems. In the presence of an\\noscillating field, the interaction strength changes. The oscillating field can\\nbe estimated by measuring the change in this interaction strength. We quantify\\nthe precision of this estimate by calculating the Fisher information. We show\\nthe effect of noise on our scheme and discuss how control pulses can be applied\\nto mitigate the impact of noise. Importantly, the time interval between these\\npulses need not be very short.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |quant-ph             |quant-ph         |\n",
      "|http://arxiv.org/abs/2505.19730v1|Composition dependent $\\mathbf{k}\\cdot\\mathbf{p}$ band parameters for\\n  wurtzite (Al,Ga)N alloys from density functional theory UV emitters based on the semiconductor alloy aluminium gallium nitride,\\n(Al,Ga)N, have attracted significant interest in recent years due to their\\npotential for optoelectronic devices. To guide the design of such devices with\\nimproved efficiencies, theoretical frameworks based on so-called k.p methods\\nhave found widespread application in the literature. Given that k.p models are\\nempirical in nature, parameters such as effective masses or crystal field\\nsplitting energies of (Al,Ga)N alloys have to be provided as input from\\nfirst-principles calculations or experiment. Although these parameters are\\navailable for GaN and AlN, detailed information on their composition dependence\\nis sparse. Here, we address this question and provide (Al,Ga)N band parameters\\nfor widely used k.p Hamiltonians. We start from density functional theory (DFT)\\nto sample the electronic structure of (Al,Ga)N alloys over the full composition\\nrange. The k.p parameters are treated as free parameters to reproduce the DFT\\ndata. For GaN and AlN the parameters extracted here agree well with literature\\nvalues. When turning to the composition dependence of the k.p parameters, our\\ncalculations show that most parameters deviate significantly from a linear\\ninterpolation of the GaN and AlN values, an approximation widely made in the\\nliterature. Moreover, to describe changes in the band parameters with Al\\ncontent, composition dependent bowing parameters have to be considered for an\\naccurate description of the DFT data. Finally, our analysis also provides\\ninitial insight into consequences of the nonlinear composition dependence of\\nthe k.p parameters for the electronic structure of (Al,Ga)N alloys. We find\\nthat in particular the band ordering is affected by the nonlinear evolution of\\nthe crystal field splitting energy with composition, an important aspect for\\nthe light polarization characteristics of high Al content (Al,Ga)N alloys.|cond-mat.mtrl-sci    |cond-mat.mtrl-sci|\n",
      "|http://arxiv.org/abs/2505.19731v1|Accelerating Nash Learning from Human Feedback via Mirror Prox Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on\\nreward models, frequently assuming preference structures like the Bradley-Terry\\nmodel, which may not accurately capture the complexities of real human\\npreferences (e.g., intransitivity). Nash Learning from Human Feedback (NLHF)\\noffers a more direct alternative by framing the problem as finding a Nash\\nequilibrium of a game defined by these preferences. In this work, we introduce\\nNash Mirror Prox ($\\mathtt{Nash-MP}$), an online NLHF algorithm that leverages\\nthe Mirror Prox optimization scheme to achieve fast and stable convergence to\\nthe Nash equilibrium. Our theoretical analysis establishes that Nash-MP\\nexhibits last-iterate linear convergence towards the $\\beta$-regularized Nash\\nequilibrium. Specifically, we prove that the KL-divergence to the optimal\\npolicy decreases at a rate of order $(1+2\\beta)^{-N/2}$, where $N$ is a number\\nof preference queries. We further demonstrate last-iterate linear convergence\\nfor the exploitability gap and uniformly for the span semi-norm of\\nlog-probabilities, with all these rates being independent of the size of the\\naction space. Furthermore, we propose and analyze an approximate version of\\nNash-MP where proximal steps are estimated using stochastic policy gradients,\\nmaking the algorithm closer to applications. Finally, we detail a practical\\nimplementation strategy for fine-tuning large language models and present\\nexperiments that demonstrate its competitive performance and compatibility with\\nexisting methods.                                                                                                                                                                                                                                                                                                                                                                                                                                                             |stat.ML,cs.LG        |cs.LG            |\n",
      "|http://arxiv.org/abs/2505.19732v1|Generic effective source for gravitational self-force calculations in\\n  Schwarzschild spacetime The numerical calculation of gravitational self-force in extreme mass ratio\\ninspiral systems (EMRIs) is fundamentally challenging due to the singular\\nnature of point-particle sources. This singularity arises from the interaction\\nbetween the smaller compact object and its own gravitational perturbation. To\\naddress these challenges, the effective source method offers an innovative\\napproach. It replaces traditional regularization schemes with a reformulation\\nof the problem, utilizing finite and physically meaningful effective sources\\nthat inherently incorporate renormalized quantities. This paper presents an\\nanalytic framework for constructing finite and continuous effective sources for\\nmassive point particles undergoing arbitrary geodesic motion in Schwarzschild\\nspacetime. This represents the first fully analytic treatment of such sources\\nfor generic geodesic trajectories. The complete analytic expression for\\neffective sources establishes a critical foundation for computing both\\nself-consistent and second-order gravitational self-forces, thereby enabling\\naccurate waveform modeling of EMRIs in gravitational wave astronomy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |gr-qc                |gr-qc            |\n",
      "|http://arxiv.org/abs/2505.19733v1|Cross-Sequence Semi-Supervised Learning for Multi-Parametric MRI-Based\\n  Visual Pathway Delineation Accurately delineating the visual pathway (VP) is crucial for understanding\\nthe human visual system and diagnosing related disorders. Exploring\\nmulti-parametric MR imaging data has been identified as an important way to\\ndelineate VP. However, due to the complex cross-sequence relationships,\\nexisting methods cannot effectively model the complementary information from\\ndifferent MRI sequences. In addition, these existing methods heavily rely on\\nlarge training data with labels, which is labor-intensive and time-consuming to\\nobtain. In this work, we propose a novel semi-supervised multi-parametric\\nfeature decomposition framework for VP delineation. Specifically, a\\ncorrelation-constrained feature decomposition (CFD) is designed to handle the\\ncomplex cross-sequence relationships by capturing the unique characteristics of\\neach MRI sequence and easing the multi-parametric information fusion process.\\nFurthermore, a consistency-based sample enhancement (CSE) module is developed\\nto address the limited labeled data issue, by generating and promoting\\nmeaningful edge information from unlabeled data. We validate our framework\\nusing two public datasets, and one in-house Multi-Shell Diffusion MRI (MDM)\\ndataset. Experimental results demonstrate the superiority of our approach in\\nterms of delineation performance when compared to seven state-of-the-art\\napproaches.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.CV,cs.CE          |eess.IV          |\n",
      "|http://arxiv.org/abs/2505.19734v1|ReChisel: Effective Automatic Chisel Code Generation by LLM with\\n  Reflection Coding with hardware description languages (HDLs) such as Verilog is a\\ntime-intensive and laborious task. With the rapid advancement of large language\\nmodels (LLMs), there is increasing interest in applying LLMs to assist with HDL\\ncoding. Recent efforts have demonstrated the potential of LLMs in translating\\nnatural language to traditional HDL Verilog. Chisel, a next-generation HDL\\nbased on Scala, introduces higher-level abstractions, facilitating more\\nconcise, maintainable, and scalable hardware designs. However, the potential of\\nusing LLMs for Chisel code generation remains largely unexplored. This work\\nproposes ReChisel, an LLM-based agentic system designed to enhance the\\neffectiveness of Chisel code generation. ReChisel incorporates a reflection\\nmechanism to iteratively refine the quality of generated code using feedback\\nfrom compilation and simulation processes, and introduces an escape mechanism\\nto break free from non-progress loops. Experiments demonstrate that ReChisel\\nsignificantly improves the success rate of Chisel code generation, achieving\\nperformance comparable to state-of-the-art LLM-based agentic systems for\\nVerilog code generation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |cs.AI,cs.AR          |cs.SE            |\n",
      "|http://arxiv.org/abs/2505.19735v1|A space-dependent Boltzmann-BGK model for gas mixtures and its\\n  hydrodynamic limits We present a hybrid Boltzmann-BGK model for inert mixtures, where each kind\\nof binary interaction may be described by a classical Boltzmann integral or by\\na suitable relaxation-type operator. We allow also the possibility of changing\\nthe option Boltzmann/BGK operator according to the space position. We prove\\nthat this model guarantees conservations of species masses, global momentum and\\nenergy, as well as the entropy dissipation, leading to the expected Maxwellian\\nequilibria with all species sharing the same mean velocity and the same\\ntemperature. We investigate then such mixed kinetic equations in three\\ndifferent hydrodynamic limits: the classical collision dominated regime, a\\nsituation with dominant intra-species collisions, and a mixture with heavy and\\nlight particles leading to a kinetic-fluid description.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |math-ph,math.MP      |math.AP          |\n",
      "|http://arxiv.org/abs/2505.19736v1|SETBVE: Quality-Diversity Driven Exploration of Software Boundary\\n  Behaviors Software systems exhibit distinct behaviors based on input characteristics,\\nand failures often occur at the boundaries between input domains. Traditional\\nBoundary Value Analysis (BVA) relies on manual heuristics, while automated\\nBoundary Value Exploration (BVE) methods typically optimize a single quality\\nmetric, risking a narrow and incomplete survey of boundary behaviors. We\\nintroduce SETBVE, a customizable, modular framework for automated black-box BVE\\nthat leverages Quality-Diversity (QD) optimization to systematically uncover\\nand refine a broader spectrum of boundaries. SETBVE maintains an archive of\\nboundary pairs organized by input- and output-based behavioral descriptors. It\\nsteers exploration toward underrepresented regions while preserving\\nhigh-quality boundary pairs and applies local search to refine candidate\\nboundaries. In experiments with ten integer-based functions, SETBVE outperforms\\nthe baseline in diversity, boosting archive coverage by 37 to 82 percentage\\npoints. A qualitative analysis reveals that SETBVE identifies boundary\\ncandidates the baseline misses. While the baseline method typically plateaus in\\nboth diversity and quality after 30 seconds, SETBVE continues to improve in\\n600-second runs, demonstrating better scalability. Even the simplest SETBVE\\nconfigurations perform well in identifying diverse boundary behaviors. Our\\nfindings indicate that balancing quality with behavioral diversity can help\\nidentify more software edge-case behaviors than quality-focused approaches.                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.SE,D.2.5          |cs.SE            |\n",
      "|http://arxiv.org/abs/2505.19737v1|Weighted Leave-One-Out Cross Validation We present a weighted version of Leave-One-Out (LOO) cross-validation for\\nestimating the Integrated Squared Error (ISE) when approximating an unknown\\nfunction by a predictor that depends linearly on evaluations of the function\\nover a finite collection of sites. The method relies on the construction of the\\nbest linear estimator of the squared prediction error at an arbitrary unsampled\\nsite based on squared LOO residuals, assuming that the function is a\\nrealization of a Gaussian Process (GP). A theoretical analysis of performance\\nof the ISE estimator is presented, and robustness with respect to the choice of\\nthe GP kernel is investigated first analytically, then through numerical\\nexamples. Overall, the estimation of ISE is significantly more precise than\\nwith classical, unweighted, LOO cross validation. Application to model\\nselection is briefly considered through examples.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |stat.ML,cs.LG,stat.ME|stat.ME          |\n",
      "|http://arxiv.org/abs/2505.19738v1|Numerical Identification of a Time-Dependent Coefficient in a\\n  Time-Fractional Diffusion Equation with Integral Constraints In this paper, we numerically address the inverse problem of identifying a\\ntime-dependent coefficient in the time-fractional diffusion equation. An a\\npriori estimate is established to ensure uniqueness and stability of the\\nsolution. A fully implicit finite-difference scheme is proposed and rigorously\\nanalysed for stability and convergence. An efficient algorithm based on an\\nintegral formulation is implemented and verified through numerical experiments,\\ndemonstrating accuracy and robustness under noisy data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |math.NA,cs.NA        |math.NA          |\n",
      "|http://arxiv.org/abs/2505.19739v1|Justin: Hybrid CPU/Memory Elastic Scaling for Distributed Stream\\n  Processing Distributed Stream Processing (DSP) engines analyze continuous data via\\nqueries expressed as a graph of operators. Auto-scalers adjust the number of\\nparallel instances of these operators to support a target rate. Current\\nauto-scalers couple CPU and memory scaling, allocating resources as\\none-size-fits-all packages. This contrasts with operators' high diversity of\\nrequirements. We present Justin, an auto-scaler that enables hybrid CPU and\\nmemory scaling of DSP operators. Justin monitors both CPU usage and the\\nperformance of operators' storage operations. Its mechanisms enable finegrain\\nmemory allocation for tasks upon a query reconfiguration. The Justin policy\\nidentifies individual operators' memory pressure and decides between adjusting\\nparallelism and/or memory assignment. We implement Justin in Apache Flink,\\nextending the Flink Kubernetes Operator and the DS2 CPU-only auto-scaler. Using\\nthe Nexmark benchmark, our evaluation shows that Justin identifies suitable\\nresource allocation in as many or fewer reconfiguration steps as DS2 and\\nsupports a target rate with significantly fewer CPU and memory resources.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |cs.DC                |cs.DC            |\n",
      "|http://arxiv.org/abs/2505.19740v1|Machine Learning Algorithm for Noise Reduction and Disease-Causing Gene\\n  Feature Extraction in Gene Sequencing Data In this study, we propose a machine learning-based method for noise reduction\\nand disease-causing gene feature extraction in gene sequencing DeepSeqDenoise\\nalgorithm combines CNN and RNN to effectively remove the sequencing noise, and\\nimproves the signal-to-noise ratio by 9.4 dB. We screened 17 key features by\\nfeature engineering, and constructed an integrated learning model to predict\\ndisease-causing genes with 94.3% accuracy. We successfully identified 57 new\\ncandidate disease-causing genes in a cardiovascular disease cohort validation,\\nand detected 3 missed variants in clinical applications. The method\\nsignificantly outperforms existing tools and provides strong support for\\naccurate diagnosis of genetic diseases.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.LG                |cs.LG            |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-34-50.json\n",
      "\n",
      "========= 2025-05-29 21:35:00 =========\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------+------------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |true_label                        |pred              |\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------+------------------+\n",
      "|http://arxiv.org/abs/2505.19746v1|Improving Heart Rejection Detection in XPCI Images Using Synthetic Data\\n  Augmentation Accurate identification of acute cellular rejection (ACR) in endomyocardial\\nbiopsies is essential for effective management of heart transplant patients.\\nHowever, the rarity of high-grade rejection cases (3R) presents a significant\\nchallenge for training robust deep learning models. This work addresses the\\nclass imbalance problem by leveraging synthetic data generation using StyleGAN\\nto augment the limited number of real 3R images. Prior to GAN training,\\nhistogram equalization was applied to standardize image appearance and improve\\nthe consistency of tissue representation. StyleGAN was trained on available 3R\\nbiopsy patches and subsequently used to generate 10,000 realistic synthetic\\nimages. These were combined with real 0R samples, that is samples without\\nrejection, in various configurations to train ResNet-18 classifiers for binary\\nrejection classification.\\n  Three classifier variants were evaluated: one trained on real 0R and\\nsynthetic 3R images, another using both synthetic and additional real samples,\\nand a third trained solely on real data. All models were tested on an\\nindependent set of real biopsy images. Results demonstrate that synthetic data\\nimproves classification performance, particularly when used in combination with\\nreal samples. The highest-performing model, which used both real and synthetic\\nimages, achieved strong precision and recall for both classes. These findings\\nunderscore the value of hybrid training strategies and highlight the potential\\nof GAN-based data augmentation in biomedical image analysis, especially in\\ndomains constrained by limited annotated datasets.                                                                                                                                                                                 |cs.CV                             |cs.CV             |\n",
      "|http://arxiv.org/abs/2505.19747v1|Gravitational wave cosmology Gravitational waves (GWs) originating from cosmological sources offer direct\\ninsights into the physics of the primordial Universe, the fundamental nature of\\ngravity, and the cosmic expansion of the Universe. In this review paper, we\\npresent a comprehensive overview of our recent advances in GW cosmology,\\nsupported by the national key research and development program of China,\\nfocusing on cosmological GW sources and their implications for fundamental\\nphysics and cosmology. We first discuss the generation mechanisms and\\ncharacteristics of stochastic gravitational wave backgrounds generated by\\nphysical processes occurred in the early Universe, including those from\\ninflation, phase transitions, and topological defects, and summarize current\\nand possible future constraints from pulsar timing array and space-based\\ndetectors. Next, we explore the formation and observational prospects of\\nprimordial black holes as GW sources and their potential connection to dark\\nmatter. We then analyze how GWs are affected by large-scale structure,\\ncosmological perturbations, and possible modifications of gravity on GW\\npropagation, and how these effects can be used to test fundamental symmetry of\\ngravity. Finally, we discuss the application of GW standard sirens in measuring\\nthe Hubble constant, the expansion history, and dark energy parameters,\\nincluding their combination with electromagnetic observations. These topics\\ntogether show how GW observations, especially with upcoming space-based\\ndetectors, such as LISA, Taiji, and Tianqin, can provide new information about\\nthe physics of the early Universe, cosmological evolution, and the nature of\\ngravity.                                                                                                                                                                                               |gr-qc,hep-th                      |gr-qc             |\n",
      "|http://arxiv.org/abs/2505.19748v1|Boundary local time on wedges and prefractal curves We investigate the boundary local time on polygonal boundaries such as finite\\ngenerations of the Koch snowflake. To reveal the role of angles, we first focus\\non wedges and obtain the mean boundary local time, its variance, and the\\nasymptotic behavior of its distribution. Moreover, we establish the coupled\\npartial differential equations for higher-order moments. Next, we propose an\\nefficient multi-scale Monte Carlo approach to simulate the boundary local time,\\nas well as the escape duration and position of the associated reaction event on\\na polygonal boundary. This numerical approach combines the walk-on-spheres\\nalgorithm in the bulk with an approximate solution of the escape problem from a\\nsector. We apply it to investigate how the statistics of the boundary local\\ntime depends on the geometric complexity of the Koch snowflake. Eventual\\napplications to diffusion-controlled reactions on partially reactive\\nboundaries, including the asymptotic behavior of the survival probability, are\\ndiscussed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cond-mat.stat-mech,physics.comp-ph|cond-mat.stat-mech|\n",
      "|http://arxiv.org/abs/2505.19749v1|Global stability for the compressible isentropic magnetohydrodynamic\\n  equations in 3D bounded domains with Navier-slip boundary conditions We study the global stability of large solutions to the compressible\\nisentropic magnetohydrodynamic equations in a three-dimensional (3D) bounded\\ndomain with Navier-slip boundary conditions. It is shown that the solutions\\nconverge to an equilibrium state exponentially in the $L^2$-norm provided the\\ndensity is essentially uniform-in-time bounded from above. Moreover, we also\\nobtain that the density and magnetic field converge to their equilibrium states\\nexponentially in the $L^\\infty$-norm if additionally the initial density is\\nbounded away from zero. These greatly improve the previous work in (J.\\nDifferential Equations 288 (2021), 1-39), where the authors considered the\\ntorus case and required the $L^6$-norm of the magnetic field to be uniformly\\nbounded as well as zero initial total momentum and an additional restriction\\n$2\\mu>\\lambda$ for the viscous coefficients. This paper provides the first\\nglobal stability result for large strong solutions of compressible\\nmagnetohydrodynamic equations in 3D general bounded domains.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |math.AP                           |math.AP           |\n",
      "|http://arxiv.org/abs/2505.19750v1|SuperAD: A Training-free Anomaly Classification and Segmentation Method\\n  for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect In this technical report, we present our solution to the CVPR 2025 Visual\\nAnomaly and Novelty Detection (VAND) 3.0 Workshop Challenge Track 1: Adapt &\\nDetect: Robust Anomaly Detection in Real-World Applications. In real-world\\nindustrial anomaly detection, it is crucial to accurately identify anomalies\\nwith physical complexity, such as transparent or reflective surfaces,\\nocclusions, and low-contrast contaminations. The recently proposed MVTec AD 2\\ndataset significantly narrows the gap between publicly available benchmarks and\\nanomalies found in real-world industrial environments. To address the\\nchallenges posed by this dataset--such as complex and varying lighting\\nconditions and real anomalies with large scale differences--we propose a fully\\ntraining-free anomaly detection and segmentation method based on feature\\nextraction using the DINOv2 model named SuperAD. Our method carefully selects a\\nsmall number of normal reference images and constructs a memory bank by\\nleveraging the strong representational power of DINOv2. Anomalies are then\\nsegmented by performing nearest neighbor matching between test image features\\nand the memory bank. Our method achieves competitive results on both test sets\\nof the MVTec AD 2 dataset.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |cs.CV                             |cs.CV             |\n",
      "|http://arxiv.org/abs/2505.19751v1|SAIL: Self-supervised Albedo Estimation from Real Images with a Latent\\n  Diffusion Model Intrinsic image decomposition aims at separating an image into its underlying\\nalbedo and shading components, isolating the base color from lighting effects\\nto enable downstream applications such as virtual relighting and scene editing.\\nDespite the rise and success of learning-based approaches, intrinsic image\\ndecomposition from real-world images remains a significant challenging task due\\nto the scarcity of labeled ground-truth data. Most existing solutions rely on\\nsynthetic data as supervised setups, limiting their ability to generalize to\\nreal-world scenes. Self-supervised methods, on the other hand, often produce\\nalbedo maps that contain reflections and lack consistency under different\\nlighting conditions. To address this, we propose SAIL, an approach designed to\\nestimate albedo-like representations from single-view real-world images. We\\nrepurpose the prior knowledge of a latent diffusion model for unconditioned\\nscene relighting as a surrogate objective for albedo estimation. To extract the\\nalbedo, we introduce a novel intrinsic image decomposition fully formulated in\\nthe latent space. To guide the training of our latent diffusion model, we\\nintroduce regularization terms that constrain both the lighting-dependent and\\nindependent components of our latent image decomposition. SAIL predicts stable\\nalbedo under varying lighting conditions and generalizes to multiple scenes,\\nusing only unlabeled multi-illumination data available online.                                                                                                                                                                                                                                                                                                                                            |cs.CV                             |cs.CV             |\n",
      "|http://arxiv.org/abs/2505.19752v1|Discrete Markov Bridge Discrete diffusion has recently emerged as a promising paradigm in discrete\\ndata modeling. However, existing methods typically rely on a fixed rate\\ntransition matrix during training, which not only limits the expressiveness of\\nlatent representations, a fundamental strength of variational methods, but also\\nconstrains the overall design space. To address these limitations, we propose\\nDiscrete Markov Bridge, a novel framework specifically designed for discrete\\nrepresentation learning. Our approach is built upon two key components: Matrix\\nLearning and Score Learning. We conduct a rigorous theoretical analysis,\\nestablishing formal performance guarantees for Matrix Learning and proving the\\nconvergence of the overall framework. Furthermore, we analyze the space\\ncomplexity of our method, addressing practical constraints identified in prior\\nstudies. Extensive empirical evaluations validate the effectiveness of the\\nproposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO)\\nof 1.38 on the Text8 dataset, outperforming established baselines. Moreover,\\nthe proposed model demonstrates competitive performance on the CIFAR-10\\ndataset, achieving results comparable to those obtained by image-specific\\ngeneration approaches.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |cs.LG,cs.AI,cs.CL                 |cs.LG             |\n",
      "|http://arxiv.org/abs/2505.19753v1|Triaxial shapes in even-even nuclei: A theoretical overview Triaxial shapes in even-even nuclei have been considered since the early days\\nof the nuclear collective model. Although many theoretical approaches have been\\nused over the years for their description, no effort appears to have been made\\nfor grouping them together and identifying regions on the nuclear chart where\\nthe appearance of triaxiality might be favored. In addition, over the last few\\nyears, discussion has started on the appearance of small triaxiality in nuclei\\nconsidered so far as purely axial rotors. In the present work we collect the\\npredictions made by various theoretical approaches and show that pronounced\\ntriaxiality appears to be favored within specific stripes on the nuclear chart,\\nwith low triaxiality being present in the regions between these stripes, in\\nagreement with parameter-free predictions made by the proxy-SU(3) approximation\\nto the shell model, based on the Pauli principle and the short-range nature of\\nthe nucleon-nucleon interaction. The robustness of triaxiality within these\\nstripes is supported by global calculations made in the framework of the\\nFinite-Range Droplet Model (FRDM), which is based on completely different\\nassumptions and possesses parameters fitted in order to reproduce fundamental\\nnuclear properties.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |nucl-th                           |nucl-th           |\n",
      "|http://arxiv.org/abs/2505.19754v1|NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring\\n  for PDF Question Answering The increasing number of academic papers poses significant challenges for\\nresearchers to efficiently acquire key details. While retrieval augmented\\ngeneration (RAG) shows great promise in large language model (LLM) based\\nautomated question answering, previous works often isolate neural and symbolic\\nretrieval despite their complementary strengths. Moreover, conventional\\nsingle-view chunking neglects the rich structure and layout of PDFs, e.g.,\\nsections and tables. In this work, we propose NeuSym-RAG, a hybrid neural\\nsymbolic retrieval framework which combines both paradigms in an interactive\\nprocess. By leveraging multi-view chunking and schema-based parsing, NeuSym-RAG\\norganizes semi-structured PDF content into both the relational database and\\nvectorstore, enabling LLM agents to iteratively gather context until sufficient\\nto generate answers. Experiments on three full PDF-based QA datasets, including\\na self-annotated one AIRQA-REAL, show that NeuSym-RAG stably defeats both the\\nvector-based RAG and various structured baselines, highlighting its capacity to\\nunify both retrieval schemes and utilize multiple views. Code and data are\\npublicly available at https://github.com/X-LANCE/NeuSym-RAG.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cs.CL,cs.AI                       |cs.CL             |\n",
      "|http://arxiv.org/abs/2505.19755v1|One Model to Rank Them All: Unifying Online Advertising with End-to-End\\n  Learning Modern industrial advertising systems commonly employ Multi-stage Cascading\\nArchitectures (MCA) to balance computational efficiency with ranking accuracy.\\nHowever, this approach presents two fundamental challenges: (1) performance\\ninconsistencies arising from divergent optimization targets and capability\\ndifferences between stages, and (2) failure to account for advertisement\\nexternalities - the complex interactions between candidate ads during ranking.\\nThese limitations ultimately compromise system effectiveness and reduce\\nplatform profitability. In this paper, we present UniROM, an end-to-end\\ngenerative architecture that Unifies online advertising Ranking as One Model.\\nUniROM replaces cascaded stages with a single model to directly generate\\noptimal ad sequences from the full candidate ad corpus in location-based\\nservices (LBS). The primary challenges associated with this approach stem from\\nhigh costs of feature processing and computational bottlenecks in modeling\\nexternalities of large-scale candidate pools. To address these challenges,\\nUniROM introduces an algorithm and engine co-designed hybrid feature service to\\ndecouple user and ad feature processing, reducing latency while preserving\\nexpressiveness. To efficiently extract intra- and cross-sequence mutual\\ninformation, we propose RecFormer with an innovative cluster-attention\\nmechanism as its core architectural component. Furthermore, we propose a\\nbi-stage training strategy that integrates pre-training with reinforcement\\nlearning-based post-training to meet sophisticated platform and advertising\\nobjectives. Extensive offline evaluations on public benchmarks and large-scale\\nonline A/B testing on industrial advertising platform have demonstrated the\\nsuperior performance of UniROM over state-of-the-art MCAs.|cs.IR                             |cs.LG             |\n",
      "|http://arxiv.org/abs/2505.19756v1|Efficient Reasoning via Chain of Unconscious Thought Large Reasoning Models (LRMs) achieve promising performance but compromise\\ntoken efficiency due to verbose reasoning processes. Unconscious Thought Theory\\n(UTT) posits that complex problems can be solved more efficiently through\\ninternalized cognitive processes. Inspired by UTT, we propose a new reasoning\\nparadigm, termed Chain of Unconscious Thought (CoUT), to improve the token\\nefficiency of LRMs by guiding them to mimic human unconscious thought and\\ninternalize reasoning processes. Concretely, we first prompt the model to\\ninternalize the reasoning by thinking in the hidden layer. Then, we design a\\nbag of token-efficient strategies to further help models reduce unnecessary\\ntokens yet preserve the performance. Our work reveals that models may possess\\nbeneficial unconscious thought, enabling improved efficiency without\\nsacrificing performance. Extensive experiments demonstrate the effectiveness of\\nCoUT. Remarkably, it surpasses CoT by reducing token usage by 47.62% while\\nmaintaining comparable accuracy, as shown in Figure 1. The code of CoUT is\\navailable at this link: https://github.com/Rohan-GRH/CoUT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |cs.CL                             |cs.CL             |\n",
      "|http://arxiv.org/abs/2505.19757v1|CIDRe: A Reference-Free Multi-Aspect Criterion for Code Comment Quality\\n  Measurement Effective generation of structured code comments requires robust quality\\nmetrics for dataset curation, yet existing approaches (SIDE, MIDQ, STASIS)\\nsuffer from limited code-comment analysis. We propose CIDRe, a\\nlanguage-agnostic reference-free quality criterion combining four synergistic\\naspects: (1) relevance (code-comment semantic alignment), (2) informativeness\\n(functional coverage), (3) completeness (presence of all structure sections),\\nand (4) description length (detail sufficiency). We validate our criterion on a\\nmanually annotated dataset. Experiments demonstrate CIDRe's superiority over\\nexisting metrics, achieving improvement in cross-entropy evaluation. When\\napplied to filter comments, the models finetuned on CIDRe-filtered data show\\nstatistically significant quality gains in GPT-4o-mini assessments.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.SE,cs.AI,cs.CL,cs.LG           |cs.SE             |\n",
      "|http://arxiv.org/abs/2505.19758v1|The nonleptonic decays $Œû_{cc}^{++}\\toŒû_{c}^{(\\prime)+}œÄ^{+}$\\n  within the nonrelativistic quark model In this work, we study the nonleptonic decays\\n$\\Xi_{cc}^{++}\\to\\Xi_{c}^{(\\prime)+}\\pi^{+}$ with considering\\n$\\Xi_{c}-\\Xi_{c}^{\\prime}$ mixing. The relevant decay amplitudes are evaluated\\nwithin the framework of nonrelativistic quark model, combining the baryon\\nspatial wave functions adopted from solving the Schr\\\"{o}dinger equation with a\\nnonrelativistic potential. With the mixing angle ranging\\n$\\theta\\in(-18.2^{\\circ},-14.3^{\\circ})$, we successfully reproduce the\\nmeasured ratio\\n$R=\\mathcal{B}[\\Xi_{cc}^{++}\\to\\Xi_{c}^{\\prime+}\\pi^{+}]/\\mathcal{B}[\\Xi_{cc}^{++}\\to\\Xi_{c}^{+}\\pi^{+}]$\\nreported by the LHCb Collaboration. Furthermore, we estimate the branching\\nfractions as $\\mathcal{B}[\\Xi_{cc}^{++}\\to\\Xi_{c}^{+}\\pi^{+}]=(3.36\\sim3.92)\\%$\\nand $\\mathcal{B}[\\Xi_{cc}^{++}\\to\\Xi_{c}^{\\prime+}\\pi^{+}]=(4.74\\sim5.40)\\%$,\\nand the asymmetry parameters as\\n$\\alpha[\\Xi_{cc}^{++}\\to\\Xi_{c}^{+}\\pi^{+}]=(-0.80\\sim-0.81)$ and\\n$\\alpha[\\Xi_{cc}^{++}\\to\\Xi_{c}^{\\prime+}\\pi^{+}]=(-0.61\\sim-0.62)$. The\\nmeasurements of absolute branching fractions and asymmetry parameters by the\\nongoing LHCb and Belle II experiments will be helpful for further testing our\\nnumerical results and confirming the mixing angle.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |hep-ph                            |hep-ph            |\n",
      "|http://arxiv.org/abs/2505.19759v1|Minimization of the expected first-passage time of a Brownian motion\\n  with Poissonian resetting We address the problem of minimizing the expected first-passage time of a\\nBrownian motion with Poissonian resetting, with respect to the resetting rate\\n$r.$ We consider both the one-boundary and the two-boundary cases.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |math.PR                           |math.PR           |\n",
      "|http://arxiv.org/abs/2505.19760v1|Navigating PESQ: Up-to-Date Versions and Open Implementations Perceptual Evaluation of Speech Quality (PESQ) is an objective quality\\nmeasure that remains widely used despite its withdrawal by the International\\nTelecommunication Union (ITU). PESQ has evolved over two decades, with multiple\\nversions and publicly available implementations emerging during this time. The\\nnumerous versions and their updates can be overwhelming, especially for new\\nPESQ users. This work provides practical guidance on the different versions and\\nimplementations of PESQ. We show that differences can be significant,\\nespecially between PESQ versions. We stress the importance of specifying the\\nexact version and implementation that is used to compute PESQ, and possibly to\\ndetail how multi-channel signals are handled. These practices would facilitate\\nthe interpretation of results and allow comparisons of PESQ scores between\\ndifferent studies. We also provide a repository that implements the latest\\ncorrections to PESQ, i.e., Corrigendum 2, which is not implemented by any other\\nopenly available distribution: https://github.com/audiolabs/PESQ.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |eess.AS                           |eess.AS           |\n",
      "|http://arxiv.org/abs/2505.19761v1|Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents\\n  via Offline Hierarchical Reinforcement Learning While showing sophisticated reasoning abilities, large language models (LLMs)\\nstill struggle with long-horizon decision-making tasks due to deficient\\nexploration and long-term credit assignment, especially in sparse-reward\\nscenarios. Inspired by the divide-and-conquer principle, we propose an\\ninnovative framework **GLIDER** (**G**rounding **L**anguage Models as\\nEff**I**cient **D**ecision-Making Agents via Offline Hi**E**rarchical\\n**R**einforcement Learning) that introduces a parameter-efficient and generally\\napplicable hierarchy to LLM policies. We develop a scheme where the low-level\\ncontroller is supervised with abstract, step-by-step plans that are learned and\\ninstructed by the high-level policy. This design decomposes complicated\\nproblems into a series of coherent chain-of-thought reasoning sub-tasks,\\nproviding flexible temporal abstraction to significantly enhance exploration\\nand learning for long-horizon tasks. Furthermore, GLIDER facilitates fast\\nonline adaptation to non-stationary environments owing to the strong\\ntransferability of its task-agnostic low-level skills. Experiments on\\nScienceWorld and ALFWorld benchmarks show that GLIDER achieves consistent\\nperformance gains, along with enhanced generalization capabilities.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.AI                             |cs.LG             |\n",
      "|http://arxiv.org/abs/2505.19762v1|Language Model-Enhanced Message Passing for Heterophilic Graph Learning Traditional graph neural networks (GNNs), which rely on homophily-driven\\nmessage passing, struggle with heterophilic graphs where connected nodes\\nexhibit dissimilar features and different labels. While existing methods\\naddress heterophily through graph structure refinement or adaptation of\\nneighbor aggregation functions, they often overlook the semantic potential of\\nnode text, rely on suboptimal message representation for propagation and\\ncompromise performance on homophilic graphs. To address these limitations, we\\npropose a novel language model (LM)-enhanced message passing approach for\\nheterophilic graph leaning (LEMP4HG). Specifically, in the context of\\ntext-attributed graph, we provide paired node texts for LM to generate their\\nconnection analysis, which are encoded and then fused with paired node textual\\nembeddings through a gating mechanism. The synthesized messages are\\nsemantically enriched and adaptively balanced with both nodes' information,\\nwhich mitigates contradictory signals when neighbor aggregation in heterophilic\\nregions. Furthermore, we introduce an active learning strategy guided by our\\nheuristic MVRD (Modulated Variation of Reliable Distance), selectively\\nenhancing node pairs suffer most from message passing, reducing the cost of\\nanalysis generation and side effects on homophilic regions. Extensive\\nexperiments validate that our approach excels on heterophilic graphs and\\nperforms robustly on homophilic ones, with a graph convolutional network (GCN)\\nbackbone and a practical budget.                                                                                                                                                                                                                                                                                           |cs.AI                             |cs.LG             |\n",
      "|http://arxiv.org/abs/2505.19763v1|Unfolding AlphaFold's Bayesian Roots in Probability Kinematics We present a novel theoretical interpretation of AlphaFold1. The seminal\\nbreakthrough of AlphaFold1 in protein structure prediction by deep learning\\nrelied on a learned potential energy function, in contrast to the later\\nend-to-end architectures of AlphaFold2 and AlphaFold3. While this potential was\\noriginally justified by referring to physical potentials of mean force (PMFs),\\nwe reinterpret AlphaFold1's potential as an instance of probability kinematics\\n- also known as Jeffrey conditioning - a principled but underrecognised\\ngeneralization of conventional Bayesian updating. Probability kinematics\\naccommodates uncertain or soft evidence in the form of updated probabilities\\nover a partition. This perspective reveals AlphaFold1's potential as a form of\\ngeneralized Bayesian updating, rather than a thermodynamic potential. To\\nconfirm our probabilistic framework's scope and precision, we analyze a\\nsynthetic 2D model in which an angular random walk prior is updated with\\nevidence on distances via probability kinematics, mirroring AlphaFold1's\\napproach. This theoretical contribution connects AlphaFold1 to a broader class\\nof well-justified Bayesian methods, allowing precise quantification, surpassing\\nmerely qualitative heuristics based on PMFs. More broadly, given the\\nachievements of AlphaFold1, probability kinematics holds considerable promise\\nfor probabilistic deep learning, as it allows for the formulation of complex\\nmodels from a few simpler components.                                                                                                                                                                                                                                                                                                                                                        |cs.LG                             |cs.LG             |\n",
      "|http://arxiv.org/abs/2505.19764v1|Agentic Predictor: Performance Prediction for Agentic Workflows via\\n  Multi-View Encoding Large language models (LLMs) have demonstrated remarkable capabilities across\\ndiverse tasks, but optimizing LLM-based agentic systems remains challenging due\\nto the vast search space of agent configurations, prompting strategies, and\\ncommunication patterns. Existing approaches often rely on heuristic-based\\ntuning or exhaustive evaluation, which can be computationally expensive and\\nsuboptimal. This paper proposes Agentic Predictor, a lightweight predictor for\\nefficient agentic workflow evaluation. Agentic Predictor is equipped with a\\nmulti-view workflow encoding technique that leverages multi-view representation\\nlearning of agentic systems by incorporating code architecture, textual\\nprompts, and interaction graph features. To achieve high predictive accuracy\\nwhile significantly reducing the number of required workflow evaluations for\\ntraining a predictor, Agentic Predictor employs cross-domain unsupervised\\npretraining. By learning to approximate task success rates, Agentic Predictor\\nenables fast and accurate selection of optimal agentic workflow configurations\\nfor a given task, significantly reducing the need for expensive trial-and-error\\nevaluations. Experiments on a carefully curated benchmark spanning three\\ndomains show that our predictor outperforms state-of-the-art methods in both\\npredictive accuracy and workflow utility, highlighting the potential of\\nperformance predictors in streamlining the design of LLM-based agentic\\nworkflows.                                                                                                                                                                                                                                                                                                                                        |cs.LG,cs.AI                       |cs.CL             |\n",
      "|http://arxiv.org/abs/2505.19765v1|On some coupled local and nonlocal diffusion models We study problems in which a local model is coupled with a nonlocal one. We\\npropose two energies: both of them are based on the same classical weighted\\n$H^1$-semi norm to model the local part, while two different weighted\\n$H^s$-semi norms, with $s \\in (0,1)$, are used to model the nonlocal part. The\\ncorresponding strong formulations are derived. In doing so, one needs to\\ndevelop some technical tools, such as suitable integration by parts formulas\\nfor operators with variable diffusivity, and one also needs to study the\\nmapping properties of the Neumann operators that arise. In contrast to problems\\ncoupling purely local models, in which one requires transmission conditions on\\nthe interface between the subdomains, the presence of a nonlocal operator may\\ngive rise to nonlocal fluxes. These nonlocal fluxes may enter the problem as a\\nsource term, thereby changing its structure. Finally, we focus on a specific\\nproblem, that we consider most relevant, and study regularity of solutions and\\nfinite element discretizations. We provide numerical experiments to illustrate\\nthe most salient features of the models.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |math.NA,cs.NA,math.AP             |math.AP           |\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-35-00.json\n",
      "\n",
      "========= 2025-05-29 21:35:10 =========\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------+------------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |true_label                              |pred              |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------+------------------+\n",
      "|http://arxiv.org/abs/2505.19771v1|A Cost-efficient Credit-Based Shaper Deployment Framework for\\n  Time-Sensitive Networks Time-sensitive networks are designed to meet stringent Quality of Service\\n(QoS) requirements for mixed-criticality traffic with diverse performance\\ndemands. Ensuring deterministic guarantees for such traffic while reducing\\ndeployment costs remains a significant challenge. This paper proposes a\\ncost-efficient partial deployment strategy for Time Sensitive Networking (TSN)\\ndevices within legacy Ethernet network. At the core of our approach is the\\nCredit-Based Shaper (CBS), a key TSN scheduling mechanism. Unlike\\ncost-prohibitive full CBS deployment, our approach selectively integrates CBS\\nwhere it is most needed to enhance performance while reducing costs. Combining\\nNetwork Calculus for schedulability verification and a heuristic optimization\\nmethod for CBS configuration and placement, our proposal minimizes deployment\\ncosts while improving schedulability for medium-priority traffic and mitigating\\nblocking delays for high-priority traffic. The feasibility and benefits of our\\napproach are validated on a realistic automotive TSN use case with up to 70% of\\nreduction in TSN devices requirements compared to a full deployment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |cs.NI                                   |cs.NI             |\n",
      "|http://arxiv.org/abs/2505.19772v1|Truncated Variational Hamiltonian Ansatz: efficient quantum circuit\\n  design for quantum chemistry and material science Quantum computing has the potential to revolutionize quantum chemistry and\\nmaterial science by offering solutions to complex problems unattainable with\\nclassical computers. However, the development of efficient quantum algorithms\\nthat are efficient under noisy conditions remains a major challenge. This paper\\nintroduces the truncated Variational Hamiltonian Ansatz (tVHA), a novel circuit\\ndesign for conducting quantum calculations on Noisy Intermediate-Scale Quantum\\n(NISQ) devices. tVHA provides a promising approach for a broad range of\\napplications by utilizing principles from the adiabatic theorem in solid state\\nphysics. Our proposed ansatz significantly reduces the parameter count and can\\ndecrease circuit size substantially, with a trade-off in accuracy. Thus, tVHA\\nfacilitates easier convergence within the variational quantum eigensolver\\nframework compared to state-of-the-art ans\\\"atze such as Unitary Coupled\\nCluster (UCC) and Hardware-Efficient Ansatz (HEA). While this paper\\nconcentrates on the practical applications of tVHA in quantum chemistry,\\ndemonstrating its suitability for both weakly and strongly correlated systems\\nand its compatibility with active space calculations, its underlying principles\\nsuggest a wider applicability extending to the broader field of material\\nscience computations on quantum computing platforms.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |quant-ph,physics.chem-ph,physics.comp-ph|quant-ph          |\n",
      "|http://arxiv.org/abs/2505.19773v1|What Really Matters in Many-Shot Attacks? An Empirical Study of\\n  Long-Context Vulnerabilities in LLMs We investigate long-context vulnerabilities in Large Language Models (LLMs)\\nthrough Many-Shot Jailbreaking (MSJ). Our experiments utilize context length of\\nup to 128K tokens. Through comprehensive analysis with various many-shot attack\\nsettings with different instruction styles, shot density, topic, and format, we\\nreveal that context length is the primary factor determining attack\\neffectiveness. Critically, we find that successful attacks do not require\\ncarefully crafted harmful content. Even repetitive shots or random dummy text\\ncan circumvent model safety measures, suggesting fundamental limitations in\\nlong-context processing capabilities of LLMs. The safety behavior of\\nwell-aligned models becomes increasingly inconsistent with longer contexts.\\nThese findings highlight significant safety gaps in context expansion\\ncapabilities of LLMs, emphasizing the need for new safety mechanisms.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |cs.CL,cs.CR                             |cs.CL             |\n",
      "|http://arxiv.org/abs/2505.19774v1|DuRep: Dual-Mode Speech Representation Learning via ASR-Aware\\n  Distillation Recent advancements in speech encoders have drawn attention due to their\\nintegration with Large Language Models for various speech tasks. While most\\nresearch has focused on either causal or full-context speech encoders, there's\\nlimited exploration to effectively handle both streaming and non-streaming\\napplications, while achieving state-of-the-art performance. We introduce DuRep,\\na Dual-mode Speech Representation learning setup, which enables a single speech\\nencoder to function efficiently in both offline and online modes without\\nadditional parameters or mode-specific adjustments, across downstream tasks.\\nDuRep-200M, our 200M parameter dual-mode encoder, achieves 12% and 11.6%\\nimprovements in streaming and non-streaming modes, over baseline encoders on\\nMultilingual ASR. Scaling this approach to 2B parameters, DuRep-2B sets new\\nperformance benchmarks across ASR and non-ASR tasks. Our analysis reveals\\ninteresting trade-offs between acoustic and semantic information across encoder\\nlayers.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |eess.AS                                 |cs.SD             |\n",
      "|http://arxiv.org/abs/2505.19775v1|$Œ∑$ and $Œ∑'$ mesons from $N_f = 2+1$ lattice QCD at the physical\\n  point using topological charge operators By fitting the two-point correlation functions of topological charge density\\noperators calculated on two $2+1$-flavor gauge ensembles with physical pion\\nmass, we determine both the $\\eta$ and $\\eta'$ masses and also the mixing angle\\nto be $m_\\eta = 0.522(27)(22)$ GeV, $m_{\\eta'}=0.970(56)(17)$ GeV, and\\n$\\theta_1 = -10.7(1.4)(0.2)^\\circ$, respectively, where the first error is the\\nstatistical uncertainty and the second one is the systematic uncertainty of\\nlattice discretization effects. This is the first extraction of both\\n$\\eta/\\eta'$ masses and the mixing angle $\\theta_1$ using topological charge\\noperators. Compared with previous studies using quark bilinear operators, the\\nerror of the $\\eta$ mass is relatively large, but the mixing angle has\\nremarkably high precision. This demonstrates that the topological charge\\noperators are well suited to study the $\\eta$ and $\\eta'$ mesons.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |hep-lat                                 |hep-lat           |\n",
      "|http://arxiv.org/abs/2505.19776v1|Analyzing Political Bias in LLMs via Target-Oriented Sentiment\\n  Classification Political biases encoded by LLMs might have detrimental effects on downstream\\napplications. Existing bias analysis methods rely on small-size intermediate\\ntasks (questionnaire answering or political content generation) and rely on the\\nLLMs themselves for analysis, thus propagating bias. We propose a new approach\\nleveraging the observation that LLM sentiment predictions vary with the target\\nentity in the same sentence. We define an entropy-based inconsistency metric to\\nencode this prediction variability. We insert 1319 demographically and\\npolitically diverse politician names in 450 political sentences and predict\\ntarget-oriented sentiment using seven models in six widely spoken languages. We\\nobserve inconsistencies in all tested combinations and aggregate them in a\\nstatistically robust analysis at different granularity levels. We observe\\npositive and negative bias toward left and far-right politicians and positive\\ncorrelations between politicians with similar alignment. Bias intensity is\\nhigher for Western languages than for others. Larger models exhibit stronger\\nand more consistent biases and reduce discrepancies between similar languages.\\nWe partially mitigate LLM unreliability in target-oriented sentiment\\nclassification (TSC) by replacing politician names with fictional but plausible\\ncounterparts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.CL,cs.AI                             |cs.CL             |\n",
      "|http://arxiv.org/abs/2505.19777v1|MuGrid-v2: A novel scintillator detector for multidisciplinary\\n  applications Muography, traditionally recognized as a potent instrument for imaging the\\ninternal structure of gigantic objects, has initialized various\\ninterdisciplinary applications. As the financial and labor costs of muography\\ndetector development hinder their massive applications, we develop a novel muon\\ndetector called MuGrid by coupling a monolithic plastic scintillator with the\\nlight guide array in order to achieve competitive spatial resolution while\\nsubstantially reducing production costs. For a prototype detector in 30 cm\\n$\\times$ 30 cm, the intrinsic spatial resolution has been optimized toward a\\nmillimeter scale. An outdoor field muography experiment was conducted to\\nmonitor two buildings for validation purposes. The test successfully resolved\\nthe geometric influence of architectural features based on the attenuation of\\nmuon flux in a good agreement between experimental results and the simulation\\nprediction.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |physics.ins-det,hep-ex                  |physics.ins-det   |\n",
      "|http://arxiv.org/abs/2505.19778v1|Giant spontaneous polarization in zincblende III-V semiconductors The discovery of ferroelectricity in wurtzite nitrides has paved the way for\\nmeasuring and understanding spontaneous polarization in III-V semiconductors.\\nHowever, the calculation of polarization effects at heterointerfaces - crucial\\nfor numerous electronic and photonic applications - remains a topic of debate.\\nThe need for a reference structure to calculate spontaneous polarization has\\nled to discussions over whether to use the zincblende or layered hexagonal\\nstructures as the reference for wurtzite crystals. In this work, we argue that\\nthe layered hexagonal structure is not only a better reference due to its\\nvanishing formal polarization but also the only physically correct choice for\\nthe wurtzite system. This follows from the fact that spontaneous polarization\\nis rigorously defined through the ferroelectric switching. Applying this\\ndefinition, we extend our analysis to III-V zincblende semiconductors and\\nreveal that their spontaneous polarization is approximately three times larger\\nthan that of wurtzite, thereby refuting the longstanding assumption that it is\\nzero. Through this example, we illustrate that spontaneous polarization is not\\ninherently linked to charge density at interfaces.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |cond-mat.mtrl-sci                       |cond-mat.mtrl-sci |\n",
      "|http://arxiv.org/abs/2505.19779v1|Advancements in Medical Image Classification through Fine-Tuning Natural\\n  Domain Foundation Models Using massive datasets, foundation models are large-scale, pre-trained models\\nthat perform a wide range of tasks. These models have shown consistently\\nimproved results with the introduction of new methods. It is crucial to analyze\\nhow these trends impact the medical field and determine whether these\\nadvancements can drive meaningful change. This study investigates the\\napplication of recent state-of-the-art foundation models, DINOv2, MAE, VMamba,\\nCoCa, SAM2, and AIMv2, for medical image classification. We explore their\\neffectiveness on datasets including CBIS-DDSM for mammography, ISIC2019 for\\nskin lesions, APTOS2019 for diabetic retinopathy, and CHEXPERT for chest\\nradiographs. By fine-tuning these models and evaluating their configurations,\\nwe aim to understand the potential of these advancements in medical image\\nclassification. The results indicate that these advanced models significantly\\nenhance classification outcomes, demonstrating robust performance despite\\nlimited labeled data. Based on our results, AIMv2, DINOv2, and SAM2 models\\noutperformed others, demonstrating that progress in natural domain training has\\npositively impacted the medical domain and improved classification outcomes.\\nOur code is publicly available at:\\nhttps://github.com/sajjad-sh33/Medical-Transfer-Learning.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |eess.IV,cs.CV,cs.LG                     |cs.CV             |\n",
      "|http://arxiv.org/abs/2505.19780v1|A pseudometric on $\\mathcal{M}(X,\\mathscr{A})$ induced by a measure For a probability measure space $(X,\\mathscr{A},\\mu)$, we define a\\npseudometric $\\delta$ on the ring $\\mathcal{M}(X,\\mathscr{A})$ of real-valued\\nmeasurable functions on $X$ as $\\delta(f,g)=\\mu(X\\setminus Z(f-g))$ and denote\\nthe topological space induced by $\\delta$ as $\\mathcal{M}_\\delta$. We examine\\nseveral topological properties, such as connectedness, compactness,\\nLindel\\\"{o}fness, separability and second countability of this pseudometric\\nspace. We realise that the space is connected if and only if $\\mu$ is a\\nnon-atomic measure and we explicitly describe the components in\\n$\\mathcal{M}_\\delta$, for any choice of measure. We also deduce that\\n$\\mathcal{M}_\\delta$ is zero-dimensional if and only if $\\mu$ is purely atomic.\\nWe define $\\mu$ to be bounded away from zero, if every non-zero measurable set\\nhas measure greater than some constant. We establish several conditions\\nequivalent to $\\mu$ being bounded away from zero. For instance, $\\mu$ is\\nbounded away from zero if and only if $\\mathcal{M}_\\delta$ is a locally compact\\nspace. We conclude this article by describing the structure of compact sets and\\nLindel\\\"{o}f sets in $\\mathcal{M}_\\delta$.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |math.GN                                 |math.GN           |\n",
      "|http://arxiv.org/abs/2505.19781v1|Deep learning based spatial aliasing reduction in beamforming for audio\\n  capture Spatial aliasing affects spaced microphone arrays, causing directional\\nambiguity above certain frequencies, degrading spatial and spectral accuracy of\\nbeamformers. Given the limitations of conventional signal processing and the\\nscarcity of deep learning approaches to spatial aliasing mitigation, we propose\\na novel approach using a U-Net architecture to predict a signal-dependent\\nde-aliasing filter, which reduces aliasing in conventional beamforming for\\nspatial capture. Two types of multichannel filters are considered, one which\\ntreats the channels independently and a second one that models cross-channel\\ndependencies. The proposed approach is evaluated in two common spatial capture\\nscenarios: stereo and first-order Ambisonics. The results indicate a very\\nsignificant improvement, both objective and perceptual, with respect to\\nconventional beamforming. This work shows the potential of deep learning to\\nreduce aliasing in beamforming, leading to improvements in multi-microphone\\nsetups.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |eess.AS,cs.SD                           |eess.AS           |\n",
      "|http://arxiv.org/abs/2505.19782v1|Collapse and Burst of generalized Surface Quasi-Geostrophic point\\n  Vortices We consider the generalized Surface Quasi-Geostrophic point vortices\\ndynamics, and identify a sufficient condition implying existence of bursts out\\nof (and collapses into) any given initial configuration of vortices. The\\ncondition is related to the stability of the linearized dynamics around three\\nvortices evolving in a self-similar fashion.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |math.CA                                 |math.DS           |\n",
      "|http://arxiv.org/abs/2505.19783v1|On the asymptotic scaling of the von Neumann entropy in quasifree\\n  fermionic right mover/left mover systems For the general class of quasifree fermionic right mover/left mover systems\\nover the infinitely extended two-sided discrete line introduced in [8] within\\nthe algebraic framework of quantum statistical mechanics, we study the von\\nNeumann entropy of a contiguous subsystem of finite length in interaction with\\nits environment. In particular, under the assumption of spatial translation\\ninvariance, we analyze the asymptotic behavior of the von Neumann entropy for\\nlarge subsystem lengths and prove that its leading order density is, in\\ngeneral, nonvanishing and displays the signature of a mixture of the\\nindependent thermal species underlying the right mover/left mover system. As\\nspecial cases, the formalism covers so-called nonequilibrium steady states,\\nthermal equilibrium states, and ground states. Moreover, for general Fermi\\nfunctions, we derive a necessary and sufficient criterion for the von Neumann\\nentropy density to vanish.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |math-ph,cond-mat.stat-mech,math.MP      |cond-mat.stat-mech|\n",
      "|http://arxiv.org/abs/2505.19784v1|Do multifrequency polarimetric observations of BL Lac exclude a hadronic\\n  origin of its X-ray emission? Recent multifrequency polarimetric observations of the eponymous blazar BL\\nLac reveal an extremely large degree of polarization in the optical band\\n(average of $25\\%$, reaching $45\\%$), together with a small ($\\lesssim 7\\%$)\\ndegree of polarization in the X-ray band. This has been interpreted as evidence\\nthat the X-rays are produced through inverse Compton emission by relativistic\\nelectrons, thus ruling out alternative models based on hadronic processes. Here\\nwe revisit the observational evidence, interpreting it in a framework where the\\nobserved radiation is entirely produced through synchrotron emission. Electrons\\nproduce the radio-to-optical component and protons produce the X-rays and the\\ngamma-rays. We determine the jet magnetic fields from an MHD model of\\nmagnetically dominated stationary axisymmetric outflows, and show that the\\nX-ray emission from the protons is naturally less polarized than the optical\\nemission from the electrons. The model parameters required to reproduce the\\nmultifrequency polarimetric observations are fully compatible with blazar jets.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |astro-ph.HE                             |astro-ph.HE       |\n",
      "|http://arxiv.org/abs/2505.19785v1|MedDreamer: Model-Based Reinforcement Learning with Latent Imagination\\n  on Complex EHRs for Clinical Decision Support Timely and personalized treatment decisions are essential across a wide range\\nof healthcare settings where patient responses vary significantly and evolve\\nover time. Clinical data used to support these decisions are often irregularly\\nsampled, sparse, and noisy. Existing decision support systems commonly rely on\\ndiscretization and imputation, which can distort critical temporal dynamics and\\ndegrade decision quality. Moreover, they often overlook the clinical\\nsignificance of irregular recording frequencies, filtering out patterns in how\\nand when data is collected. Reinforcement Learning (RL) is a natural fit for\\nclinical decision-making, enabling sequential, long-term optimization in\\ndynamic, uncertain environments. However, most existing treatment\\nrecommendation systems are model-free and trained solely on offline data,\\nmaking them sample-inefficient, sensitive to data quality, and poorly\\ngeneralizable across tasks or cohorts. To address these limitations, we propose\\nMedDreamer, a two-phase model-based RL framework for personalized treatment\\nrecommendation. MedDreamer uses a world model with an Adaptive Feature\\nIntegration (AFI) module to effectively model irregular, sparse clinical data.\\nThrough latent imagination, it simulates plausible patient trajectories to\\nenhance learning, refining its policy using a mix of real and imagined\\nexperiences. This enables learning policies that go beyond suboptimal\\nhistorical decisions while remaining grounded in clinical data. To our\\nknowledge, this is the first application of latent imagination to irregular\\nhealthcare data. Evaluations on sepsis and mechanical ventilation (MV)\\ntreatment using two large-scale EHR datasets show that MedDreamer outperforms\\nboth model-free and model-based baselines in clinical outcomes and off-policy\\nmetrics.                                                 |cs.LG,cs.AI                             |cs.LG             |\n",
      "|http://arxiv.org/abs/2505.19786v1|Numerical Periodic Normalization at Codim 1 Bifurcations of Limit Cycles\\n  in DDEs Recent work in [53, 54] by the authors on periodic center manifolds and\\nnormal forms for bifurcations of limit cycles in delay differential equations\\n(DDEs) motivates the derivation of explicit computational formulas for the\\ncritical normal form coefficients of all codimension one bifurcations of limit\\ncycles. In this paper, we derive such formulas via an application of the\\nperiodic normalization method in combination with the functional analytic\\nperturbation framework for dual semigroups (sun-star calculus). The explicit\\nformulas allow us to distinguish between nondegenerate, sub- and supercritical\\nbifurcations. To efficiently apply these formulas, we introduce the\\ncharacteristic operator as this enables us to use robust numerical\\nboundary-value algorithms based on orthogonal collocation. Although our\\ntheoretical results are proven in a more general setting, the software\\nimplementation and examples focus on discrete DDEs. The actual implementation\\nis described in detail and its effectiveness is demonstrated on various models.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |math.DS,math.FA                         |math.DS           |\n",
      "|http://arxiv.org/abs/2505.19787v1|Distribution Dependent SDEs with Singular Interactions: Well-Posedness\\n  and Regularity For a class of distribution dependent SDEs with singular interactions, which\\ninclude the Coulomb/Riesz/Biot-Savart kernels as typical examples (Examples 2.1\\nand 2.2), we derive the well-posedness and regularity estimates by establishing\\nthe entropy-cost inequality. To measure the singularity of interactions, we\\nintroduce a new probability distance induced by local integrable functions, and\\nestimate this distance for the time-marginal laws of solutions by using the\\nWasserstein distance of initial distributions. A key point of the study is to\\ncharacterize the path space of time-marginal distributions for the solutions,\\nby using local hyperbound estimates on diffusion semigroups.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |math.PR                                 |math.PR           |\n",
      "|http://arxiv.org/abs/2505.19788v1|Done Is Better than Perfect: Unlocking Efficient Reasoning by Structured\\n  Multi-Turn Decomposition Large Reasoning Models (LRMs) are criticized for the excessively lengthy\\nChain-of-Thought (CoT) to derive the final answer, suffering from high\\nfirst-token and overall latency. Typically, the CoT of LRMs mixes multiple\\nthinking units; each unit attempts to produce a candidate answer to the\\noriginal query. Hence, a natural idea to improve efficiency is to reduce the\\nunit number. Yet, the fact that the thinking units in vanilla CoT cannot be\\nexplicitly managed renders doing so challenging. This paper introduces\\nMulti-Turn Decomposition (MinD) to decode conventional CoT into a sequence of\\nexplicit, structured, and turn-wise interactions to bridge the gap. In MinD,\\nthe model provides a multi-turn response to the query, where each turn embraces\\na thinking unit and yields a corresponding answer. The subsequent turns can\\nreflect, verify, revise, or explore alternative approaches to both the thinking\\nand answer parts of earlier ones. This not only makes the answer delivered more\\nswiftly, but also enables explicit controls over the iterative reasoning\\nprocess (i.e., users may halt or continue at any turn). We follow a supervised\\nfine-tuning (SFT) then reinforcement learning (RL) paradigm to realize MinD. We\\nfirst rephrase the outputs of an LRM into multi-turn formats by prompting\\nanother LLM, and then tune the LRM with such data. Observing that the tuned\\nmodel tends to consume even more tokens than the original one (probably due to\\nthat the multi-turn formats introduce additional answer tokens), we advocate\\nleveraging RL algorithms like GRPO to prioritize correct outputs with fewer\\nturns. Trained on the MATH dataset using R1-Distill models, MinD can achieve up\\nto ~70% reduction in both output token usage and time to first token (TTFT),\\nwhile maintaining competitive performance on reasoning benchmarks such as\\nMATH-500, AIME24, AMC23, and GPQA-Diamond.|cs.AI                                   |cs.CL             |\n",
      "|http://arxiv.org/abs/2505.19789v1|What Can RL Bring to VLA Generalization? An Empirical Study Large Vision-Language Action (VLA) models have shown significant potential\\nfor embodied AI. However, their predominant training via supervised fine-tuning\\n(SFT) limits generalization due to susceptibility to compounding errors under\\ndistribution shifts. Reinforcement learning (RL) offers a path to overcome\\nthese limitations by optimizing for task objectives via trial-and-error, yet a\\nsystematic understanding of its specific generalization benefits for VLAs\\ncompared to SFT is lacking. To address this, our study introduces a\\ncomprehensive benchmark for evaluating VLA generalization and systematically\\ninvestigates the impact of RL fine-tuning across diverse visual, semantic, and\\nexecution dimensions. Our extensive experiments reveal that RL fine-tuning,\\nparticularly with PPO, significantly enhances generalization in semantic\\nunderstanding and execution robustness over SFT, while maintaining comparable\\nvisual robustness. We identify PPO as a more effective RL algorithm for VLAs\\nthan LLM-derived methods like DPO and GRPO. We also develop a simple recipe for\\nefficient PPO training on VLAs, and demonstrate its practical utility for\\nimproving VLA generalization. The project page is at https://rlvla.github.io                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.LG                                   |cs.LG             |\n",
      "|http://arxiv.org/abs/2505.19790v1|Alpay Algebra III: Observer-Coupled Collapse and the Temporal Drift of\\n  Identity This paper introduces a formal framework for modeling observer-dependent\\ncollapse dynamics and temporal identity drift within artificial and\\nmathematical systems, grounded entirely in the symbolic foundations of Alpay\\nAlgebra. Building upon the fixed-point emergence structures developed in Alpay\\nAlgebra I and II, this third installment formalizes the observer-coupled\\n{\\phi}-collapse process through transfinite categorical flows and\\ncurvature-driven identity operators. We define a novel temporal drift mechanism\\nas a recursive deformation of identity signatures under entangled observer\\ninfluence, constructing categorical invariants that evolve across fold\\niterations. The proposed system surpasses conventional identity modeling in\\nexplainable AI (XAI) by encoding internal transformation history into a\\nsymbolic fixed-point structure, offering provable traceability and temporal\\ncoherence. Applications range from AI self-awareness architectures to formal\\nlogic systems where identity is not static but dynamically induced by\\nobservation. The theoretical results also offer a mathematically rigorous basis\\nfor future AI systems with stable self-referential behavior, positioning Alpay\\nAlgebra as a next-generation symbolic framework bridging category theory,\\nidentity logic, and observer dynamics.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |math.CT,cs.AI,cs.LO                     |cs.AI             |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-35-10.json\n",
      "\n",
      "========= 2025-05-29 21:35:20 =========\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+---------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |true_label                   |pred           |\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+---------------+\n",
      "|http://arxiv.org/abs/2505.19796v1|A Topological Perspective on the Birch and Swinnerton Dyer Conjectures This paper presents a topological framework for investigating the Birch and\\nSwinnerton Dyer conjecture through four dimensional embeddings of elliptic\\ncurves. We propose a correspondence between the algebraic rank of an elliptic\\ncurve and the number of topologically independent loops in its embedding, which\\nappears to be related to the order of vanishing of its L function at s=1. Our\\ncomputational function F new and its generalization F_(m,s) provide methods for\\nexamining this relationship through asymptotic analysis. Examples with rank\\ncurves from 0 to 8 show patterns supporting this correspondence. The approach\\nconnects with established frameworks, including the Kolyvagin Flach machinery\\nand the Gross Zagier formula, potentially offering new perspectives on this\\nsignificant open problem in number theory.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |math.GM                      |math.NT        |\n",
      "|http://arxiv.org/abs/2505.19797v1|The Avengers: A Simple Recipe for Uniting Smaller Language Models to\\n  Challenge Proprietary Giants As proprietary giants increasingly dominate the race for ever-larger language\\nmodels, a pressing question arises for the open-source community: can smaller\\nmodels remain competitive across a broad range of tasks? In this paper, we\\npresent the Avengers--a simple recipe that effectively leverages the collective\\nintelligence of open-source, smaller language models. Our framework is built\\nupon four lightweight operations: (i) embedding: encode queries using a text\\nembedding model; (ii) clustering: group queries based on their semantic\\nsimilarity; (iii) scoring: scores each model's performance within each cluster;\\nand (iv) voting: improve outputs via repeated sampling and voting. At inference\\ntime, each query is embedded and assigned to its nearest cluster. The\\ntop-performing model(s) within that cluster are selected to generate the\\nresponse using the Self-Consistency or its multi-model variant. Remarkably,\\nwith 10 open-source models (~7B parameters each), the Avengers collectively\\noutperforms GPT-4.1 on 10 out of 15 datasets (spanning mathematics, code,\\nlogic, knowledge, and affective tasks). In particular, it surpasses GPT-4.1 on\\nmathematics tasks by 18.21% and on code tasks by 7.46%. Furthermore, the\\nAvengers delivers superior out-of-distribution generalization, and remains\\nrobust across various embedding models, clustering algorithms, ensemble\\nstrategies, and values of its sole parameter--the number of clusters. We have\\nopen-sourced the code on GitHub: https://github.com/ZhangYiqun018/Avengers                                                                                                                                                                                                                                                                                                                                                                                                                                |cs.CL                        |cs.CL          |\n",
      "|http://arxiv.org/abs/2505.19798v1|Challenges and perspectives in using multimodal imaging techniques to\\n  advance the understanding of fish intestinal microvilli The primary function of intestinal microvilli is to increase the surface area\\nof the intestinal lining to maximize nutrient absorption. Despite its\\nimportance to the fish health, the small size and dense footprint of microvilli\\nhinders its investigation and necessitates the need of advanced microscopy\\nmethods for its visualization. Characterization of the microvilli using\\nsuper-resolution microscopy provides insights into their structural\\norganization, spatial distribution, and surface properties. Here, we present a\\ncomprehensive investigation of different optical, electron and force microscopy\\nmethods for analysis of fish microvilli. The super-resolution optical\\nmicroscopy methods used are 3D structured illumination microscopy (SIM),\\nstimulated emission depletion microscopy (STED), and fluorescence fluctuation\\nmicroscopy. We also visualized the intestinal microvilli in fish using\\ndiffraction-limited optical microscopy methods including confocal and total\\ninternal reflection fluorescence microscopy. Additionally, label-free\\nmicroscopy methods, such as quantitative phase microscopy (QPM) and\\nbright-field imaging, were also employed. To obtain ultra-high resolution, we\\nused scanning electron microscopy (SEM), transmission electron microscopy (TEM)\\nand atomic force microscopy (AFM). We demonstrate a systematic comparison of\\nthese microscopy techniques in resolving and quantifying microvilli features,\\nranging from 1-2 {\\mu}m structural morphology to 10-100 nm surface details. Our\\nresults highlight the advantages, limitations, and complementary nature of each\\nmethod in capturing microvilli characteristics across different scales. These\\ntechniques are used for super-resolution and high-resolution imaging of\\nAtlantic salmon microvilli gastrointestinal tract.                                                                                                                        |physics.optics,physics.med-ph|physics.optics |\n",
      "|http://arxiv.org/abs/2505.19799v1|A Regularization-Guided Equivariant Approach for Image Restoration Equivariant and invariant deep learning models have been developed to exploit\\nintrinsic symmetries in data, demonstrating significant effectiveness in\\ncertain scenarios. However, these methods often suffer from limited\\nrepresentation accuracy and rely on strict symmetry assumptions that may not\\nhold in practice. These limitations pose a significant drawback for image\\nrestoration tasks, which demands high accuracy and precise symmetry\\nrepresentation. To address these challenges, we propose a rotation-equivariant\\nregularization strategy that adaptively enforces the appropriate symmetry\\nconstraints on the data while preserving the network's representational\\naccuracy. Specifically, we introduce EQ-Reg, a regularizer designed to enhance\\nrotation equivariance, which innovatively extends the insights of\\ndata-augmentation-based and equivariant-based methodologies. This is achieved\\nthrough self-supervised learning and the spatial rotation and cyclic channel\\nshift of feature maps deduce in the equivariant framework. Our approach firstly\\nenables a non-strictly equivariant network suitable for image restoration,\\nproviding a simple and adaptive mechanism for adjusting equivariance based on\\ntask. Extensive experiments across three low-level tasks demonstrate the\\nsuperior accuracy and generalization capability of our method, outperforming\\nstate-of-the-art approaches.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CV                        |cs.CV          |\n",
      "|http://arxiv.org/abs/2505.19800v1|MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs Metadata extraction is essential for cataloging and preserving datasets,\\nenabling effective research discovery and reproducibility, especially given the\\ncurrent exponential growth in scientific research. While Masader (Alyafeai et\\nal.,2021) laid the groundwork for extracting a wide range of metadata\\nattributes from Arabic NLP datasets' scholarly articles, it relies heavily on\\nmanual annotation. In this paper, we present MOLE, a framework that leverages\\nLarge Language Models (LLMs) to automatically extract metadata attributes from\\nscientific papers covering datasets of languages other than Arabic. Our\\nschema-driven methodology processes entire documents across multiple input\\nformats and incorporates robust validation mechanisms for consistent output.\\nAdditionally, we introduce a new benchmark to evaluate the research progress on\\nthis task. Through systematic analysis of context length, few-shot learning,\\nand web browsing integration, we demonstrate that modern LLMs show promising\\nresults in automating this task, highlighting the need for further future work\\nimprovements to ensure consistent and reliable performance. We release the\\ncode: https://github.com/IVUL-KAUST/MOLE and dataset:\\nhttps://huggingface.co/datasets/IVUL-KAUST/MOLE for the research community.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.CL                        |cs.CL          |\n",
      "|http://arxiv.org/abs/2505.19801v1|Convergence Analysis of Adaptive Finite Element Algorithms for a\\n  Regularized Variational Model of Quasi-Static Brittle Fracture in\\n  \"Strain-Limiting\" Elastic Solids The rigorous convergence analysis of adaptive finite element methods for\\nregularized variational models of quasi-static brittle fracture in\\nstrain-limiting elastic solids is presented. This work introduces two novel\\nadaptive mesh refinement algorithms, based on robust local error indicators,\\ndesigned to solve the underlying energy minimization problem efficiently. A\\ncomprehensive convergence analysis is provided for minimizer sequences\\ngenerated by these distinct adaptive strategies. It is rigorously demonstrated\\nthat sequences from the first algorithm converge to a prescribed tolerance.\\nNotably, the second algorithm is proven to yield inherently convergent\\nsequences without requiring an explicit stopping criterion. The practical\\nefficacy of the proposed adaptive framework is validated through extensive\\nnumerical simulations, where critical comparisons of energy components (bulk,\\nsurface, and total) demonstrate the performance of the two adaptive algorithms\\nin the case of an edge crack in a strain-limiting solid subjected to anti-plane\\nshear-type loading.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |math.NA,cs.NA                |math.NA        |\n",
      "|http://arxiv.org/abs/2505.19802v1|GraphAU-Pain: Graph-based Action Unit Representation for Pain Intensity\\n  Estimation Understanding pain-related facial behaviors is essential for digital\\nhealthcare in terms of effective monitoring, assisted diagnostics, and\\ntreatment planning, particularly for patients unable to communicate verbally.\\nExisting data-driven methods of detecting pain from facial expressions are\\nlimited due to interpretability and severity quantification. To this end, we\\npropose GraphAU-Pain, leveraging a graph-based framework to model facial Action\\nUnits (AUs) and their interrelationships for pain intensity estimation. AUs are\\nrepresented as graph nodes, with co-occurrence relationships as edges, enabling\\na more expressive depiction of pain-related facial behaviors. By utilizing a\\nrelational graph neural network, our framework offers improved interpretability\\nand significant performance gains. Experiments conducted on the publicly\\navailable UNBC dataset demonstrate the effectiveness of the GraphAU-Pain,\\nachieving an F1-score of 66.21% and accuracy of 87.61% in pain intensity\\nestimation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |cs.LG,cs.CV                  |cs.LG          |\n",
      "|http://arxiv.org/abs/2505.19803v1|Integrating emotional intelligence, memory architecture, and gestures to\\n  achieve empathetic humanoid robot interaction in an educational setting This study investigates the integration of individual human traits into an\\nempathetically adaptive educational robot tutor system designed to improve\\nstudent engagement and learning outcomes with corresponding Engagement Vector\\nmeasurement. While prior research in the field of Human-Robot Interaction (HRI)\\nhas examined the integration of the traits, such as emotional intelligence,\\nmemory-driven personalization, and non-verbal communication, by themselves,\\nthey have thus-far neglected to consider their synchronized integration into a\\ncohesive, operational education framework. To address this gap, we customize a\\nMulti-Modal Large Language Model (LLaMa 3.2 from Meta) deployed with modules\\nfor human-like traits (emotion, memory and gestures) into an AI-Agent\\nframework. This constitutes to the robot's intelligent core mimicing the human\\nemotional system, memory architecture and gesture control to allow the robot to\\nbehave more empathetically while recognizing and responding appropriately to\\nthe student's emotional state. It can also recall the student's past learning\\nrecord and adapt its style of interaction accordingly. This allows the robot\\ntutor to react to the student in a more sympathetic manner by delivering\\npersonalized verbal feedback synchronized with relevant gestures. Our study\\ninvestigates the extent of this effect through the introduction of Engagement\\nVector Model which can be a surveyor's pole for judging the quality of HRI\\nexperience. Quantitative and qualitative results demonstrate that such an\\nempathetic responsive approach significantly improves student engagement and\\nlearning outcomes compared with a baseline humanoid robot without these\\nhuman-like traits. This indicates that robot tutors with empathetic\\ncapabilities can create a more supportive, interactive learning experience that\\nultimately leads to better outcomes for the student.|cs.RO                        |cs.HC          |\n",
      "|http://arxiv.org/abs/2505.19804v1|Compliance-to-Code: Enhancing Financial Compliance Checking via Code\\n  Generation Nowadays, regulatory compliance has become a cornerstone of corporate\\ngovernance, ensuring adherence to systematic legal frameworks. At its core,\\nfinancial regulations often comprise highly intricate provisions, layered\\nlogical structures, and numerous exceptions, which inevitably result in\\nlabor-intensive or comprehension challenges. To mitigate this, recent\\nRegulatory Technology (RegTech) and Large Language Models (LLMs) have gained\\nsignificant attention in automating the conversion of regulatory text into\\nexecutable compliance logic. However, their performance remains suboptimal\\nparticularly when applied to Chinese-language financial regulations, due to\\nthree key limitations: (1) incomplete domain-specific knowledge representation,\\n(2) insufficient hierarchical reasoning capabilities, and (3) failure to\\nmaintain temporal and logical coherence. One promising solution is to develop a\\ndomain specific and code-oriented datasets for model training. Existing\\ndatasets such as LexGLUE, LegalBench, and CODE-ACCORD are often\\nEnglish-focused, domain-mismatched, or lack fine-grained granularity for\\ncompliance code generation. To fill these gaps, we present Compliance-to-Code,\\nthe first large-scale Chinese dataset dedicated to financial regulatory\\ncompliance. Covering 1,159 annotated clauses from 361 regulations across ten\\ncategories, each clause is modularly structured with four logical\\nelements-subject, condition, constraint, and contextual information-along with\\nregulation relations. We provide deterministic Python code mappings, detailed\\ncode reasoning, and code explanations to facilitate automated auditing. To\\ndemonstrate utility, we present FinCheck: a pipeline for regulation\\nstructuring, code generation, and report generation.                                                                                                                                                                                                  |cs.CL                        |cs.CL          |\n",
      "|http://arxiv.org/abs/2505.19805v1|Translation-Equivariance of Normalization Layers and Aliasing in\\n  Convolutional Neural Networks The design of convolutional neural architectures that are exactly equivariant\\nto continuous translations is an active field of research. It promises to\\nbenefit scientific computing, notably by making existing imaging systems more\\nphysically accurate. Most efforts focus on the design of downsampling/pooling\\nlayers, upsampling layers and activation functions, but little attention is\\ndedicated to normalization layers. In this work, we present a novel theoretical\\nframework for understanding the equivariance of normalization layers to\\ndiscrete shifts and continuous translations. We also determine necessary and\\nsufficient conditions for normalization layers to be equivariant in terms of\\nthe dimensions they operate on. Using real feature maps from ResNet-18 and\\nImageNet, we test those theoretical results empirically and find that they are\\nconsistent with our predictions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |cs.CV                        |cs.CV          |\n",
      "|http://arxiv.org/abs/2505.19806v1|Exploring Consciousness in LLMs: A Systematic Survey of Theories,\\n  Implementations, and Frontier Risks Consciousness stands as one of the most profound and distinguishing features\\nof the human mind, fundamentally shaping our understanding of existence and\\nagency. As large language models (LLMs) develop at an unprecedented pace,\\nquestions concerning intelligence and consciousness have become increasingly\\nsignificant. However, discourse on LLM consciousness remains largely unexplored\\nterritory. In this paper, we first clarify frequently conflated terminologies\\n(e.g., LLM consciousness and LLM awareness). Then, we systematically organize\\nand synthesize existing research on LLM consciousness from both theoretical and\\nempirical perspectives. Furthermore, we highlight potential frontier risks that\\nconscious LLMs might introduce. Finally, we discuss current challenges and\\noutline future directions in this emerging field. The references discussed in\\nthis paper are organized at\\nhttps://github.com/OpenCausaLab/Awesome-LLM-Consciousness.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |cs.CL,cs.CY,cs.LG            |cs.CL          |\n",
      "|http://arxiv.org/abs/2505.19807v1|Density Ratio-Free Doubly Robust Proxy Causal Learning We study the problem of causal function estimation in the Proxy Causal\\nLearning (PCL) framework, where confounders are not observed but proxies for\\nthe confounders are available. Two main approaches have been proposed: outcome\\nbridge-based and treatment bridge-based methods. In this work, we propose two\\nkernel-based doubly robust estimators that combine the strengths of both\\napproaches, and naturally handle continuous and high-dimensional variables. Our\\nidentification strategy builds on a recent density ratio-free method for\\ntreatment bridge-based PCL; furthermore, in contrast to previous approaches, it\\ndoes not require indicator functions or kernel smoothing over the treatment\\nvariable. These properties make it especially well-suited for continuous or\\nhigh-dimensional treatments. By using kernel mean embeddings, we have\\nclosed-form solutions and strong consistency guarantees. Our estimators\\noutperform existing methods on PCL benchmarks, including a prior doubly robust\\nmethod that requires both kernel smoothing and density ratio estimation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.LG,stat.ML                |stat.ML        |\n",
      "|http://arxiv.org/abs/2505.19808v1|Quantum computing of magnetic-skyrmion-like patterns in Heisenberg\\n  ferromagnets We diagonalize the quantum two-dimensional spin-1/2 Heisenberg model with\\nDzyaloshinskii-Moriya interaction (DMI) by applying the variational quantum\\neigensolver, running on a quantum-computer simulator, which turns out to be a\\nmore efficient approach than a classical direct diagonalization for systems\\nwith more than 17 sites. The calculated external-magnetic-field dependence of\\nthe total energy, of the magnetization, as well as of the topological charge\\nexhibits a distinctive discontinuity which hints for the existence of\\nzero-temperature magnetic skyrmions-like structures at the quantum level,\\ncontrolled by the combination of the exchange-coupling and the DMI parameters.\\nThe potentially measurable jump in the magnetization upon changing the field\\nindicates the investigated objects as stable enough for eventual applications\\nin spintronics or even as information carriers.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |quant-ph                     |cond-mat.str-el|\n",
      "|http://arxiv.org/abs/2505.19809v1|Equivariant Representation Learning for Symmetry-Aware Inference with\\n  Guarantees In many real-world applications of regression, conditional probability\\nestimation, and uncertainty quantification, exploiting symmetries rooted in\\nphysics or geometry can dramatically improve generalization and sample\\nefficiency. While geometric deep learning has made significant empirical\\nadvances by incorporating group-theoretic structure, less attention has been\\ngiven to statistical learning guarantees. In this paper, we introduce an\\nequivariant representation learning framework that simultaneously addresses\\nregression, conditional probability estimation, and uncertainty quantification\\nwhile providing first-of-its-kind non-asymptotic statistical learning\\nguarantees. Grounded in operator and group representation theory, our framework\\napproximates the spectral decomposition of the conditional expectation\\noperator, building representations that are both equivariant and disentangled\\nalong independent symmetry subgroups. Empirical evaluations on synthetic\\ndatasets and real-world robotics applications confirm the potential of our\\napproach, matching or outperforming existing equivariant baselines in\\nregression while additionally providing well-calibrated parametric uncertainty\\nestimates.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.LG,cs.AI,cs.RO,43-06      |cs.LG          |\n",
      "|http://arxiv.org/abs/2505.19810v1|Light distillation for Incremental Graph Convolution Collaborative\\n  Filtering Recommender systems presently utilize vast amounts of data and play a pivotal\\nrole in enhancing user experiences. Graph Convolution Networks (GCNs) have\\nsurfaced as highly efficient models within the realm of recommender systems due\\nto their ability to capture extensive relational information. The continuously\\nexpanding volume of data may render the training of GCNs excessively costly. To\\ntackle this problem, incrementally training GCNs as new data blocks come in has\\nbecome a vital research direction. Knowledge distillation techniques have been\\nexplored as a general paradigm to train GCNs incrementally and alleviate the\\ncatastrophic forgetting problem that typically occurs in incremental settings.\\nHowever, we argue that current methods based on knowledge distillation\\nintroduce additional parameters and have a high model complexity, which results\\nin unrealistic training time consumption in an incremental setting and thus\\ndifficult to actually deploy in the real world. In this work, we propose a\\nlight preference-driven distillation method to distill the preference score of\\na user for an item directly from historical interactions, which reduces the\\ntraining time consumption in the incremental setting significantly without\\nnoticeable loss in performance. The experimental result on two general datasets\\nshows that the proposed method can save training time from 1.5x to 9.5x\\ncompared to the existing methods and improves Recall@20 by 5.41% and 10.64%\\nfrom the fine-tune method.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |cs.IR                        |cs.IR          |\n",
      "|http://arxiv.org/abs/2505.19811v1|Physically Plausible Vectorial Metrics for Polarization Information\\n  Analysis The Mueller Matrix Polar Decomposition method decomposes a Mueller matrix\\ninto a diattenuator, a retarder, and a depolarizer. Among these elements, the\\nretarder, which plays a key role in medical and material characterization, is\\nmodelled as a circular retarder followed by a linear retarder when using this\\napproach. However, this model may not accurately reflect the actual structure\\nof the retarder in certain cases, as many practical retarders do not have a\\nlayered structure or consist of multiple (unknown) layers. Misinterpretation,\\ntherefore, may occur when the actual structure differs from the model. Here we\\ncircumvent this limitation by proposing to use a physically plausible parameter\\nset that includes the axis orientation angle $\\phi$, the degree of ellipticity\\n$\\chi$, and the elliptical retardance $\\rho$. By working with this set of\\nparameters, an overall characterization of a retarder is provided, encompassing\\nits full optical response without making any assumptions about the structure of\\nthe material. In this study, experiments were carried out on liquid crystalline\\nsamples to validate the feasibility of our approach, demonstrating that the\\nphysically plausible parameter set adopted provides a useful tool for a broader\\nrange of applications in both biomedical imaging and optical material analysis.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |physics.optics               |physics.optics |\n",
      "|http://arxiv.org/abs/2505.19812v1|Efficient Multi-modal Long Context Learning for Training-free Adaptation Traditional approaches to adapting multi-modal large language models (MLLMs)\\nto new tasks have relied heavily on fine-tuning. This paper introduces\\nEfficient Multi-Modal Long Context Learning (EMLoC), a novel training-free\\nalternative that embeds demonstration examples directly into the model input.\\nEMLoC offers a more efficient, flexible, and scalable solution for task\\nadaptation. Because extremely lengthy inputs introduce prohibitive\\ncomputational and memory overhead, EMLoC contributes a chunk-wise compression\\nmechanism combined with layer-wise adaptive pruning. It condenses long-context\\nmultimodal inputs into compact, task-specific memory representations. By\\nadaptively pruning tokens at each layer under a Jensen-Shannon divergence\\nconstraint, our method achieves a dramatic reduction in inference complexity\\nwithout sacrificing performance. This approach is the first to seamlessly\\nintegrate compression and pruning techniques for multi-modal long-context\\nlearning, offering a scalable and efficient solution for real-world\\napplications. Extensive experiments on diverse vision-language benchmarks\\ndemonstrate that EMLoC achieves performance on par with or superior to naive\\nlong-context approaches. Our results highlight the potential of EMLoC as a\\ngroundbreaking framework for efficient and flexible adaptation of multi-modal\\nmodels in resource-constrained environments. Codes are publicly available at\\nhttps://github.com/Zehong-Ma/EMLoC.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |cs.CV                        |cs.LG          |\n",
      "|http://arxiv.org/abs/2505.19813v1|GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot\\n  View Synthesis Neural Radiance Fields (NeRF) have transformed novel view synthesis by\\nmodeling scene-specific volumetric representations directly from images. While\\ngeneralizable NeRF models can generate novel views across unknown scenes by\\nlearning latent ray representations, their performance heavily depends on a\\nlarge number of multi-view observations. However, with limited input views,\\nthese methods experience significant degradation in rendering quality. To\\naddress this limitation, we propose GoLF-NRT: a Global and Local feature\\nFusion-based Neural Rendering Transformer. GoLF-NRT enhances generalizable\\nneural rendering from few input views by leveraging a 3D transformer with\\nefficient sparse attention to capture global scene context. In parallel, it\\nintegrates local geometric features extracted along the epipolar line, enabling\\nhigh-quality scene reconstruction from as few as 1 to 3 input views.\\nFurthermore, we introduce an adaptive sampling strategy based on attention\\nweights and kernel regression, improving the accuracy of transformer-based\\nneural rendering. Extensive experiments on public datasets show that GoLF-NRT\\nachieves state-of-the-art performance across varying numbers of input views,\\nhighlighting the effectiveness and superiority of our approach. Code is\\navailable at https://github.com/KLMAV-CUC/GoLF-NRT.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.CV                        |cs.CV          |\n",
      "|http://arxiv.org/abs/2505.19814v1|Stratifications and term description over valued fields with analytic\\n  structure, uniform Yomdin-Gromov parametrizations We establish a certain strong smooth stratification of sets and a term\\ndescription of functions, which are definable over valued fields (possibly non\\nalgebraically closed) with separated analytic structure. The basic tools are:\\nelimination of valued field quantifiers, term structure of definable functions,\\nLipschitz cell decomposition with preparation of $RV$-parametrized sets, and a\\nnon-Archimedean definable version of Bierstone-Milman's canonical\\ndesingularization algorithm, achieved in an earlier paper of ours. As\\napplication, we give uniform Yomdin-Gromov parametrizations over Henselian\\nfields $K$ with separated analytic structure.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |math.LO,math.AG              |math.AG        |\n",
      "|http://arxiv.org/abs/2505.19815v1|Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective We propose a novel framework for comprehending the reasoning capabilities of\\nlarge language models (LLMs) through the perspective of meta-learning. By\\nconceptualizing reasoning trajectories as pseudo-gradient descent updates to\\nthe LLM's parameters, we identify parallels between LLM reasoning and various\\nmeta-learning paradigms. We formalize the training process for reasoning tasks\\nas a meta-learning setup, with each question treated as an individual task, and\\nreasoning trajectories serving as the inner loop optimization for adapting\\nmodel parameters. Once trained on a diverse set of questions, the LLM develops\\nfundamental reasoning capabilities that can generalize to previously unseen\\nquestions. Extensive empirical evaluations substantiate the strong connection\\nbetween LLM reasoning and meta-learning, exploring several issues of\\nsignificant interest from a meta-learning standpoint. Our work not only\\nenhances the understanding of LLM reasoning but also provides practical\\ninsights for improving these models through established meta-learning\\ntechniques.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.CL,cs.AI                  |cs.CL          |\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-35-20.json\n",
      "\n",
      "========= 2025-05-29 21:35:30 =========\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+-------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |true_label              |pred         |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+-------------+\n",
      "|http://arxiv.org/abs/2505.19821v1|Poison in the Well: Feature Embedding Disruption in Backdoor Attacks Backdoor attacks embed malicious triggers into training data, enabling\\nattackers to manipulate neural network behavior during inference while\\nmaintaining high accuracy on benign inputs. However, existing backdoor attacks\\nface limitations manifesting in excessive reliance on training data, poor\\nstealth, and instability, which hinder their effectiveness in real-world\\napplications. Therefore, this paper introduces ShadowPrint, a versatile\\nbackdoor attack that targets feature embeddings within neural networks to\\nachieve high ASRs and stealthiness. Unlike traditional approaches, ShadowPrint\\nreduces reliance on training data access and operates effectively with\\nexceedingly low poison rates (as low as 0.01%). It leverages a clustering-based\\noptimization strategy to align feature embeddings, ensuring robust performance\\nacross diverse scenarios while maintaining stability and stealth. Extensive\\nevaluations demonstrate that ShadowPrint achieves superior ASR (up to 100%),\\nsteady CA (with decay no more than 1% in most cases), and low DDR (averaging\\nbelow 5%) across both clean-label and dirty-label settings, and with poison\\nrates ranging from as low as 0.01% to 0.05%, setting a new standard for\\nbackdoor attack capabilities and emphasizing the need for advanced defense\\nstrategies focused on feature space manipulations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CR,cs.LG             |cs.CR        |\n",
      "|http://arxiv.org/abs/2505.19822v1|The stability threshold for 3D MHD equations around Couette with\\n  rationally aligned magnetic field We address a stability threshold problem of the Couette flow $(y,0,0)$ in a\\nuniform magnetic fleld $\\alpha(\\sigma,0,1)$ with $\\sigma\\in\\mathbb{Q}$ for the\\n3D MHD equations on $\\mathbb{T}\\times\\mathbb{R}\\times\\mathbb{T}$. We obtain the\\nthreshold $\\gamma=1$ in $H^N(N>13/2)$, hence improving the results in\\n\\cite{L20,RZZ25}. The nonlinear inviscid damping for velocity $u^2_{\\neq}$ is\\nalso established. Moreover, our result shows that the nonzero modes of magnetic\\nfield has an amplification of order $\\nu^{-1/3}$ even on low regularity, which\\nis very different from the case of $\\sigma\\in\\mathbb{R}\\backslash\\mathbb{Q}$\\nsatisfying a generic Diophantine condition in \\cite{L20,RZZ25}.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |math.AP                 |math.AP      |\n",
      "|http://arxiv.org/abs/2505.19823v1|LAPA-based Dynamic Privacy Optimization for Wireless Federated Learning\\n  in Heterogeneous Environments Federated Learning (FL) is a distributed machine learning paradigm based on\\nprotecting data privacy of devices, which however, can still be broken by\\ngradient leakage attack via parameter inversion techniques. Differential\\nprivacy (DP) technology reduces the risk of private data leakage by adding\\nartificial noise to the gradients, but detrimental to the FL utility at the\\nsame time, especially in the scenario where the data is Non-Independent\\nIdentically Distributed (Non-IID). Based on the impact of heterogeneous data on\\naggregation performance, this paper proposes a Lightweight Adaptive Privacy\\nAllocation (LAPA) strategy, which assigns personalized privacy budgets to\\ndevices in each aggregation round without transmitting any additional\\ninformation beyond gradients, ensuring both privacy protection and aggregation\\nefficiency. Furthermore, the Deep Deterministic Policy Gradient (DDPG)\\nalgorithm is employed to optimize the transmission power, in order to determine\\nthe optimal timing at which the adaptively attenuated artificial noise aligns\\nwith the communication noise, enabling an effective balance between DP and\\nsystem utility. Finally, a reliable aggregation strategy is designed by\\nintegrating communication quality and data distribution characteristics, which\\nimproves aggregation performance while preserving privacy. Experimental results\\ndemonstrate that the personalized noise allocation and dynamic optimization\\nstrategy based on LAPA proposed in this paper enhances convergence performance\\nwhile satisfying the privacy requirements of FL.                                                                                                                                                                                                                                                                                                                                              |cs.LG,cs.AI             |cs.LG        |\n",
      "|http://arxiv.org/abs/2505.19824v1|Weighted Tail Random Variable: A Novel Framework with Stochastic\\n  Properties and Applications This paper introduces a novel framework to construct the probability density\\nfunction (PDF) of non-negative continuous random variables. The proposed\\nframework uses two functions: one is the survival function (SF) of a\\nnon-negative continuous random variable, and the other is a weight function,\\nwhich is an increasing and differentiable function satisfying some properties.\\nThe resulting random variable is referred to as the weighted tail random\\nvariable (WTRV) corresponding to the given random variable and the weight\\nfunction. We investigate several reliability properties of the WTRV and\\nestablish various stochastic orderings between a random variable and its WTRV,\\nas well as between two WTRVs. Using this framework, we construct a WTRV of the\\nKumaraswamy distribution. We conduct goodness-of-fit tests for two real-world\\ndatasets, applied to the Kumaraswamy distribution and its corresponding WTRV.\\nThe test results indicate that the WTRV offers a superior fit compared to the\\nKumaraswamy distribution, which demonstrates the utility of the proposed\\nframework.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |math.ST,stat.AP,stat.TH |stat.ME      |\n",
      "|http://arxiv.org/abs/2505.19825v1|Foundation Models for Tabular Data within Systemic Contexts Need\\n  Grounding Current research on tabular foundation models often overlooks the\\ncomplexities of large-scale, real-world data by treating tables as isolated\\nentities and assuming information completeness, thereby neglecting the vital\\noperational context. To address this, we introduce the concept of Semantically\\nLinked Tables (SLT), recognizing that tables are inherently connected to both\\ndeclarative and procedural operational knowledge. We propose Foundation Models\\nfor Semantically Linked Tables (FMSLT), which integrate these components to\\nground tabular data within its true operational context. This comprehensive\\nrepresentation unlocks the full potential of machine learning for complex,\\ninterconnected tabular data across diverse domains. Realizing FMSLTs requires\\naccess to operational knowledge that is often unavailable in public datasets,\\nhighlighting the need for close collaboration between domain experts and\\nresearchers. Our work exposes the limitations of current tabular foundation\\nmodels and proposes a new direction centered on FMSLTs, aiming to advance\\nrobust, context-aware models for structured data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |cs.LG,cs.AI,cs.DB       |cs.DB        |\n",
      "|http://arxiv.org/abs/2505.19826v1|The Entropy Characterization of Quantum MDS Codes An $[[n,k,d]]$ quantum maximum-distance-separable code maps $k$ source qudits\\nto $n$ coded qudits such that any $n-(d-1)$ coded qudits may recover all source\\nqudits and $n = k + 2 (d-1)$. The entropy of the joint state of the reference\\nsystem of $k$ qudits and the $n$ coded qudits is fully characterized - the\\njoint state must be pure, i.e., has entropy zero; and any sub-system whose\\nnumber of qudits is at most half of $k+n$, the total number of qudits in the\\njoint state must be maximally mixed, i.e., has entropy equal to its size.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |quant-ph,cs.IT,math.IT  |quant-ph     |\n",
      "|http://arxiv.org/abs/2505.19827v1|Revisiting Glorot Initialization for Long-Range Linear Recurrences Proper initialization is critical for Recurrent Neural Networks (RNNs),\\nparticularly in long-range reasoning tasks, where repeated application of the\\nsame weight matrix can cause vanishing or exploding signals. A common baseline\\nfor linear recurrences is Glorot initialization, designed to ensure stable\\nsignal propagation--but derived under the infinite-width, fixed-length\\nregime--an unrealistic setting for RNNs processing long sequences. In this\\nwork, we show that Glorot initialization is in fact unstable: small positive\\ndeviations in the spectral radius are amplified through time and cause the\\nhidden state to explode. Our theoretical analysis demonstrates that sequences\\nof length $t = O(\\sqrt{n})$, where $n$ is the hidden width, are sufficient to\\ninduce instability. To address this, we propose a simple, dimension-aware\\nrescaling of Glorot that shifts the spectral radius slightly below one,\\npreventing rapid signal explosion or decay. These results suggest that standard\\ninitialization schemes may break down in the long-sequence regime, motivating a\\nseparate line of theory for stable recurrent initialization.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.LG,cs.AI             |cs.LG        |\n",
      "|http://arxiv.org/abs/2505.19828v1|SecVulEval: Benchmarking LLMs for Real-World C/C++ Vulnerability\\n  Detection Large Language Models (LLMs) have shown promise in software engineering\\ntasks, but evaluating their effectiveness in vulnerability detection is\\nchallenging due to the lack of high-quality datasets. Most existing datasets\\nare limited to function-level labels, ignoring finer-grained vulnerability\\npatterns and crucial contextual information. Also, poor data quality such as\\nmislabeling, inconsistent annotations, and duplicates can lead to inflated\\nperformance and weak generalization. Moreover, by including only the functions,\\nthese datasets miss broader program context, like data/control dependencies and\\ninterprocedural interactions, that are essential for accurately understanding\\nreal-world security flaws. Without this context, detection models are evaluated\\nunder unrealistic assumptions.\\n  To address these limitations, this paper introduces SecVulEval, a benchmark\\ndesigned to support fine-grained evaluation of LLMs and other detection methods\\nwith rich contextual information. SecVulEval focuses on real-world C/C++\\nvulnerabilities at the statement level. This granularity enables more precise\\nevaluation of a model's ability to localize vulnerabilities, beyond simple\\nbinary classification at the function level. By incorporating rich contextual\\ninformation, SecVulEval sets a new standard for vulnerability detection\\nbenchmarks in realistic scenarios. This benchmark includes 25,440 function\\nsamples covering 5,867 unique CVEs in C/C++ projects from 1999 to 2024. We\\nevaluated the SOTA LLMs with a multi-agent-based approach. The evaluation on\\nour dataset shows that the models are still far from accurately predicting\\nvulnerable statements in a given function. The best-performing\\nClaude-3.7-Sonnet model achieves 23.83% F1-score for detecting vulnerable\\nstatements with correct reasoning. Finally, we analyze the LLM outputs and\\nprovide insights into their behavior in vulnerability detection for C/C++.|cs.SE                   |cs.SE        |\n",
      "|http://arxiv.org/abs/2505.19829v1|Gauge symmetry breaking with $S^2$ extra dimensions We consider symmetry breaking of arbitrary gauge groups on a six-dimensional\\nspace-time which consists of a four-dimensional Minkowski space-time $M^4$ and\\na two-dimensional sphere $S^2$. We expand the gauge fields in the presence of a\\nnon-trivial background unique to $S^2$. We analyze Kaluza-Klein(KK) modes of\\nthe gauge fields and derive the mass spectrum of the KK modes. We found that\\nthe gauge fields (not) commuting with the background fields (do not) remain\\nsymmetry operators in four dimensions. We also discuss the mass spectrum of the\\nextra-dimensional components of the gauge fields and identify a physical scalar\\n$\\phi$ and a Nambu-Goldstone mode $\\chi$. As a result, we obtain a method to\\nbreak gauge symmetry due to the nontrivial solution for gauge fields which is a\\nunique feature of $S^2$.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |hep-ph,hep-th           |hep-th       |\n",
      "|http://arxiv.org/abs/2505.19830v1|Statistical physics of active matter, cell division and cell aggregation In these Lecture Notes we aim at clarifying how soft matter physics, and\\nherein notably statistical mechanics and fluid mechanics, can be engaged to\\nunderstand and manipulate non-equilibrium systems consisting of numerous\\n(microscopic) constituents that convert (chemical) energy to mechanical energy,\\nor vice versa, and that are known as active matter. Hydrodynamic theory,\\nvitally extended to include (anisotropic) active stress, provides an\\nastonishingly successful scaffold for tackling the problem of spontaneous flow\\nin active nematics, all the way to active turbulence. The laws of physics,\\nnonchalantly tresspassing the border crossing between inanimate particle and\\nliving cell, are seen to perform cum laude in describing the bi-directional\\ncoupling between division and apoptosis on the one hand and mechanical stress\\non the other. Fluidization of cellular tissue by cell division is a conceptual\\nleap in this arena. The active behavior of nematic tissues (cell extrusion,\\nmultilayer formation, ...) turns out to be controlled by topological defects in\\nthe orientational order. Playgrounds by excellence for exhibiting stress-growth\\ncoupling are multicellular spheroids serving as model tumors, and cysts used as\\nstem cell factories for cell therapy. Finally, our study of villi and crypts in\\nthe intestine furnishes a synthesis of various concepts explored. Cell\\nmechanical pressure and cell layer geometrical curvature turn out to provide\\nthe dynamical ingredients which, when coupled to the cell division rate, allow\\none to develop a physical theory of tissue morphology which hopefully will have\\npractical impact on cancer research.                                                                                                                                                                                                                                                                                         |cond-mat.soft           |cond-mat.soft|\n",
      "|http://arxiv.org/abs/2505.19831v1|SN 2024aecx: A double-peaked rapidly evolving Type IIb supernova at 11\\n  Mpc We present the results of low-resolution spectroscopic and densely sampled\\nmultiband simultaneous optical imaging ($ugi$ and $vrz$ bands) follow-up of\\nsupernova (SN) 2024aecx. The photometric data is supplemented with $Swift$/UVOT\\nand ATLAS survey observations. The SN was discovered in the spiral galaxy NGC\\n3521 (distance $\\sim$11 Mpc) within a day after the explosion. The early\\nspectra of SN 2024aecx show a weak signature of hydrogen lines, which\\ndisappeared in $\\sim$30 days after the explosion. Light curves in all bands\\nshow a distinct feature of two peaks, and the first peak is likely due to the\\nshock cooling emission. The early phase light curve evolution of SN 2024aecx\\nhas similarity with the typical Type IIb events, but the decay rate in\\ndifferent bands (e.g., $\\rm \\Delta m_{15}$ = 1.60 $\\pm$ 0.05 mag, $g$-band) is\\nsignificantly faster in the post-peak phase. It attained the secondary maximum\\nin $\\sim$19 days ($g$-band) with a peak absolute magnitude of M$_{g}$= -17.94\\n$\\pm$ 0.10 mag. The color evolution of SN 2024aecx is displaying a red-blue-red\\ntrend between days $\\sim$8 to 40. The analytical model fitting to the light\\ncurves reveals an envelope mass and progenitor radii in the range of $\\sim$0.03\\n- 0.24 $M_\\odot$ and $\\sim$169 - 200 $R_\\odot$, respectively. Modeling of the\\npseudo-bolometric light curve suggests that synthesized $^{56}$Ni in the\\nexplosion was $\\sim$0.15 M$_{\\odot}$ with ejecta mass and kinetic energy of\\n$\\sim$0.7 M$_{\\odot}$ and $\\sim$0.16 x 10$^{51}$ erg, respectively. The\\nobservational properties and modeling indicate that the SN 2024aecx progenitor\\nbelongs to the extended progenitor category.                                                                                                                                                                                                                                                                                   |astro-ph.HE             |astro-ph.HE  |\n",
      "|http://arxiv.org/abs/2505.19832v1|Reconciling extragalactic star formation efficiencies with theory:\\n  insights from PHANGS New extragalactic measurements of the cloud population-averaged star\\nformation (SF) efficiency per freefall time $\\rm\\epsilon_{\\rm ff}$ from PHANGS\\nshow little sign of theoretically predicted dependencies on cloud-scale virial\\nlevel or velocity dispersion. We explore ways to bring theory into consistency\\nwith observations, highlighting systematic variations in internal density\\nstructure that must happen together with an increase in virial level typical\\ntowards galaxy centers. To introduce these variations into conventional\\nturbulence-regulated SF models we adopt three adjustments motivated by the host\\ngalaxy's influence on the cloud-scale: we incorporate self-gravity and a gas\\ndensity distribution that contains a broad power-law (PL) component and\\nresembles the structure observed in local resolved clouds, we let the internal\\ngas kinematics include motion in the background potential and let this regulate\\nthe onset of self-gravitation, and we assume that the gas density distribution\\nis in a steady-state for only a fraction of a freefall time. The combined\\nresult is a strong reduction to $\\rm\\epsilon_{\\rm ff}$ predicted in\\nmulti-freefall (MFF) scenarios compared to purely lognormal probability density\\nfunctions and variations that are tied to the PL slope $\\alpha$. The $\\alpha$\\nneeded to match PHANGS $\\rm\\epsilon_{\\rm ff}$'s vary systematically with\\nenvironment in the sense that gas sitting furthest from virial balance contains\\nmore gas at high density. With this `galaxy regulation' behavior included, our\\n`self-gravitating' sgMFF models function similar to the original, roughly\\n`virialized cloud' single-freefall models. However, outside disks with their\\ncharacteristic regulation, the flexible MFF models may be better suited.                                                                                                                                                              |astro-ph.GA             |astro-ph.GA  |\n",
      "|http://arxiv.org/abs/2505.19833v1|An analog to the Goldbach problem and the twin prime problem One of the best approaches to the Goldbach conjectures is the Chen's theorem,\\nshowing that every large enough even integer can be represented by a sum of a\\nprime and a $2$-almost prime. In this article, we consider a thinner set than\\nthe set of $2$-almost primes, which is $$ \\mathbb{P}^{(c)}=(\\lfloor p^c\\n\\rfloor)_{p\\in \\mathbb{P}}\\quad (c>0,c\\notin \\mathbb{N}), $$ where $\\mathbb{P}$\\nis the set of prime numbers and $\\lfloor \\cdot \\rfloor$ is the floor function.\\nWe prove that for all $c \\in (0,\\frac{13}{15})$, any large enough integer $N$\\ncan be represented as\\n  $$\\n  N=\\lfloor p^c\\rfloor+q,\\n  $$ where $p$ and $q$ are primes. Moreover, for almost all $c \\in (0, M)$ and\\nlarge enough $N$ where $M \\ll \\log N/ \\log\\log N$, we also prove that $N \\in\\n\\mathbb{P}^{(c)} + \\mathbb{P}$.\\n  It is well known that the twin prime conjecture can be approached by a\\nsimilar way to the Goldbach conjecture with a different form of the Chen's\\ntheorem. We also prove similar results due to the set $\\mathbb{P}^{(c)}$ with\\nboth an unconditional case and an average case based on the Lebesgue measure,\\nwhich also improve a theorem by Balog.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |math.NT                 |math.NT      |\n",
      "|http://arxiv.org/abs/2505.19834v1|Axiomatizing approximate inclusion We introduce two approximate variants of inclusion dependencies and examine\\nthe axiomatization and computational complexity of their implication problems.\\nThe approximate variants allow for some imperfection in the database and differ\\nin how this degree is measured. One considers the error relative to the\\ndatabase size, while the other applies a fixed threshold independent of size.\\nWe obtain complete axiomatizations for both under some arity restrictions. In\\nparticular, restricted to unary inclusion dependencies, the implication problem\\nfor each approximate variant is decidable in PTIME. We formalise the results\\nusing team semantics, where a team corresponds to a uni-relational database.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |cs.LO,math.LO           |cs.LO        |\n",
      "|http://arxiv.org/abs/2505.19835v1|On a retarded stochastic system with discrete diffusion modeling life\\n  tables This work proposes a method for modeling and forecasting mortality rates. It\\nconstitutes an improvement over previous studies by incorporating both the\\nhistorical evolution of the mortality phenomenon and its random behavior. In\\nthe first part, we introduce the model and analyze mathematical properties such\\nas the existence of solutions and their asymptotic behavior. In the second\\npart, we apply this model to forecast mortality rates in Spain, showing that it\\nyields better results than classical methods.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |math.ST,math.PR,stat.TH |math.PR      |\n",
      "|http://arxiv.org/abs/2505.19836v1|Spinor Bose-Einstein condensate as an analog simulator of molecular\\n  bending vibrations We demonstrate that spinor Bose-Einstein condensates (BEC) can be operated as\\nan analog simulator of the two-dimensional vibron model. This algebraic model\\nfor the description of bending and stretching vibrations of molecules, in the\\ncase of a triatomic molecules, exhibits two phases where linear and bent\\nconfigurations are stabilised. Spinor BECs can be engineered to simulate states\\nthat correspond to linear or bent triatomic molecules, with the BEC's Wigner\\nfunction encoding information about the molecular configuration. We show how\\nquantum simulations of the bending dynamics of linear molecules can be\\nrealized, and how the straightening of a bent molecule leads to a dynamical\\ninstability. In the dynamics triggered by the corresponding instability, a\\nsignificant amount of entanglement is generated, and we characterise the\\ndynamics with the squeezing parameter and the quantum Fisher information (QFI).\\nThe scaling of the non-Gaussian sensitivity, described by the difference\\nbetween squeezing and QFI, grows with the system size once the spinor system\\ncrosses from the linear to the bent phase, thus serving as a dynamical witness\\nfor the quantum phase transition.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |quant-ph,physics.atom-ph|quant-ph     |\n",
      "|http://arxiv.org/abs/2505.19837v1|Multi-Agent Reinforcement Learning in Cybersecurity: From Fundamentals\\n  to Applications Multi-Agent Reinforcement Learning (MARL) has shown great potential as an\\nadaptive solution for addressing modern cybersecurity challenges. MARL enables\\ndecentralized, adaptive, and collaborative defense strategies and provides an\\nautomated mechanism to combat dynamic, coordinated, and sophisticated threats.\\nThis survey investigates the current state of research in MARL applications for\\nautomated cyber defense (ACD), focusing on intruder detection and lateral\\nmovement containment. Additionally, it examines the role of Autonomous\\nIntelligent Cyber-defense Agents (AICA) and Cyber Gyms in training and\\nvalidating MARL agents. Finally, the paper outlines existing challenges, such\\nas scalability and adversarial robustness, and proposes future research\\ndirections. This also discusses how MARL integrates in AICA to provide\\nadaptive, scalable, and dynamic solutions to counter the increasingly\\nsophisticated landscape of cyber threats. It highlights the transformative\\npotential of MARL in areas like intrusion detection and lateral movement\\ncontainment, and underscores the value of Cyber Gyms for training and\\nvalidation of AICA.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.MA,cs.GT,cs.LG       |cs.CR        |\n",
      "|http://arxiv.org/abs/2505.19838v1|FoodTaxo: Generating Food Taxonomies with Large Language Models We investigate the utility of Large Language Models for automated taxonomy\\ngeneration and completion specifically applied to taxonomies from the food\\ntechnology industry. We explore the extent to which taxonomies can be completed\\nfrom a seed taxonomy or generated without a seed from a set of known concepts,\\nin an iterative fashion using recent prompting techniques. Experiments on five\\ntaxonomies using an open-source LLM (Llama-3), while promising, point to the\\ndifficulty of correctly placing inner nodes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |cs.CL,cs.AI             |cs.CL        |\n",
      "|http://arxiv.org/abs/2505.19839v1|Chance-constrained Solar PV Hosting Capacity Assessment for Distribution\\n  Grids Using Gaussian Process and Logit Learning Growing penetration of distributed generation such as solar PV can increase\\nthe risk of over-voltage in distribution grids, affecting network security.\\nTherefore, assessment of the so-called, PV hosting capacity (HC) - the maximum\\namount of PV that a given grid can accommodate becomes an important practical\\nproblem. In this paper, we propose a novel chance-constrained HC estimation\\nframework using Gaussian Process and Logit learning that can account for\\nuncertainty and risk management. Also, we consider the assessment of HC under\\ndifferent voltage control strategies. Our results have demonstrated that the\\nproposed models can achieve high accuracy levels of up to 93% in predicting\\nnodal over-voltage events on IEEE 33-bus and 123-bus test-cases. Thus, these\\nmodels can be effectively employed to estimate the chance-constrained HC with\\nvarious risk levels. Moreover, our proposed methods have simple forms and low\\ncomputational costs of only a few seconds.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |eess.SY,cs.SY           |eess.SY      |\n",
      "|http://arxiv.org/abs/2505.19840v1|One Surrogate to Fool Them All: Universal, Transferable, and Targeted\\n  Adversarial Attacks with CLIP Deep Neural Networks (DNNs) have achieved widespread success yet remain prone\\nto adversarial attacks. Typically, such attacks either involve frequent queries\\nto the target model or rely on surrogate models closely mirroring the target\\nmodel -- often trained with subsets of the target model's training data -- to\\nachieve high attack success rates through transferability. However, in\\nrealistic scenarios where training data is inaccessible and excessive queries\\ncan raise alarms, crafting adversarial examples becomes more challenging. In\\nthis paper, we present UnivIntruder, a novel attack framework that relies\\nsolely on a single, publicly available CLIP model and publicly available\\ndatasets. By using textual concepts, UnivIntruder generates universal,\\ntransferable, and targeted adversarial perturbations that mislead DNNs into\\nmisclassifying inputs into adversary-specified classes defined by textual\\nconcepts.\\n  Our extensive experiments show that our approach achieves an Attack Success\\nRate (ASR) of up to 85% on ImageNet and over 99% on CIFAR-10, significantly\\noutperforming existing transfer-based methods. Additionally, we reveal\\nreal-world vulnerabilities, showing that even without querying target models,\\nUnivIntruder compromises image search engines like Google and Baidu with ASR\\nrates up to 84%, and vision language models like GPT-4 and Claude-3.5 with ASR\\nrates up to 80%. These findings underscore the practicality of our attack in\\nscenarios where traditional avenues are blocked, highlighting the need to\\nreevaluate security paradigms in AI applications.                                                                                                                                                                                                                                                                                                                                  |cs.CR,cs.LG,I.2.6       |cs.CR        |\n",
      "+---------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìÅ Saved predictions to ./predictions_batch_2025-05-29_21-35-30.json\n",
      "\n",
      "========= 2025-05-29 21:35:40 =========\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------+---------------+\n",
      "|aid                              |text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |true_label                                        |pred           |\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------+---------------+\n",
      "|http://arxiv.org/abs/2505.19845v1|Power allocation for cell-free MIMO integrated sensing and communication In this paper, we investigate integrated sensing and communication (ISAC) in\\na cell-free (CF) multiple-input multiple-output (MIMO) network with\\nsingle-antenna access points (APs), where each AP functions either as a\\ntransmitter for both sensing and communication or as a receiver for\\ntarget-reflected signals. We derive closed-form Cramer-Rao lower bounds (CRLBs)\\nfor location and velocity estimation under arbitrary power allocation ratios,\\nassuming the radar cross-section (RCS) is deterministic and unknown over the\\nobservation interval. A power allocation optimization problem is formulated to\\nmaximize the communication signal-to-interference-plus-noise ratio (SINR),\\nsubject to CRLB-based sensing constraints and per-transmitter power limits. To\\nsolve the resulting nonlinear and non-convex problem, we propose a penalty\\nfunction and projection-based modified conjugate gradient algorithm with\\ninexact line search (PP-MCG-ILS), and an alternative method based on a modified\\nsteepest descent approach (PP-MSD-ILS). Additionally, for power minimization in\\npure sensing scenarios, we introduce a penalty function-based normalized\\nconjugate gradient algorithm (P-NCG-ILS). We analyze the convergence behavior\\nand qualitatively compare the computational complexity of the proposed\\nalgorithms. Simulation results confirm the accuracy of the derived CRLBs and\\ndemonstrate the effectiveness of the proposed power allocation strategies in\\nenhancing both sensing and overall ISAC performance.                                                                                                                                                                                                                                                                                                                                                                                                          |eess.SP                                           |eess.SP        |\n",
      "|http://arxiv.org/abs/2505.19846v1|Zero-Shot Pseudo Labels Generation Using SAM and CLIP for\\n  Semi-Supervised Semantic Segmentation Semantic segmentation is a fundamental task in medical image analysis and\\nautonomous driving and has a problem with the high cost of annotating the\\nlabels required in training. To address this problem, semantic segmentation\\nmethods based on semi-supervised learning with a small number of labeled data\\nhave been proposed. For example, one approach is to train a semantic\\nsegmentation model using images with annotated labels and pseudo labels. In\\nthis approach, the accuracy of the semantic segmentation model depends on the\\nquality of the pseudo labels, and the quality of the pseudo labels depends on\\nthe performance of the model to be trained and the amount of data with\\nannotated labels. In this paper, we generate pseudo labels using zero-shot\\nannotation with the Segment Anything Model (SAM) and Contrastive Language-Image\\nPretraining (CLIP), improve the accuracy of the pseudo labels using the Unified\\nDual-Stream Perturbations Approach (UniMatch), and use them as enhanced labels\\nto train a semantic segmentation model. The effectiveness of the proposed\\nmethod is demonstrated through the experiments using the public datasets:\\nPASCAL and MS COCO.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CV                                             |cs.CV          |\n",
      "|http://arxiv.org/abs/2505.19847v1|DGRAG: Distributed Graph-based Retrieval-Augmented Generation in\\n  Edge-Cloud Systems Retrieval-Augmented Generation (RAG) has emerged as a promising approach to\\nenhance the capabilities of language models by integrating external knowledge.\\nDue to the diversity of data sources and the constraints of memory and\\ncomputing resources, real-world data is often scattered in multiple devices.\\nConventional RAGs that store massive amounts of scattered data centrally face\\nincreasing privacy concerns and high computational costs. Additionally, RAG in\\na central node raises latency issues when searching over a large-scale\\nknowledge base. To address these challenges, we propose a distributed Knowledge\\nGraph-based RAG approach, referred to as DGRAG, in an edge-cloud system, where\\neach edge device maintains a local knowledge base without the need to share it\\nwith the cloud, instead sharing only summaries of its knowledge. Specifically,\\nDGRAG has two main phases. In the Distributed Knowledge Construction phase,\\nDGRAG organizes local knowledge using knowledge graphs, generating subgraph\\nsummaries and storing them in a summary database in the cloud as information\\nsharing. In the Collaborative Retrieval and Generation phase, DGRAG first\\nperforms knowledge retrieval and answer generation locally, and a gate\\nmechanism determines whether the query is beyond the scope of local knowledge\\nor processing capabilities. For queries that exceed the local knowledge scope,\\nthe cloud retrieves knowledge from the most relevant edges based on the\\nsummaries and generates a more precise answer. Experimental results demonstrate\\nthe effectiveness of the proposed DGRAG approach in significantly improving the\\nquality of question-answering tasks over baseline approaches.                                                                                                                                                                                                   |cs.AI,cs.DC                                       |cs.DB          |\n",
      "|http://arxiv.org/abs/2505.19848v1|Improving Multilingual Math Reasoning for African Languages Researchers working on low-resource languages face persistent challenges due\\nto limited data availability and restricted access to computational resources.\\nAlthough most large language models (LLMs) are predominantly trained in\\nhigh-resource languages, adapting them to low-resource contexts, particularly\\nAfrican languages, requires specialized techniques. Several strategies have\\nemerged for adapting models to low-resource languages in todays LLM landscape,\\ndefined by multi-stage pre-training and post-training paradigms. However, the\\nmost effective approaches remain uncertain. This work systematically\\ninvestigates which adaptation strategies yield the best performance when\\nextending existing LLMs to African languages. We conduct extensive experiments\\nand ablation studies to evaluate different combinations of data types\\n(translated versus synthetically generated), training stages (pre-training\\nversus post-training), and other model adaptation configurations. Our\\nexperiments focuses on mathematical reasoning tasks, using the Llama 3.1 model\\nfamily as our base model.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |cs.CL                                             |cs.CL          |\n",
      "|http://arxiv.org/abs/2505.19849v1|HIT Model: A Hierarchical Interaction-Enhanced Two-Tower Model for\\n  Pre-Ranking Systems Online display advertising platforms rely on pre-ranking systems to\\nefficiently filter and prioritize candidate ads from large corpora, balancing\\nrelevance to users with strict computational constraints. The prevailing\\ntwo-tower architecture, though highly efficient due to its decoupled design and\\npre-caching, suffers from cross-domain interaction and coarse similarity\\nmetrics, undermining its capacity to model complex user-ad relationships. In\\nthis study, we propose the Hierarchical Interaction-Enhanced Two-Tower (HIT)\\nmodel, a new architecture that augments the two-tower paradigm with two key\\ncomponents: $\\textit{generators}$ that pre-generate holistic vectors\\nincorporating coarse-grained user-ad interactions through a dual-generator\\nframework with a cosine-similarity-based generation loss as the training\\nobjective, and $\\textit{multi-head representers}$ that project embeddings into\\nmultiple latent subspaces to capture fine-grained, multi-faceted user interests\\nand multi-dimensional ad attributes. This design enhances modeling\\neffectiveness without compromising inference efficiency. Extensive experiments\\non public datasets and large-scale online A/B testing on Tencent's advertising\\nplatform demonstrate that HIT significantly outperforms several baselines in\\nrelevance metrics, yielding a $1.66\\%$ increase in Gross Merchandise Volume and\\na $1.55\\%$ improvement in Return on Investment, alongside similar serving\\nlatency to the vanilla two-tower models. The HIT model has been successfully\\ndeployed in Tencent's online display advertising system, serving billions of\\nimpressions daily. The code is available at\\nhttps://anonymous.4open.science/r/HIT_model-5C23.                                                                                                                                                                                      |cs.IR                                             |cs.IR          |\n",
      "|http://arxiv.org/abs/2505.19850v1|DISCOVER: Automated Curricula for Sparse-Reward Reinforcement Learning Sparse-reward reinforcement learning (RL) can model a wide range of highly\\ncomplex tasks. Solving sparse-reward tasks is RL's core premise - requiring\\nefficient exploration coupled with long-horizon credit assignment - and\\novercoming these challenges is key for building self-improving agents with\\nsuperhuman ability. We argue that solving complex and high-dimensional tasks\\nrequires solving simpler tasks that are relevant to the target task. In\\ncontrast, most prior work designs strategies for selecting exploratory tasks\\nwith the objective of solving any task, making exploration of challenging\\nhigh-dimensional, long-horizon tasks intractable. We find that the sense of\\ndirection, necessary for effective exploration, can be extracted from existing\\nRL algorithms, without needing any prior information. Based on this finding, we\\npropose a method for directed sparse-reward goal-conditioned very long-horizon\\nRL (DISCOVER), which selects exploratory goals in the direction of the target\\ntask. We connect DISCOVER to principled exploration in bandits, formally\\nbounding the time until the target task becomes achievable in terms of the\\nagent's initial distance to the target, but independent of the volume of the\\nspace of all tasks. Empirically, we perform a thorough evaluation in\\nhigh-dimensional environments. We find that the directed goal selection of\\nDISCOVER solves exploration problems that are beyond the reach of prior\\nstate-of-the-art exploration methods in RL.                                                                                                                                                                                                                                                                                                                                                                                                                           |cs.LG,cs.AI,cs.RO                                 |cs.LG          |\n",
      "|http://arxiv.org/abs/2505.19851v1|Beyond Specialization: Benchmarking LLMs for Transliteration of Indian\\n  Languages Transliteration, the process of mapping text from one script to another,\\nplays a crucial role in multilingual natural language processing, especially\\nwithin linguistically diverse contexts such as India. Despite significant\\nadvancements through specialized models like IndicXlit, recent developments in\\nlarge language models suggest a potential for general-purpose models to excel\\nat this task without explicit task-specific training. The current work\\nsystematically evaluates the performance of prominent LLMs, including GPT-4o,\\nGPT-4.5, GPT-4.1, Gemma-3-27B-it, and Mistral-Large against IndicXlit, a\\nstate-of-the-art transliteration model, across ten major Indian languages.\\nExperiments utilized standard benchmarks, including Dakshina and Aksharantar\\ndatasets, with performance assessed via Top-1 Accuracy and Character Error\\nRate. Our findings reveal that while GPT family models generally outperform\\nother LLMs and IndicXlit for most instances. Additionally, fine-tuning GPT-4o\\nimproves performance on specific languages notably. An extensive error analysis\\nand robustness testing under noisy conditions further elucidate strengths of\\nLLMs compared to specialized models, highlighting the efficacy of foundational\\nmodels for a wide spectrum of specialized applications with minimal overhead.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CL,cs.AI                                       |cs.CL          |\n",
      "|http://arxiv.org/abs/2505.19852v1|Density-Functional Green Function Theory: Dynamical exchange-correlation\\n  field in lieu of self-energy The one-particle Green function of a many-electron system is traditionally\\nformulated within the self-energy picture. A different formalism was recently\\nproposed, in which the self-energy is replaced by a dynamical\\nexchange-correlation field, which acts on the Green function locally in both\\nspace and time. It was found that there exists a fundamental quantity, referred\\nto as the dynamical exchange-correlation hole, which can be interpreted as\\neffective density fluctuations induced in a many-electron system when a hole or\\nan electron is introduced into the system, as in photoemission and inverse\\nphotoemission experiments. The dynamical exchange-correlation potential is\\nsimply the Coulomb potential of this exchange-correlation hole, which fulfils a\\nsum rule and an exact constraint, identical to those satisfied by the static\\nexchange-correlation hole in density-functional theory. The proposed formalism\\nhas been applied to a number of model systems such as the half-filled\\none-dimensional Hubbard model, the one-dimensional antiferromagnetic Heisenberg\\nmodel, and the single-impurity Anderson model. The dynamical\\nexchange-correlation hole and field of the homogeneous electron gas have also\\nbeen studied with the view of constructing a density-functional approximation\\nsuch as the local-density approximation. The availability of simple but\\naccurate approximations for the exchange-correlation potential would circumvent\\ncostly computations of the traditional self-energy. The formalism may also\\nprovide new perspectives and insights into the many-body problem.                                                                                                                                                                                                                                                                                      |cond-mat.str-el,cond-mat.mtrl-sci                 |cond-mat.str-el|\n",
      "|http://arxiv.org/abs/2505.19853v1|Two Causally Related Needles in a Video Haystack Evaluating the video understanding capabilities of Video-Language Models\\n(VLMs) remains a significant challenge. We propose a long-context video\\nunderstanding benchmark, Causal2Needles, that assesses two crucial abilities\\ninsufficiently evaluated by existing benchmarks: (1) the ability to extract\\ninformation from two separate locations in a long video and understand them\\njointly, and (2) the ability to model the world in terms of cause and effect in\\nhuman behaviors. Specifically, Causal2Needles introduces 2-needle questions,\\nwhich require extracting information from both the cause and effect\\nhuman-behavior events in a long video and the associated narration text. To\\nprevent textual bias, these questions comprise two complementary formats: one\\nasking to identify the video clip containing the answer, and one asking for the\\ntextual description of an unrelated visual detail from that video clip. Our\\nexperiments reveal that models excelling in pre-existing benchmarks struggle\\nwith 2-needle visual grounding, and the model performance is negatively\\ncorrelated with the distance between the two needles. These findings highlight\\ncritical limitations in current VLMs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |cs.CV,cs.AI                                       |cs.CV          |\n",
      "|http://arxiv.org/abs/2505.19854v1|Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian\\n  Splatting with Dense Point Cloud Gaussian Splatting (GS) has gained attention as a fast and effective method\\nfor novel view synthesis. It has also been applied to 3D reconstruction using\\nmulti-view images and can achieve fast and accurate 3D reconstruction. However,\\nGS assumes that the input contains a large number of multi-view images, and\\ntherefore, the reconstruction accuracy significantly decreases when only a\\nlimited number of input images are available. One of the main reasons is the\\ninsufficient number of 3D points in the sparse point cloud obtained through\\nStructure from Motion (SfM), which results in a poor initialization for\\noptimizing the Gaussian primitives. We propose a new 3D reconstruction method,\\ncalled Sparse2DGS, to enhance 2DGS in reconstructing objects using only three\\nimages. Sparse2DGS employs DUSt3R, a fundamental model for stereo images, along\\nwith COLMAP MVS to generate highly accurate and dense 3D point clouds, which\\nare then used to initialize 2D Gaussians. Through experiments on the DTU\\ndataset, we show that Sparse2DGS can accurately reconstruct the 3D shapes of\\nobjects using just three images.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |cs.CV                                             |cs.CV          |\n",
      "|http://arxiv.org/abs/2505.19855v1|Editing as Unlearning: Are Knowledge Editing Methods Strong Baselines\\n  for Large Language Model Unlearning? Large language Model (LLM) unlearning, i.e., selectively removing information\\nfrom LLMs, is vital for responsible model deployment. Differently, LLM\\nknowledge editing aims to modify LLM knowledge instead of removing it. Though\\nediting and unlearning seem to be two distinct tasks, we find there is a tight\\nconnection between them. In this paper, we conceptualize unlearning as a\\nspecial case of editing where information is modified to a refusal or \"empty\\nset\" $\\emptyset$ response, signifying its removal. This paper thus investigates\\nif knowledge editing techniques are strong baselines for LLM unlearning. We\\nevaluate state-of-the-art (SOTA) editing methods (e.g., ROME, MEMIT, GRACE,\\nWISE, and AlphaEdit) against existing unlearning approaches on pretrained and\\nfinetuned knowledge. Results show certain editing methods, notably WISE and\\nAlphaEdit, are effective unlearning baselines, especially for pretrained\\nknowledge, and excel in generating human-aligned refusal answers. To better\\nadapt editing methods for unlearning applications, we propose practical recipes\\nincluding self-improvement and query merging. The former leverages the LLM's\\nown in-context learning ability to craft a more human-aligned unlearning\\ntarget, and the latter enables ROME and MEMIT to perform well in unlearning\\nlonger sample sequences. We advocate for the unlearning community to adopt SOTA\\nediting methods as baselines and explore unlearning from an editing perspective\\nfor more holistic LLM memory control.                                                                                                                                                                                                                                                                                                                                                                |cs.LG                                             |cs.CL          |\n",
      "|http://arxiv.org/abs/2505.19856v1|Beyond the Electric Dipole Approximation: Electric and Magnetic\\n  Multipole Contributions Reveal Biaxial Water Structure from SFG Spectra at\\n  the Air-Water Interface The interpretation of sum-frequency generation (SFG) spectra has been\\nseverely limited by the absence of quantitative theoretical predictions for\\nmultipole contributions. The previously unknown magnetic dipole and electric\\nquadrupole contributions are determined by the bulk media but appear in all\\nexperimental SFG spectra, obscuring the connection between measured spectra and\\ninterfacial structure. We present the simulation-based framework that predicts\\nthe full set of multipole contributions to the SFG spectrum. This framework\\nalso yields depth-resolved spectra, enabling the precise localization of\\nspectroscopic features. Applied to the air-water interface, our approach\\nachieves quantitative agreement with experimental spectra for different\\npolarization combinations in both the bending and stretching regions. Multipole\\ncontributions are crucial for correctly interpreting SFG spectra: in the\\nbending band, the electric dipole contribution is of an intensity similar to\\nthe magnetic dipole contribution, and both are dominated by the electric\\nquadrupole contribution. In the OH-stretch region, the electric quadrupole\\ncontribution is found to be responsible for the mysterious shoulder at 3600\\ncm$^{-1}$. Crucially, subtracting the multipole contributions isolates the\\nsecond-order electric dipole susceptibility, which is a quantitative probe for\\ninterfacial orientational anisotropy. This electric-dipole susceptibility\\nreveals a pronounced biaxial ordering of water at the air-water interface. By\\nresolving a fundamental limitation of the interpretation of SFG spectroscopy,\\nour framework allows for the detailed extraction of interfacial water ordering\\nfrom SFG spectra.                                                                                                  |cond-mat.stat-mech,physics.chem-ph                |physics.chem-ph|\n",
      "|http://arxiv.org/abs/2505.19857v1|Probing Memory-Burdened Primordial Black Holes with Galactic Sources\\n  observed by LHAASO The recently identified \\textit{memory burden} effect has the potential to\\nsignificantly decelerate the evaporation of black holes. Specifically, when\\napproximately half of a black hole's initial mass has been radiated away, the\\nevaporation process is halted. This mechanism allows very light primordial\\nblack holes (PBHs) with masses $m_{\\rm PBH}<10^{15}$ g to persist until the\\npresent day and may contribute to the dark matter (DM) content of the universe.\\nIn this work, we focus on PBHs with masses $\\lesssim 10^{9}$ g. Due to the\\nmemory burden effect, these PBHs emit high-energy gamma-rays, which in turn\\nalter the corresponding observed energy spectra. To investigate the constraints\\non the masses and DM abundance of PBHs, we analyze data from four Galactic\\nsources measured by the Large High Altitude Air Shower Observatory (LHAASO),\\nincluding the Crab Nebula, LHAASO J2226+6057, LHAASO J1908+0621, and LHAASO\\nJ1825-1326. Our findings indicate that the ultra-high-energy gamma-ray spectra\\nfrom these Galactic sources provide crucial probes for light PBHs, thereby\\nsignificantly constraining their potential contribution to DM.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |astro-ph.CO,astro-ph.HE                           |astro-ph.HE    |\n",
      "|http://arxiv.org/abs/2505.19858v1|A Unified Solution to Video Fusion: From Multi-Frame Learning to\\n  Benchmarking The real world is dynamic, yet most image fusion methods process static\\nframes independently, ignoring temporal correlations in videos and leading to\\nflickering and temporal inconsistency. To address this, we propose Unified\\nVideo Fusion (UniVF), a novel framework for temporally coherent video fusion\\nthat leverages multi-frame learning and optical flow-based feature warping for\\ninformative, temporally coherent video fusion. To support its development, we\\nalso introduce Video Fusion Benchmark (VF-Bench), the first comprehensive\\nbenchmark covering four video fusion tasks: multi-exposure, multi-focus,\\ninfrared-visible, and medical fusion. VF-Bench provides high-quality,\\nwell-aligned video pairs obtained through synthetic data generation and\\nrigorous curation from existing datasets, with a unified evaluation protocol\\nthat jointly assesses the spatial quality and temporal consistency of video\\nfusion. Extensive experiments show that UniVF achieves state-of-the-art results\\nacross all tasks on VF-Bench. Project page: https://vfbench.github.io.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.CV                                             |cs.CV          |\n",
      "|http://arxiv.org/abs/2505.19859v1|Role of settling inertial particles in modulating flow structures and\\n  drag in Taylor-Couette turbulence The modulation of drag through dispersed phases in wall turbulence has been a\\nlongstanding focus. This study examines the effects of particle Stokes number\\n($St$) and Froude number ($Fr$) on drag modulation in turbulent Taylor-Couette\\n(TC) flow, using a two-way coupled Eulerian-Lagrangian approach with Reynolds\\nnumber $Re_i = r_i \\omega_i d/\\nu$ fixed at 3500. For light particles (small\\n$St$), drag reduction is observed in the TC system, exhibiting a non-monotonic\\ndependence on $Fr$. In specific, drag reduction initially increases and then\\ndecreases with stronger influence of gravitational settling (characterized by\\ninverse of $Fr$), indicating the presence of an optimal $Fr$ for maximum drag\\nreduction. For heavy particles, similar non-monotonic trend can also be\\nobserved, but significant drag enhancement is resulted at large $Fr^{-1}$. We\\nfurther elucidate the role of settling particles in modulating the flow\\nstructure in TC by decomposing the advective flux into contributions from\\ncoherent Taylor vortices and background turbulent fluctuations. At moderate\\neffects of particle inertia and gravitational settling, particles suppress the\\ncoherence of Taylor vortices which remarkably reduces angular velocity\\ntransport and thus leads to drag reduction. However, with increasing influence\\nof particle inertia and gravitational settling, the flow undergoes abrupt\\nchange. Rapidly settling particles disrupt the Taylor vortices, shifting the\\nbulk flow from a vortex-dominated regime to one characterized by\\nparticle-induced turbulence. With the dominance by particle-induced turbulence,\\nvelocity plumes -- initially transported by small-scale G{\\\"{o}}rtler vortices\\nnear the cylinder wall and large-scale Taylor vortices in bulk region -- are\\ninstead carried into the bulk by turbulent fluctuations driven by the settling\\nparticles.|physics.flu-dyn                                   |physics.flu-dyn|\n",
      "|http://arxiv.org/abs/2505.19860v1|Causal Bayesian Networks for Data-driven Safety Analysis of Complex\\n  Systems Ensuring safe operation of safety-critical complex systems interacting with\\ntheir environment poses significant challenges, particularly when the system's\\nworld model relies on machine learning algorithms to process the perception\\ninput. A comprehensive safety argumentation requires knowledge of how faults or\\nfunctional insufficiencies propagate through the system and interact with\\nexternal factors, to manage their safety impact. While statistical analysis\\napproaches can support the safety assessment, associative reasoning alone is\\nneither sufficient for the safety argumentation nor for the identification and\\ninvestigation of safety measures. A causal understanding of the system and its\\ninteraction with the environment is crucial for safeguarding safety-critical\\ncomplex systems. It allows to transfer and generalize knowledge, such as\\ninsights gained from testing, and facilitates the identification of potential\\nimprovements. This work explores using causal Bayesian networks to model the\\nsystem's causalities for safety analysis, and proposes measures to assess\\ncausal influences based on Pearl's framework of causal inference. We compare\\nthe approach of causal Bayesian networks to the well-established fault tree\\nanalysis, outlining advantages and limitations. In particular, we examine\\nimportance metrics typically employed in fault tree analysis as foundation to\\ndiscuss suitable causal metrics. An evaluation is performed on the example of a\\nperception system for automated driving. Overall, this work presents an\\napproach for causal reasoning in safety analysis that enables the integration\\nof data-driven and expert-based knowledge to account for uncertainties arising\\nfrom complex systems operating in open environments.                                                                                                                                     |cs.RO                                             |cs.AI          |\n",
      "|http://arxiv.org/abs/2505.19861v1|Tight Generalization of Robertson-Type Uncertainty Relations We establish the tightest possible Robertson-type preparation uncertainty\\nrelation, which explicitly depends on the eigenvalue spectrum of the quantum\\nstate. The conventional constant 1/4 is replaced by a state-dependent\\ncoefficient with the largest and smallest eigenvalues of the density operator.\\nThis coefficient is optimal among all Robertson-type generalizations and does\\nnot admit further improvement. Our relation becomes more pronounced as the\\nquantum state becomes more mixed, capturing a trade-off in quantum uncertainty\\nthat the conventional Robertson relation fails to detect. In addition, our\\nresult provides a strict generalization of the Schroedinger uncertainty\\nrelation, showing that the uncertainty trade-off is governed by the sum of the\\ncovariance term and a state-dependent improvement over the Robertson bound. As\\napplications, we also refine error-disturbance trade-offs by incorporating\\nspectral information of both the system and the measuring apparatus, thereby\\ngeneralizing the Arthurs-Goodman and Ozawa inequalities.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |quant-ph,cond-mat.stat-mech,hep-th,math-ph,math.MP|quant-ph       |\n",
      "|http://arxiv.org/abs/2505.19862v1|REA-RL: Reflection-Aware Online Reinforcement Learning for Efficient\\n  Large Reasoning Models Large Reasoning Models (LRMs) demonstrate strong performance in complex tasks\\nbut often face the challenge of overthinking, leading to substantially high\\ninference costs. Existing approaches synthesize shorter reasoning responses for\\nLRMs to learn, but are inefficient for online usage due to the time-consuming\\ndata generation and filtering processes. Meanwhile, online reinforcement\\nlearning mainly adopts a length reward to encourage short reasoning responses,\\nbut tends to lose the reflection ability and harm the performance. To address\\nthese issues, we propose REA-RL, which introduces a small reflection model for\\nefficient scaling in online training, offering both parallel sampling and\\nsequential revision. Besides, a reflection reward is designed to further\\nprevent LRMs from favoring short yet non-reflective responses. Experiments show\\nthat both methods maintain or enhance performance while significantly improving\\ninference efficiency. Their combination achieves a good balance between\\nperformance and efficiency, reducing inference costs by 35% without\\ncompromising performance. Further analysis demonstrates that our methods are\\neffective by maintaining reflection frequency for hard problems while\\nappropriately reducing it for simpler ones without losing reflection ability.\\nCodes are available at https://github.com/hexuandeng/REA-RL.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |cs.CL,cs.LG                                       |cs.LG          |\n",
      "|http://arxiv.org/abs/2505.19863v1|FruitNeRF++: A Generalized Multi-Fruit Counting Method Utilizing\\n  Contrastive Learning and Neural Radiance Fields We introduce FruitNeRF++, a novel fruit-counting approach that combines\\ncontrastive learning with neural radiance fields to count fruits from\\nunstructured input photographs of orchards. Our work is based on FruitNeRF,\\nwhich employs a neural semantic field combined with a fruit-specific clustering\\napproach. The requirement for adaptation for each fruit type limits the\\napplicability of the method, and makes it difficult to use in practice. To lift\\nthis limitation, we design a shape-agnostic multi-fruit counting framework,\\nthat complements the RGB and semantic data with instance masks predicted by a\\nvision foundation model. The masks are used to encode the identity of each\\nfruit as instance embeddings into a neural instance field. By volumetrically\\nsampling the neural fields, we extract a point cloud embedded with the instance\\nfeatures, which can be clustered in a fruit-agnostic manner to obtain the fruit\\ncount. We evaluate our approach using a synthetic dataset containing apples,\\nplums, lemons, pears, peaches, and mangoes, as well as a real-world benchmark\\napple dataset. Our results demonstrate that FruitNeRF++ is easier to control\\nand compares favorably to other state-of-the-art methods.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.CV,cs.LG                                       |cs.CV          |\n",
      "|http://arxiv.org/abs/2505.19864v1|CPA-RAG:Covert Poisoning Attacks on Retrieval-Augmented Generation in\\n  Large Language Models Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\\nincorporating external knowledge, but its openness introduces vulnerabilities\\nthat can be exploited by poisoning attacks. Existing poisoning methods for RAG\\nsystems have limitations, such as poor generalization and lack of fluency in\\nadversarial texts. In this paper, we propose CPA-RAG, a black-box adversarial\\nframework that generates query-relevant texts capable of manipulating the\\nretrieval process to induce target answers. The proposed method integrates\\nprompt-based text generation, cross-guided optimization through multiple LLMs,\\nand retriever-based scoring to construct high-quality adversarial samples. We\\nconduct extensive experiments across multiple datasets and LLMs to evaluate its\\neffectiveness. Results show that the framework achieves over 90\\% attack\\nsuccess when the top-k retrieval setting is 5, matching white-box performance,\\nand maintains a consistent advantage of approximately 5 percentage points\\nacross different top-k values. It also outperforms existing black-box baselines\\nby 14.5 percentage points under various defense strategies. Furthermore, our\\nmethod successfully compromises a commercial RAG system deployed on Alibaba's\\nBaiLian platform, demonstrating its practical threat in real-world\\napplications. These findings underscore the need for more robust and secure RAG\\nframeworks to defend against poisoning attacks.                                                                                                                                                                                                                                                                                                                                                                                                                                               |cs.CR                                             |cs.CL          |\n",
      "+---------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a StreamingContext that checks for new data every 10 seconds\n",
    "ssc = StreamingContext(sc, 10)\n",
    "\n",
    "# Connect to the live data stream from the instructor's server\n",
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "\n",
    "# Process each RDD of incoming lines using your model\n",
    "lines.foreachRDD(process)\n",
    "\n",
    "# Start the streaming thread (non-blocking)\n",
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()\n",
    "\n",
    "# Optional: manually stop after e.g. 60 seconds or a few batches\n",
    "# time.sleep(60)\n",
    "# ssc_t.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd260d1-e7df-4bb9-aa12-5a73e09a343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d71d82-8378-41ea-9d3b-5b2f37f6681e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
